


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: ContextIndexSearcher</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.elasticsearch.search.internal</a> ]
</div>

<h1>Coverage Summary for Class: ContextIndexSearcher (org.elasticsearch.search.internal)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">ContextIndexSearcher</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 15)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 88)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to Elasticsearch under one or more contributor
<i>3</i>&nbsp; * license agreements. See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright
<i>5</i>&nbsp; * ownership. Elasticsearch licenses this file to you under
<i>6</i>&nbsp; * the Apache License, Version 2.0 (the &quot;License&quot;); you may
<i>7</i>&nbsp; * not use this file except in compliance with the License.
<i>8</i>&nbsp; * You may obtain a copy of the License at
<i>9</i>&nbsp; *
<i>10</i>&nbsp; *    http://www.apache.org/licenses/LICENSE-2.0
<i>11</i>&nbsp; *
<i>12</i>&nbsp; * Unless required by applicable law or agreed to in writing,
<i>13</i>&nbsp; * software distributed under the License is distributed on an
<i>14</i>&nbsp; * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
<i>15</i>&nbsp; * KIND, either express or implied.  See the License for the
<i>16</i>&nbsp; * specific language governing permissions and limitations
<i>17</i>&nbsp; * under the License.
<i>18</i>&nbsp; */
<i>19</i>&nbsp;
<i>20</i>&nbsp;package org.elasticsearch.search.internal;
<i>21</i>&nbsp;
<i>22</i>&nbsp;import org.apache.lucene.index.DirectoryReader;
<i>23</i>&nbsp;import org.apache.lucene.index.IndexReader;
<i>24</i>&nbsp;import org.apache.lucene.index.LeafReaderContext;
<i>25</i>&nbsp;import org.apache.lucene.index.Term;
<i>26</i>&nbsp;import org.apache.lucene.search.BulkScorer;
<i>27</i>&nbsp;import org.apache.lucene.search.CollectionStatistics;
<i>28</i>&nbsp;import org.apache.lucene.search.CollectionTerminatedException;
<i>29</i>&nbsp;import org.apache.lucene.search.Collector;
<i>30</i>&nbsp;import org.apache.lucene.search.ConjunctionDISI;
<i>31</i>&nbsp;import org.apache.lucene.search.DocIdSetIterator;
<i>32</i>&nbsp;import org.apache.lucene.search.Explanation;
<i>33</i>&nbsp;import org.apache.lucene.search.IndexSearcher;
<i>34</i>&nbsp;import org.apache.lucene.search.LeafCollector;
<i>35</i>&nbsp;import org.apache.lucene.search.Query;
<i>36</i>&nbsp;import org.apache.lucene.search.QueryCache;
<i>37</i>&nbsp;import org.apache.lucene.search.QueryCachingPolicy;
<i>38</i>&nbsp;import org.apache.lucene.search.ScoreMode;
<i>39</i>&nbsp;import org.apache.lucene.search.Scorer;
<i>40</i>&nbsp;import org.apache.lucene.search.TermStatistics;
<i>41</i>&nbsp;import org.apache.lucene.search.Weight;
<i>42</i>&nbsp;import org.apache.lucene.search.similarities.Similarity;
<i>43</i>&nbsp;import org.apache.lucene.util.BitSet;
<i>44</i>&nbsp;import org.apache.lucene.util.BitSetIterator;
<i>45</i>&nbsp;import org.apache.lucene.util.Bits;
<i>46</i>&nbsp;import org.apache.lucene.util.CombinedBitSet;
<i>47</i>&nbsp;import org.apache.lucene.util.SparseFixedBitSet;
<i>48</i>&nbsp;import org.elasticsearch.search.dfs.AggregatedDfs;
<i>49</i>&nbsp;import org.elasticsearch.search.profile.Timer;
<i>50</i>&nbsp;import org.elasticsearch.search.profile.query.ProfileWeight;
<i>51</i>&nbsp;import org.elasticsearch.search.profile.query.QueryProfileBreakdown;
<i>52</i>&nbsp;import org.elasticsearch.search.profile.query.QueryProfiler;
<i>53</i>&nbsp;import org.elasticsearch.search.profile.query.QueryTimingType;
<i>54</i>&nbsp;
<i>55</i>&nbsp;import java.io.IOException;
<i>56</i>&nbsp;import java.util.Arrays;
<i>57</i>&nbsp;import java.util.List;
<i>58</i>&nbsp;import java.util.Set;
<i>59</i>&nbsp;
<i>60</i>&nbsp;/**
<i>61</i>&nbsp; * Context-aware extension of {@link IndexSearcher}.
<i>62</i>&nbsp; */
<b class="nc"><i>63</i>&nbsp;public class ContextIndexSearcher extends IndexSearcher {</b>
<i>64</i>&nbsp;    /**
<i>65</i>&nbsp;     * The interval at which we check for search cancellation when we cannot use
<i>66</i>&nbsp;     * a {@link CancellableBulkScorer}. See {@link #intersectScorerAndBitSet}.
<i>67</i>&nbsp;     */
<b class="nc"><i>68</i>&nbsp;    private static int CHECK_CANCELLED_SCORER_INTERVAL = 1 &lt;&lt; 11;</b>
<i>69</i>&nbsp;
<i>70</i>&nbsp;    private AggregatedDfs aggregatedDfs;
<i>71</i>&nbsp;    private QueryProfiler profiler;
<i>72</i>&nbsp;    private Runnable checkCancelled;
<i>73</i>&nbsp;
<i>74</i>&nbsp;    public ContextIndexSearcher(IndexReader reader, Similarity similarity, QueryCache queryCache, QueryCachingPolicy queryCachingPolicy) {
<b class="nc"><i>75</i>&nbsp;        super(reader);</b>
<b class="nc"><i>76</i>&nbsp;        setSimilarity(similarity);</b>
<b class="nc"><i>77</i>&nbsp;        setQueryCache(queryCache);</b>
<b class="nc"><i>78</i>&nbsp;        setQueryCachingPolicy(queryCachingPolicy);</b>
<b class="nc"><i>79</i>&nbsp;    }</b>
<i>80</i>&nbsp;
<i>81</i>&nbsp;    public void setProfiler(QueryProfiler profiler) {
<b class="nc"><i>82</i>&nbsp;        this.profiler = profiler;</b>
<b class="nc"><i>83</i>&nbsp;    }</b>
<i>84</i>&nbsp;
<i>85</i>&nbsp;    /**
<i>86</i>&nbsp;     * Set a {@link Runnable} that will be run on a regular basis while
<i>87</i>&nbsp;     * collecting documents.
<i>88</i>&nbsp;     */
<i>89</i>&nbsp;    public void setCheckCancelled(Runnable checkCancelled) {
<b class="nc"><i>90</i>&nbsp;        this.checkCancelled = checkCancelled;</b>
<b class="nc"><i>91</i>&nbsp;    }</b>
<i>92</i>&nbsp;
<i>93</i>&nbsp;    public void setAggregatedDfs(AggregatedDfs aggregatedDfs) {
<b class="nc"><i>94</i>&nbsp;        this.aggregatedDfs = aggregatedDfs;</b>
<b class="nc"><i>95</i>&nbsp;    }</b>
<i>96</i>&nbsp;
<i>97</i>&nbsp;    @Override
<i>98</i>&nbsp;    public Query rewrite(Query original) throws IOException {
<b class="nc"><i>99</i>&nbsp;        if (profiler != null) {</b>
<b class="nc"><i>100</i>&nbsp;            profiler.startRewriteTime();</b>
<i>101</i>&nbsp;        }
<i>102</i>&nbsp;
<i>103</i>&nbsp;        try {
<b class="nc"><i>104</i>&nbsp;            return super.rewrite(original);</b>
<i>105</i>&nbsp;        } finally {
<b class="nc"><i>106</i>&nbsp;            if (profiler != null) {</b>
<b class="nc"><i>107</i>&nbsp;                profiler.stopAndAddRewriteTime();</b>
<i>108</i>&nbsp;            }
<b class="nc"><i>109</i>&nbsp;        }</b>
<i>110</i>&nbsp;    }
<i>111</i>&nbsp;
<i>112</i>&nbsp;    @Override
<i>113</i>&nbsp;    public Weight createWeight(Query query, ScoreMode scoreMode, float boost) throws IOException {
<b class="nc"><i>114</i>&nbsp;        if (profiler != null) {</b>
<i>115</i>&nbsp;            // createWeight() is called for each query in the tree, so we tell the queryProfiler
<i>116</i>&nbsp;            // each invocation so that it can build an internal representation of the query
<i>117</i>&nbsp;            // tree
<b class="nc"><i>118</i>&nbsp;            QueryProfileBreakdown profile = profiler.getQueryBreakdown(query);</b>
<b class="nc"><i>119</i>&nbsp;            Timer timer = profile.getTimer(QueryTimingType.CREATE_WEIGHT);</b>
<b class="nc"><i>120</i>&nbsp;            timer.start();</b>
<i>121</i>&nbsp;            final Weight weight;
<i>122</i>&nbsp;            try {
<b class="nc"><i>123</i>&nbsp;                weight = super.createWeight(query, scoreMode, boost);</b>
<i>124</i>&nbsp;            } finally {
<b class="nc"><i>125</i>&nbsp;                timer.stop();</b>
<b class="nc"><i>126</i>&nbsp;                profiler.pollLastElement();</b>
<b class="nc"><i>127</i>&nbsp;            }</b>
<b class="nc"><i>128</i>&nbsp;            return new ProfileWeight(query, weight, profile);</b>
<i>129</i>&nbsp;        } else {
<b class="nc"><i>130</i>&nbsp;            return super.createWeight(query, scoreMode, boost);</b>
<i>131</i>&nbsp;        }
<i>132</i>&nbsp;    }
<i>133</i>&nbsp;
<i>134</i>&nbsp;    @Override
<i>135</i>&nbsp;    protected void search(List&lt;LeafReaderContext&gt; leaves, Weight weight, Collector collector) throws IOException {
<i>136</i>&nbsp;        final Weight cancellableWeight;
<b class="nc"><i>137</i>&nbsp;        if (checkCancelled != null) {</b>
<b class="nc"><i>138</i>&nbsp;            cancellableWeight = new Weight(weight.getQuery()) {</b>
<i>139</i>&nbsp;
<i>140</i>&nbsp;                @Override
<i>141</i>&nbsp;                public void extractTerms(Set&lt;Term&gt; terms) {
<i>142</i>&nbsp;                    throw new UnsupportedOperationException();
<i>143</i>&nbsp;                }
<i>144</i>&nbsp;
<i>145</i>&nbsp;                @Override
<i>146</i>&nbsp;                public Explanation explain(LeafReaderContext context, int doc) throws IOException {
<i>147</i>&nbsp;                    throw new UnsupportedOperationException();
<i>148</i>&nbsp;                }
<i>149</i>&nbsp;
<i>150</i>&nbsp;                @Override
<i>151</i>&nbsp;                public boolean isCacheable(LeafReaderContext ctx) {
<i>152</i>&nbsp;                    throw new UnsupportedOperationException();
<i>153</i>&nbsp;                }
<i>154</i>&nbsp;
<i>155</i>&nbsp;                @Override
<i>156</i>&nbsp;                public Scorer scorer(LeafReaderContext context) throws IOException {
<i>157</i>&nbsp;                    return weight.scorer(context);
<i>158</i>&nbsp;                }
<i>159</i>&nbsp;
<i>160</i>&nbsp;                @Override
<i>161</i>&nbsp;                public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {
<i>162</i>&nbsp;                    BulkScorer in = weight.bulkScorer(context);
<i>163</i>&nbsp;                    if (in != null) {
<i>164</i>&nbsp;                        return new CancellableBulkScorer(in, checkCancelled);
<i>165</i>&nbsp;                    } else {
<i>166</i>&nbsp;                        return null;
<i>167</i>&nbsp;                    }
<i>168</i>&nbsp;                }
<i>169</i>&nbsp;            };
<i>170</i>&nbsp;        } else {
<b class="nc"><i>171</i>&nbsp;            cancellableWeight = weight;</b>
<i>172</i>&nbsp;        }
<b class="nc"><i>173</i>&nbsp;        searchInternal(leaves, cancellableWeight, collector);</b>
<b class="nc"><i>174</i>&nbsp;    }</b>
<i>175</i>&nbsp;
<i>176</i>&nbsp;    private void searchInternal(List&lt;LeafReaderContext&gt; leaves, Weight weight, Collector collector) throws IOException {
<b class="nc"><i>177</i>&nbsp;        for (LeafReaderContext ctx : leaves) { // search each subreader</b>
<i>178</i>&nbsp;            final LeafCollector leafCollector;
<i>179</i>&nbsp;            try {
<b class="nc"><i>180</i>&nbsp;                leafCollector = collector.getLeafCollector(ctx);</b>
<b class="nc"><i>181</i>&nbsp;            } catch (CollectionTerminatedException e) {</b>
<i>182</i>&nbsp;                // there is no doc of interest in this reader context
<i>183</i>&nbsp;                // continue with the following leaf
<b class="nc"><i>184</i>&nbsp;                continue;</b>
<b class="nc"><i>185</i>&nbsp;            }</b>
<b class="nc"><i>186</i>&nbsp;            Bits liveDocs = ctx.reader().getLiveDocs();</b>
<b class="nc"><i>187</i>&nbsp;            BitSet liveDocsBitSet = getSparseBitSetOrNull(liveDocs);</b>
<b class="nc"><i>188</i>&nbsp;            if (liveDocsBitSet == null) {</b>
<b class="nc"><i>189</i>&nbsp;                BulkScorer bulkScorer = weight.bulkScorer(ctx);</b>
<b class="nc"><i>190</i>&nbsp;                if (bulkScorer != null) {</b>
<i>191</i>&nbsp;                    try {
<b class="nc"><i>192</i>&nbsp;                        bulkScorer.score(leafCollector, liveDocs);</b>
<b class="nc"><i>193</i>&nbsp;                    } catch (CollectionTerminatedException e) {</b>
<i>194</i>&nbsp;                        // collection was terminated prematurely
<i>195</i>&nbsp;                        // continue with the following leaf
<b class="nc"><i>196</i>&nbsp;                    }</b>
<i>197</i>&nbsp;                }
<b class="nc"><i>198</i>&nbsp;            } else {</b>
<i>199</i>&nbsp;                // if the role query result set is sparse then we should use the SparseFixedBitSet for advancing:
<b class="nc"><i>200</i>&nbsp;                Scorer scorer = weight.scorer(ctx);</b>
<b class="nc"><i>201</i>&nbsp;                if (scorer != null) {</b>
<i>202</i>&nbsp;                    try {
<b class="nc"><i>203</i>&nbsp;                        intersectScorerAndBitSet(scorer, liveDocsBitSet, leafCollector,</b>
<b class="nc"><i>204</i>&nbsp;                            checkCancelled == null ? () -&gt; {} : checkCancelled);</b>
<b class="nc"><i>205</i>&nbsp;                    } catch (CollectionTerminatedException e) {</b>
<i>206</i>&nbsp;                        // collection was terminated prematurely
<i>207</i>&nbsp;                        // continue with the following leaf
<b class="nc"><i>208</i>&nbsp;                    }</b>
<i>209</i>&nbsp;                }
<i>210</i>&nbsp;            }
<b class="nc"><i>211</i>&nbsp;        }</b>
<b class="nc"><i>212</i>&nbsp;    }</b>
<i>213</i>&nbsp;
<i>214</i>&nbsp;    private static BitSet getSparseBitSetOrNull(Bits liveDocs) {
<b class="nc"><i>215</i>&nbsp;        if (liveDocs instanceof SparseFixedBitSet) {</b>
<b class="nc"><i>216</i>&nbsp;            return (BitSet) liveDocs;</b>
<b class="nc"><i>217</i>&nbsp;        } else if (liveDocs instanceof CombinedBitSet</b>
<i>218</i>&nbsp;                        // if the underlying role bitset is sparse
<b class="nc"><i>219</i>&nbsp;                        &amp;&amp; ((CombinedBitSet) liveDocs).getFirst() instanceof SparseFixedBitSet) {</b>
<b class="nc"><i>220</i>&nbsp;            return (BitSet) liveDocs;</b>
<i>221</i>&nbsp;        } else {
<b class="nc"><i>222</i>&nbsp;            return null;</b>
<i>223</i>&nbsp;        }
<i>224</i>&nbsp;
<i>225</i>&nbsp;    }
<i>226</i>&nbsp;
<i>227</i>&nbsp;    static void intersectScorerAndBitSet(Scorer scorer, BitSet acceptDocs,
<i>228</i>&nbsp;                                         LeafCollector collector, Runnable checkCancelled) throws IOException {
<b class="nc"><i>229</i>&nbsp;        collector.setScorer(scorer);</b>
<i>230</i>&nbsp;        // ConjunctionDISI uses the DocIdSetIterator#cost() to order the iterators, so if roleBits has the lowest cardinality it should
<i>231</i>&nbsp;        // be used first:
<b class="nc"><i>232</i>&nbsp;        DocIdSetIterator iterator = ConjunctionDISI.intersectIterators(Arrays.asList(new BitSetIterator(acceptDocs,</b>
<b class="nc"><i>233</i>&nbsp;            acceptDocs.approximateCardinality()), scorer.iterator()));</b>
<b class="nc"><i>234</i>&nbsp;        int seen = 0;</b>
<b class="nc"><i>235</i>&nbsp;        checkCancelled.run();</b>
<b class="nc"><i>236</i>&nbsp;        for (int docId = iterator.nextDoc(); docId &lt; DocIdSetIterator.NO_MORE_DOCS; docId = iterator.nextDoc()) {</b>
<b class="nc"><i>237</i>&nbsp;            if (++seen % CHECK_CANCELLED_SCORER_INTERVAL == 0) {</b>
<b class="nc"><i>238</i>&nbsp;                checkCancelled.run();</b>
<i>239</i>&nbsp;            }
<b class="nc"><i>240</i>&nbsp;            collector.collect(docId);</b>
<i>241</i>&nbsp;        }
<b class="nc"><i>242</i>&nbsp;        checkCancelled.run();</b>
<b class="nc"><i>243</i>&nbsp;    }</b>
<i>244</i>&nbsp;
<i>245</i>&nbsp;    @Override
<i>246</i>&nbsp;    public TermStatistics termStatistics(Term term, int docFreq, long totalTermFreq) throws IOException {
<b class="nc"><i>247</i>&nbsp;        if (aggregatedDfs == null) {</b>
<i>248</i>&nbsp;            // we are either executing the dfs phase or the search_type doesn&#39;t include the dfs phase.
<b class="nc"><i>249</i>&nbsp;            return super.termStatistics(term, docFreq, totalTermFreq);</b>
<i>250</i>&nbsp;        }
<b class="nc"><i>251</i>&nbsp;        TermStatistics termStatistics = aggregatedDfs.termStatistics().get(term);</b>
<b class="nc"><i>252</i>&nbsp;        if (termStatistics == null) {</b>
<i>253</i>&nbsp;            // we don&#39;t have stats for this - this might be a must_not clauses etc. that doesn&#39;t allow extract terms on the query
<b class="nc"><i>254</i>&nbsp;            return super.termStatistics(term, docFreq, totalTermFreq);</b>
<i>255</i>&nbsp;        }
<b class="nc"><i>256</i>&nbsp;        return termStatistics;</b>
<i>257</i>&nbsp;    }
<i>258</i>&nbsp;
<i>259</i>&nbsp;    @Override
<i>260</i>&nbsp;    public CollectionStatistics collectionStatistics(String field) throws IOException {
<b class="nc"><i>261</i>&nbsp;        if (aggregatedDfs == null) {</b>
<i>262</i>&nbsp;            // we are either executing the dfs phase or the search_type doesn&#39;t include the dfs phase.
<b class="nc"><i>263</i>&nbsp;            return super.collectionStatistics(field);</b>
<i>264</i>&nbsp;        }
<b class="nc"><i>265</i>&nbsp;        CollectionStatistics collectionStatistics = aggregatedDfs.fieldStatistics().get(field);</b>
<b class="nc"><i>266</i>&nbsp;        if (collectionStatistics == null) {</b>
<i>267</i>&nbsp;            // we don&#39;t have stats for this - this might be a must_not clauses etc. that doesn&#39;t allow extract terms on the query
<b class="nc"><i>268</i>&nbsp;            return super.collectionStatistics(field);</b>
<i>269</i>&nbsp;        }
<b class="nc"><i>270</i>&nbsp;        return collectionStatistics;</b>
<i>271</i>&nbsp;    }
<i>272</i>&nbsp;
<i>273</i>&nbsp;    public DirectoryReader getDirectoryReader() {
<b class="nc"><i>274</i>&nbsp;        final IndexReader reader = getIndexReader();</b>
<b class="nc"><i>275</i>&nbsp;        assert reader instanceof DirectoryReader : &quot;expected an instance of DirectoryReader, got &quot; + reader.getClass();</b>
<b class="nc"><i>276</i>&nbsp;        return (DirectoryReader) reader;</b>
<i>277</i>&nbsp;    }
<i>278</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-02-09 18:45</div>
</div>
</body>
</html>
