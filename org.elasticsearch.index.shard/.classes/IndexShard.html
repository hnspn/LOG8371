


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: IndexShard</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.elasticsearch.index.shard</a> ]
</div>

<h1>Coverage Summary for Class: IndexShard (org.elasticsearch.index.shard)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">IndexShard</td>
<td class="coverageStat">
  <span class="percent">
    28%
  </span>
  <span class="absValue">
    (65/ 232)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    26.3%
  </span>
  <span class="absValue">
    (341/ 1298)
  </span>
</td>
</tr>
  <tr>
    <td class="name">IndexShard$10</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (3/ 3)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">IndexShard$5</td>
<td class="coverageStat">
  <span class="percent">
    50%
  </span>
  <span class="absValue">
    (1/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    12.5%
  </span>
  <span class="absValue">
    (1/ 8)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">IndexShard$8</td>
<td class="coverageStat">
  <span class="percent">
    33.3%
  </span>
  <span class="absValue">
    (1/ 3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    33.3%
  </span>
  <span class="absValue">
    (1/ 3)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">IndexShard$RefreshMetricUpdater</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (4/ 4)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    94.1%
  </span>
  <span class="absValue">
    (16/ 17)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">IndexShard$ShardEventListener</td>
<td class="coverageStat">
  <span class="percent">
    50%
  </span>
  <span class="absValue">
    (1/ 2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    18.2%
  </span>
  <span class="absValue">
    (2/ 11)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>total</strong></td>
<td class="coverageStat">
  <span class="percent">
    29.9%
  </span>
  <span class="absValue">
    (73/ 244)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    27.2%
  </span>
  <span class="absValue">
    (364/ 1340)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to Elasticsearch under one or more contributor
<i>3</i>&nbsp; * license agreements. See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright
<i>5</i>&nbsp; * ownership. Elasticsearch licenses this file to you under
<i>6</i>&nbsp; * the Apache License, Version 2.0 (the &quot;License&quot;); you may
<i>7</i>&nbsp; * not use this file except in compliance with the License.
<i>8</i>&nbsp; * You may obtain a copy of the License at
<i>9</i>&nbsp; *
<i>10</i>&nbsp; *    http://www.apache.org/licenses/LICENSE-2.0
<i>11</i>&nbsp; *
<i>12</i>&nbsp; * Unless required by applicable law or agreed to in writing,
<i>13</i>&nbsp; * software distributed under the License is distributed on an
<i>14</i>&nbsp; * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
<i>15</i>&nbsp; * KIND, either express or implied.  See the License for the
<i>16</i>&nbsp; * specific language governing permissions and limitations
<i>17</i>&nbsp; * under the License.
<i>18</i>&nbsp; */
<i>19</i>&nbsp;
<i>20</i>&nbsp;package org.elasticsearch.index.shard;
<i>21</i>&nbsp;
<i>22</i>&nbsp;import com.carrotsearch.hppc.ObjectLongMap;
<i>23</i>&nbsp;import org.apache.logging.log4j.Logger;
<i>24</i>&nbsp;import org.apache.logging.log4j.message.ParameterizedMessage;
<i>25</i>&nbsp;import org.apache.lucene.index.CheckIndex;
<i>26</i>&nbsp;import org.apache.lucene.index.DirectoryReader;
<i>27</i>&nbsp;import org.apache.lucene.index.FilterDirectoryReader;
<i>28</i>&nbsp;import org.apache.lucene.index.IndexCommit;
<i>29</i>&nbsp;import org.apache.lucene.index.LeafReader;
<i>30</i>&nbsp;import org.apache.lucene.index.SegmentInfos;
<i>31</i>&nbsp;import org.apache.lucene.index.Term;
<i>32</i>&nbsp;import org.apache.lucene.search.Query;
<i>33</i>&nbsp;import org.apache.lucene.search.QueryCachingPolicy;
<i>34</i>&nbsp;import org.apache.lucene.search.ReferenceManager;
<i>35</i>&nbsp;import org.apache.lucene.search.Sort;
<i>36</i>&nbsp;import org.apache.lucene.search.UsageTrackingQueryCachingPolicy;
<i>37</i>&nbsp;import org.apache.lucene.store.AlreadyClosedException;
<i>38</i>&nbsp;import org.apache.lucene.util.SetOnce;
<i>39</i>&nbsp;import org.apache.lucene.util.ThreadInterruptedException;
<i>40</i>&nbsp;import org.elasticsearch.Assertions;
<i>41</i>&nbsp;import org.elasticsearch.ElasticsearchException;
<i>42</i>&nbsp;import org.elasticsearch.ExceptionsHelper;
<i>43</i>&nbsp;import org.elasticsearch.Version;
<i>44</i>&nbsp;import org.elasticsearch.action.ActionListener;
<i>45</i>&nbsp;import org.elasticsearch.action.admin.indices.flush.FlushRequest;
<i>46</i>&nbsp;import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeRequest;
<i>47</i>&nbsp;import org.elasticsearch.action.admin.indices.upgrade.post.UpgradeRequest;
<i>48</i>&nbsp;import org.elasticsearch.action.support.replication.ReplicationResponse;
<i>49</i>&nbsp;import org.elasticsearch.cluster.metadata.IndexMetaData;
<i>50</i>&nbsp;import org.elasticsearch.cluster.metadata.MappingMetaData;
<i>51</i>&nbsp;import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
<i>52</i>&nbsp;import org.elasticsearch.cluster.routing.RecoverySource;
<i>53</i>&nbsp;import org.elasticsearch.cluster.routing.RecoverySource.SnapshotRecoverySource;
<i>54</i>&nbsp;import org.elasticsearch.cluster.routing.ShardRouting;
<i>55</i>&nbsp;import org.elasticsearch.common.Booleans;
<i>56</i>&nbsp;import org.elasticsearch.common.CheckedFunction;
<i>57</i>&nbsp;import org.elasticsearch.common.CheckedRunnable;
<i>58</i>&nbsp;import org.elasticsearch.common.Nullable;
<i>59</i>&nbsp;import org.elasticsearch.common.collect.Tuple;
<i>60</i>&nbsp;import org.elasticsearch.common.io.stream.BytesStreamOutput;
<i>61</i>&nbsp;import org.elasticsearch.common.lease.Releasable;
<i>62</i>&nbsp;import org.elasticsearch.common.lease.Releasables;
<i>63</i>&nbsp;import org.elasticsearch.common.lucene.Lucene;
<i>64</i>&nbsp;import org.elasticsearch.common.lucene.index.ElasticsearchDirectoryReader;
<i>65</i>&nbsp;import org.elasticsearch.common.metrics.CounterMetric;
<i>66</i>&nbsp;import org.elasticsearch.common.metrics.MeanMetric;
<i>67</i>&nbsp;import org.elasticsearch.common.settings.Settings;
<i>68</i>&nbsp;import org.elasticsearch.common.unit.ByteSizeValue;
<i>69</i>&nbsp;import org.elasticsearch.common.unit.TimeValue;
<i>70</i>&nbsp;import org.elasticsearch.common.util.BigArrays;
<i>71</i>&nbsp;import org.elasticsearch.common.util.concurrent.AbstractRunnable;
<i>72</i>&nbsp;import org.elasticsearch.common.util.concurrent.AsyncIOProcessor;
<i>73</i>&nbsp;import org.elasticsearch.common.util.concurrent.RunOnce;
<i>74</i>&nbsp;import org.elasticsearch.common.util.concurrent.ThreadContext;
<i>75</i>&nbsp;import org.elasticsearch.common.xcontent.XContentHelper;
<i>76</i>&nbsp;import org.elasticsearch.core.internal.io.IOUtils;
<i>77</i>&nbsp;import org.elasticsearch.gateway.WriteStateException;
<i>78</i>&nbsp;import org.elasticsearch.index.Index;
<i>79</i>&nbsp;import org.elasticsearch.index.IndexModule;
<i>80</i>&nbsp;import org.elasticsearch.index.IndexNotFoundException;
<i>81</i>&nbsp;import org.elasticsearch.index.IndexService;
<i>82</i>&nbsp;import org.elasticsearch.index.IndexSettings;
<i>83</i>&nbsp;import org.elasticsearch.index.VersionType;
<i>84</i>&nbsp;import org.elasticsearch.index.cache.IndexCache;
<i>85</i>&nbsp;import org.elasticsearch.index.cache.bitset.ShardBitsetFilterCache;
<i>86</i>&nbsp;import org.elasticsearch.index.cache.request.ShardRequestCache;
<i>87</i>&nbsp;import org.elasticsearch.index.codec.CodecService;
<i>88</i>&nbsp;import org.elasticsearch.index.engine.CommitStats;
<i>89</i>&nbsp;import org.elasticsearch.index.engine.Engine;
<i>90</i>&nbsp;import org.elasticsearch.index.engine.Engine.GetResult;
<i>91</i>&nbsp;import org.elasticsearch.index.engine.EngineConfig;
<i>92</i>&nbsp;import org.elasticsearch.index.engine.EngineException;
<i>93</i>&nbsp;import org.elasticsearch.index.engine.EngineFactory;
<i>94</i>&nbsp;import org.elasticsearch.index.engine.ReadOnlyEngine;
<i>95</i>&nbsp;import org.elasticsearch.index.engine.RefreshFailedEngineException;
<i>96</i>&nbsp;import org.elasticsearch.index.engine.SafeCommitInfo;
<i>97</i>&nbsp;import org.elasticsearch.index.engine.Segment;
<i>98</i>&nbsp;import org.elasticsearch.index.engine.SegmentsStats;
<i>99</i>&nbsp;import org.elasticsearch.index.fielddata.FieldDataStats;
<i>100</i>&nbsp;import org.elasticsearch.index.fielddata.ShardFieldData;
<i>101</i>&nbsp;import org.elasticsearch.index.flush.FlushStats;
<i>102</i>&nbsp;import org.elasticsearch.index.get.GetStats;
<i>103</i>&nbsp;import org.elasticsearch.index.get.ShardGetService;
<i>104</i>&nbsp;import org.elasticsearch.index.mapper.DocumentMapper;
<i>105</i>&nbsp;import org.elasticsearch.index.mapper.DocumentMapperForType;
<i>106</i>&nbsp;import org.elasticsearch.index.mapper.IdFieldMapper;
<i>107</i>&nbsp;import org.elasticsearch.index.mapper.MapperParsingException;
<i>108</i>&nbsp;import org.elasticsearch.index.mapper.MapperService;
<i>109</i>&nbsp;import org.elasticsearch.index.mapper.Mapping;
<i>110</i>&nbsp;import org.elasticsearch.index.mapper.ParsedDocument;
<i>111</i>&nbsp;import org.elasticsearch.index.mapper.RootObjectMapper;
<i>112</i>&nbsp;import org.elasticsearch.index.mapper.SourceToParse;
<i>113</i>&nbsp;import org.elasticsearch.index.mapper.Uid;
<i>114</i>&nbsp;import org.elasticsearch.index.merge.MergeStats;
<i>115</i>&nbsp;import org.elasticsearch.index.recovery.RecoveryStats;
<i>116</i>&nbsp;import org.elasticsearch.index.refresh.RefreshStats;
<i>117</i>&nbsp;import org.elasticsearch.index.search.stats.SearchStats;
<i>118</i>&nbsp;import org.elasticsearch.index.search.stats.ShardSearchStats;
<i>119</i>&nbsp;import org.elasticsearch.index.seqno.ReplicationTracker;
<i>120</i>&nbsp;import org.elasticsearch.index.seqno.RetentionLease;
<i>121</i>&nbsp;import org.elasticsearch.index.seqno.RetentionLeaseStats;
<i>122</i>&nbsp;import org.elasticsearch.index.seqno.RetentionLeaseSyncer;
<i>123</i>&nbsp;import org.elasticsearch.index.seqno.RetentionLeases;
<i>124</i>&nbsp;import org.elasticsearch.index.seqno.SeqNoStats;
<i>125</i>&nbsp;import org.elasticsearch.index.seqno.SequenceNumbers;
<i>126</i>&nbsp;import org.elasticsearch.index.shard.PrimaryReplicaSyncer.ResyncTask;
<i>127</i>&nbsp;import org.elasticsearch.index.similarity.SimilarityService;
<i>128</i>&nbsp;import org.elasticsearch.index.store.Store;
<i>129</i>&nbsp;import org.elasticsearch.index.store.Store.MetadataSnapshot;
<i>130</i>&nbsp;import org.elasticsearch.index.store.StoreFileMetaData;
<i>131</i>&nbsp;import org.elasticsearch.index.store.StoreStats;
<i>132</i>&nbsp;import org.elasticsearch.index.translog.Translog;
<i>133</i>&nbsp;import org.elasticsearch.index.translog.TranslogConfig;
<i>134</i>&nbsp;import org.elasticsearch.index.translog.TranslogStats;
<i>135</i>&nbsp;import org.elasticsearch.index.warmer.ShardIndexWarmerService;
<i>136</i>&nbsp;import org.elasticsearch.index.warmer.WarmerStats;
<i>137</i>&nbsp;import org.elasticsearch.indices.IndexingMemoryController;
<i>138</i>&nbsp;import org.elasticsearch.indices.IndicesService;
<i>139</i>&nbsp;import org.elasticsearch.indices.TypeMissingException;
<i>140</i>&nbsp;import org.elasticsearch.indices.breaker.CircuitBreakerService;
<i>141</i>&nbsp;import org.elasticsearch.indices.cluster.IndicesClusterStateService;
<i>142</i>&nbsp;import org.elasticsearch.indices.recovery.PeerRecoveryTargetService;
<i>143</i>&nbsp;import org.elasticsearch.indices.recovery.RecoveryFailedException;
<i>144</i>&nbsp;import org.elasticsearch.indices.recovery.RecoveryState;
<i>145</i>&nbsp;import org.elasticsearch.indices.recovery.RecoveryTarget;
<i>146</i>&nbsp;import org.elasticsearch.repositories.RepositoriesService;
<i>147</i>&nbsp;import org.elasticsearch.repositories.Repository;
<i>148</i>&nbsp;import org.elasticsearch.rest.RestStatus;
<i>149</i>&nbsp;import org.elasticsearch.search.suggest.completion.CompletionStats;
<i>150</i>&nbsp;import org.elasticsearch.threadpool.ThreadPool;
<i>151</i>&nbsp;
<i>152</i>&nbsp;import java.io.Closeable;
<i>153</i>&nbsp;import java.io.IOException;
<i>154</i>&nbsp;import java.io.PrintStream;
<i>155</i>&nbsp;import java.io.UncheckedIOException;
<i>156</i>&nbsp;import java.nio.channels.ClosedByInterruptException;
<i>157</i>&nbsp;import java.nio.charset.StandardCharsets;
<i>158</i>&nbsp;import java.util.ArrayList;
<i>159</i>&nbsp;import java.util.Collections;
<i>160</i>&nbsp;import java.util.EnumSet;
<i>161</i>&nbsp;import java.util.HashSet;
<i>162</i>&nbsp;import java.util.List;
<i>163</i>&nbsp;import java.util.Locale;
<i>164</i>&nbsp;import java.util.Map;
<i>165</i>&nbsp;import java.util.Objects;
<i>166</i>&nbsp;import java.util.Optional;
<i>167</i>&nbsp;import java.util.Set;
<i>168</i>&nbsp;import java.util.concurrent.CopyOnWriteArrayList;
<i>169</i>&nbsp;import java.util.concurrent.CountDownLatch;
<i>170</i>&nbsp;import java.util.concurrent.TimeUnit;
<i>171</i>&nbsp;import java.util.concurrent.TimeoutException;
<i>172</i>&nbsp;import java.util.concurrent.atomic.AtomicBoolean;
<i>173</i>&nbsp;import java.util.concurrent.atomic.AtomicLong;
<i>174</i>&nbsp;import java.util.concurrent.atomic.AtomicReference;
<i>175</i>&nbsp;import java.util.function.BiConsumer;
<i>176</i>&nbsp;import java.util.function.Consumer;
<i>177</i>&nbsp;import java.util.function.Function;
<i>178</i>&nbsp;import java.util.function.LongSupplier;
<i>179</i>&nbsp;import java.util.function.Supplier;
<i>180</i>&nbsp;import java.util.stream.Collectors;
<i>181</i>&nbsp;import java.util.stream.StreamSupport;
<i>182</i>&nbsp;
<i>183</i>&nbsp;import static org.elasticsearch.index.seqno.RetentionLeaseActions.RETAIN_ALL;
<i>184</i>&nbsp;import static org.elasticsearch.index.seqno.SequenceNumbers.UNASSIGNED_SEQ_NO;
<i>185</i>&nbsp;
<b class="fc"><i>186</i>&nbsp;public class IndexShard extends AbstractIndexShardComponent implements IndicesClusterStateService.Shard {</b>
<i>187</i>&nbsp;
<i>188</i>&nbsp;    private final ThreadPool threadPool;
<i>189</i>&nbsp;    private final MapperService mapperService;
<i>190</i>&nbsp;    private final IndexCache indexCache;
<i>191</i>&nbsp;    private final Store store;
<i>192</i>&nbsp;    private final InternalIndexingStats internalIndexingStats;
<b class="fc"><i>193</i>&nbsp;    private final ShardSearchStats searchStats = new ShardSearchStats();</b>
<i>194</i>&nbsp;    private final ShardGetService getService;
<i>195</i>&nbsp;    private final ShardIndexWarmerService shardWarmerService;
<i>196</i>&nbsp;    private final ShardRequestCache requestCacheStats;
<i>197</i>&nbsp;    private final ShardFieldData shardFieldData;
<i>198</i>&nbsp;    private final ShardBitsetFilterCache shardBitsetFilterCache;
<b class="fc"><i>199</i>&nbsp;    private final Object mutex = new Object();</b>
<i>200</i>&nbsp;    private final String checkIndexOnStartup;
<i>201</i>&nbsp;    private final CodecService codecService;
<i>202</i>&nbsp;    private final Engine.Warmer warmer;
<i>203</i>&nbsp;    private final SimilarityService similarityService;
<i>204</i>&nbsp;    private final TranslogConfig translogConfig;
<i>205</i>&nbsp;    private final IndexEventListener indexEventListener;
<i>206</i>&nbsp;    private final QueryCachingPolicy cachingPolicy;
<i>207</i>&nbsp;    private final Supplier&lt;Sort&gt; indexSortSupplier;
<i>208</i>&nbsp;    // Package visible for testing
<i>209</i>&nbsp;    final CircuitBreakerService circuitBreakerService;
<i>210</i>&nbsp;
<i>211</i>&nbsp;    private final SearchOperationListener searchOperationListener;
<i>212</i>&nbsp;
<i>213</i>&nbsp;    private final GlobalCheckpointListeners globalCheckpointListeners;
<i>214</i>&nbsp;    private final ReplicationTracker replicationTracker;
<i>215</i>&nbsp;
<i>216</i>&nbsp;    protected volatile ShardRouting shardRouting;
<i>217</i>&nbsp;    protected volatile IndexShardState state;
<i>218</i>&nbsp;    // ensure happens-before relation between addRefreshListener() and postRecovery()
<b class="fc"><i>219</i>&nbsp;    private final Object postRecoveryMutex = new Object();</b>
<i>220</i>&nbsp;    private volatile long pendingPrimaryTerm; // see JavaDocs for getPendingPrimaryTerm
<b class="fc"><i>221</i>&nbsp;    private final Object engineMutex = new Object(); // lock ordering: engineMutex -&gt; mutex</b>
<b class="fc"><i>222</i>&nbsp;    private final AtomicReference&lt;Engine&gt; currentEngineReference = new AtomicReference&lt;&gt;();</b>
<i>223</i>&nbsp;    final EngineFactory engineFactory;
<i>224</i>&nbsp;
<i>225</i>&nbsp;    private final IndexingOperationListener indexingOperationListeners;
<i>226</i>&nbsp;    private final Runnable globalCheckpointSyncer;
<i>227</i>&nbsp;
<i>228</i>&nbsp;    Runnable getGlobalCheckpointSyncer() {
<b class="nc"><i>229</i>&nbsp;        return globalCheckpointSyncer;</b>
<i>230</i>&nbsp;    }
<i>231</i>&nbsp;
<i>232</i>&nbsp;    private final RetentionLeaseSyncer retentionLeaseSyncer;
<i>233</i>&nbsp;
<i>234</i>&nbsp;    @Nullable
<i>235</i>&nbsp;    private RecoveryState recoveryState;
<i>236</i>&nbsp;
<b class="fc"><i>237</i>&nbsp;    private final RecoveryStats recoveryStats = new RecoveryStats();</b>
<b class="fc"><i>238</i>&nbsp;    private final MeanMetric refreshMetric = new MeanMetric();</b>
<b class="fc"><i>239</i>&nbsp;    private final MeanMetric externalRefreshMetric = new MeanMetric();</b>
<b class="fc"><i>240</i>&nbsp;    private final MeanMetric flushMetric = new MeanMetric();</b>
<b class="fc"><i>241</i>&nbsp;    private final CounterMetric periodicFlushMetric = new CounterMetric();</b>
<i>242</i>&nbsp;
<b class="fc"><i>243</i>&nbsp;    private final ShardEventListener shardEventListener = new ShardEventListener();</b>
<i>244</i>&nbsp;
<i>245</i>&nbsp;    private final ShardPath path;
<i>246</i>&nbsp;
<i>247</i>&nbsp;    private final IndexShardOperationPermits indexShardOperationPermits;
<i>248</i>&nbsp;
<b class="fc"><i>249</i>&nbsp;    private static final EnumSet&lt;IndexShardState&gt; readAllowedStates = EnumSet.of(IndexShardState.STARTED, IndexShardState.POST_RECOVERY);</b>
<i>250</i>&nbsp;    // for primaries, we only allow to write when actually started (so the cluster has decided we started)
<i>251</i>&nbsp;    // in case we have a relocation of a primary, we also allow to write after phase 2 completed, where the shard may be
<i>252</i>&nbsp;    // in state RECOVERING or POST_RECOVERY.
<i>253</i>&nbsp;    // for replicas, replication is also allowed while recovering, since we index also during recovery to replicas and rely on
<i>254</i>&nbsp;    // version checks to make sure its consistent a relocated shard can also be target of a replication if the relocation target has not
<i>255</i>&nbsp;    // been marked as active yet and is syncing it&#39;s changes back to the relocation source
<b class="fc"><i>256</i>&nbsp;    private static final EnumSet&lt;IndexShardState&gt; writeAllowedStates = EnumSet.of(IndexShardState.RECOVERING,</b>
<i>257</i>&nbsp;        IndexShardState.POST_RECOVERY, IndexShardState.STARTED);
<i>258</i>&nbsp;
<i>259</i>&nbsp;    private final CheckedFunction&lt;DirectoryReader, DirectoryReader, IOException&gt; readerWrapper;
<i>260</i>&nbsp;
<i>261</i>&nbsp;    /**
<i>262</i>&nbsp;     * True if this shard is still indexing (recently) and false if we&#39;ve been idle for long enough (as periodically checked by {@link
<i>263</i>&nbsp;     * IndexingMemoryController}).
<i>264</i>&nbsp;     */
<b class="fc"><i>265</i>&nbsp;    private final AtomicBoolean active = new AtomicBoolean();</b>
<i>266</i>&nbsp;    /**
<i>267</i>&nbsp;     * Allows for the registration of listeners that are called when a change becomes visible for search.
<i>268</i>&nbsp;     */
<i>269</i>&nbsp;    private final RefreshListeners refreshListeners;
<i>270</i>&nbsp;
<b class="fc"><i>271</i>&nbsp;    private final AtomicLong lastSearcherAccess = new AtomicLong();</b>
<b class="fc"><i>272</i>&nbsp;    private final AtomicReference&lt;Translog.Location&gt; pendingRefreshLocation = new AtomicReference&lt;&gt;();</b>
<i>273</i>&nbsp;    private volatile boolean useRetentionLeasesInPeerRecovery;
<i>274</i>&nbsp;
<i>275</i>&nbsp;    public IndexShard(
<i>276</i>&nbsp;            final ShardRouting shardRouting,
<i>277</i>&nbsp;            final IndexSettings indexSettings,
<i>278</i>&nbsp;            final ShardPath path,
<i>279</i>&nbsp;            final Store store,
<i>280</i>&nbsp;            final Supplier&lt;Sort&gt; indexSortSupplier,
<i>281</i>&nbsp;            final IndexCache indexCache,
<i>282</i>&nbsp;            final MapperService mapperService,
<i>283</i>&nbsp;            final SimilarityService similarityService,
<i>284</i>&nbsp;            final @Nullable EngineFactory engineFactory,
<i>285</i>&nbsp;            final IndexEventListener indexEventListener,
<i>286</i>&nbsp;            final CheckedFunction&lt;DirectoryReader, DirectoryReader, IOException&gt; indexReaderWrapper,
<i>287</i>&nbsp;            final ThreadPool threadPool,
<i>288</i>&nbsp;            final BigArrays bigArrays,
<i>289</i>&nbsp;            final Engine.Warmer warmer,
<i>290</i>&nbsp;            final List&lt;SearchOperationListener&gt; searchOperationListener,
<i>291</i>&nbsp;            final List&lt;IndexingOperationListener&gt; listeners,
<i>292</i>&nbsp;            final Runnable globalCheckpointSyncer,
<i>293</i>&nbsp;            final RetentionLeaseSyncer retentionLeaseSyncer,
<i>294</i>&nbsp;            final CircuitBreakerService circuitBreakerService) throws IOException {
<b class="fc"><i>295</i>&nbsp;        super(shardRouting.shardId(), indexSettings);</b>
<b class="fc"><i>296</i>&nbsp;        assert shardRouting.initializing();</b>
<b class="fc"><i>297</i>&nbsp;        this.shardRouting = shardRouting;</b>
<b class="fc"><i>298</i>&nbsp;        final Settings settings = indexSettings.getSettings();</b>
<b class="fc"><i>299</i>&nbsp;        this.codecService = new CodecService(mapperService, logger);</b>
<b class="fc"><i>300</i>&nbsp;        this.warmer = warmer;</b>
<b class="fc"><i>301</i>&nbsp;        this.similarityService = similarityService;</b>
<b class="fc"><i>302</i>&nbsp;        Objects.requireNonNull(store, &quot;Store must be provided to the index shard&quot;);</b>
<b class="fc"><i>303</i>&nbsp;        this.engineFactory = Objects.requireNonNull(engineFactory);</b>
<b class="fc"><i>304</i>&nbsp;        this.store = store;</b>
<b class="fc"><i>305</i>&nbsp;        this.indexSortSupplier = indexSortSupplier;</b>
<b class="fc"><i>306</i>&nbsp;        this.indexEventListener = indexEventListener;</b>
<b class="fc"><i>307</i>&nbsp;        this.threadPool = threadPool;</b>
<b class="fc"><i>308</i>&nbsp;        this.translogSyncProcessor = createTranslogSyncProcessor(logger, threadPool.getThreadContext(), this::getEngine);</b>
<b class="fc"><i>309</i>&nbsp;        this.mapperService = mapperService;</b>
<b class="fc"><i>310</i>&nbsp;        this.indexCache = indexCache;</b>
<b class="fc"><i>311</i>&nbsp;        this.internalIndexingStats = new InternalIndexingStats();</b>
<b class="fc"><i>312</i>&nbsp;        final List&lt;IndexingOperationListener&gt; listenersList = new ArrayList&lt;&gt;(listeners);</b>
<b class="fc"><i>313</i>&nbsp;        listenersList.add(internalIndexingStats);</b>
<b class="fc"><i>314</i>&nbsp;        this.indexingOperationListeners = new IndexingOperationListener.CompositeListener(listenersList, logger);</b>
<b class="fc"><i>315</i>&nbsp;        this.globalCheckpointSyncer = globalCheckpointSyncer;</b>
<b class="fc"><i>316</i>&nbsp;        this.retentionLeaseSyncer = Objects.requireNonNull(retentionLeaseSyncer);</b>
<b class="fc"><i>317</i>&nbsp;        final List&lt;SearchOperationListener&gt; searchListenersList = new ArrayList&lt;&gt;(searchOperationListener);</b>
<b class="fc"><i>318</i>&nbsp;        searchListenersList.add(searchStats);</b>
<b class="fc"><i>319</i>&nbsp;        this.searchOperationListener = new SearchOperationListener.CompositeListener(searchListenersList, logger);</b>
<b class="fc"><i>320</i>&nbsp;        this.getService = new ShardGetService(indexSettings, this, mapperService);</b>
<b class="fc"><i>321</i>&nbsp;        this.shardWarmerService = new ShardIndexWarmerService(shardId, indexSettings);</b>
<b class="fc"><i>322</i>&nbsp;        this.requestCacheStats = new ShardRequestCache();</b>
<b class="fc"><i>323</i>&nbsp;        this.shardFieldData = new ShardFieldData();</b>
<b class="fc"><i>324</i>&nbsp;        this.shardBitsetFilterCache = new ShardBitsetFilterCache(shardId, indexSettings);</b>
<b class="fc"><i>325</i>&nbsp;        state = IndexShardState.CREATED;</b>
<b class="fc"><i>326</i>&nbsp;        this.path = path;</b>
<b class="fc"><i>327</i>&nbsp;        this.circuitBreakerService = circuitBreakerService;</b>
<i>328</i>&nbsp;        /* create engine config */
<b class="fc"><i>329</i>&nbsp;        logger.debug(&quot;state: [CREATED]&quot;);</b>
<i>330</i>&nbsp;
<b class="fc"><i>331</i>&nbsp;        this.checkIndexOnStartup = indexSettings.getValue(IndexSettings.INDEX_CHECK_ON_STARTUP);</b>
<b class="fc"><i>332</i>&nbsp;        this.translogConfig = new TranslogConfig(shardId, shardPath().resolveTranslog(), indexSettings, bigArrays);</b>
<b class="fc"><i>333</i>&nbsp;        final String aId = shardRouting.allocationId().getId();</b>
<b class="fc"><i>334</i>&nbsp;        final long primaryTerm = indexSettings.getIndexMetaData().primaryTerm(shardId.id());</b>
<b class="fc"><i>335</i>&nbsp;        this.pendingPrimaryTerm = primaryTerm;</b>
<b class="fc"><i>336</i>&nbsp;        this.globalCheckpointListeners =</b>
<b class="fc"><i>337</i>&nbsp;                new GlobalCheckpointListeners(shardId, threadPool.executor(ThreadPool.Names.LISTENER), threadPool.scheduler(), logger);</b>
<b class="fc"><i>338</i>&nbsp;        this.replicationTracker = new ReplicationTracker(</b>
<i>339</i>&nbsp;                shardId,
<i>340</i>&nbsp;                aId,
<i>341</i>&nbsp;                indexSettings,
<i>342</i>&nbsp;                primaryTerm,
<i>343</i>&nbsp;                UNASSIGNED_SEQ_NO,
<b class="fc"><i>344</i>&nbsp;                globalCheckpointListeners::globalCheckpointUpdated,</b>
<b class="fc"><i>345</i>&nbsp;                threadPool::absoluteTimeInMillis,</b>
<b class="nc"><i>346</i>&nbsp;                (retentionLeases, listener) -&gt; retentionLeaseSyncer.sync(shardId, retentionLeases, listener),</b>
<i>347</i>&nbsp;                this::getSafeCommitInfo);
<i>348</i>&nbsp;
<i>349</i>&nbsp;        // the query cache is a node-level thing, however we want the most popular filters
<i>350</i>&nbsp;        // to be computed on a per-shard basis
<b class="fc"><i>351</i>&nbsp;        if (IndexModule.INDEX_QUERY_CACHE_EVERYTHING_SETTING.get(settings)) {</b>
<b class="nc"><i>352</i>&nbsp;            cachingPolicy = new QueryCachingPolicy() {</b>
<i>353</i>&nbsp;                @Override
<i>354</i>&nbsp;                public void onUse(Query query) {
<i>355</i>&nbsp;
<i>356</i>&nbsp;                }
<i>357</i>&nbsp;                @Override
<i>358</i>&nbsp;                public boolean shouldCache(Query query) {
<i>359</i>&nbsp;                    return true;
<i>360</i>&nbsp;                }
<i>361</i>&nbsp;            };
<i>362</i>&nbsp;        } else {
<b class="fc"><i>363</i>&nbsp;            cachingPolicy = new UsageTrackingQueryCachingPolicy();</b>
<i>364</i>&nbsp;        }
<b class="fc"><i>365</i>&nbsp;        indexShardOperationPermits = new IndexShardOperationPermits(shardId, threadPool);</b>
<b class="fc"><i>366</i>&nbsp;        readerWrapper = indexReaderWrapper;</b>
<b class="fc"><i>367</i>&nbsp;        refreshListeners = buildRefreshListeners();</b>
<b class="fc"><i>368</i>&nbsp;        lastSearcherAccess.set(threadPool.relativeTimeInMillis());</b>
<b class="fc"><i>369</i>&nbsp;        persistMetadata(path, indexSettings, shardRouting, null, logger);</b>
<b class="fc"><i>370</i>&nbsp;        this.useRetentionLeasesInPeerRecovery = replicationTracker.hasAllPeerRecoveryRetentionLeases();</b>
<b class="fc"><i>371</i>&nbsp;    }</b>
<i>372</i>&nbsp;
<i>373</i>&nbsp;    public ThreadPool getThreadPool() {
<b class="nc"><i>374</i>&nbsp;        return this.threadPool;</b>
<i>375</i>&nbsp;    }
<i>376</i>&nbsp;
<i>377</i>&nbsp;    public Store store() {
<b class="fc"><i>378</i>&nbsp;        return this.store;</b>
<i>379</i>&nbsp;    }
<i>380</i>&nbsp;
<i>381</i>&nbsp;    /**
<i>382</i>&nbsp;     * Return the sort order of this index, or null if the index has no sort.
<i>383</i>&nbsp;     */
<i>384</i>&nbsp;    public Sort getIndexSort() {
<b class="nc"><i>385</i>&nbsp;        return indexSortSupplier.get();</b>
<i>386</i>&nbsp;    }
<i>387</i>&nbsp;
<i>388</i>&nbsp;    public ShardGetService getService() {
<b class="nc"><i>389</i>&nbsp;        return this.getService;</b>
<i>390</i>&nbsp;    }
<i>391</i>&nbsp;
<i>392</i>&nbsp;    public ShardBitsetFilterCache shardBitsetFilterCache() {
<b class="nc"><i>393</i>&nbsp;        return shardBitsetFilterCache;</b>
<i>394</i>&nbsp;    }
<i>395</i>&nbsp;
<i>396</i>&nbsp;    public MapperService mapperService() {
<b class="fc"><i>397</i>&nbsp;        return mapperService;</b>
<i>398</i>&nbsp;    }
<i>399</i>&nbsp;
<i>400</i>&nbsp;    public SearchOperationListener getSearchOperationListener() {
<b class="nc"><i>401</i>&nbsp;        return this.searchOperationListener;</b>
<i>402</i>&nbsp;    }
<i>403</i>&nbsp;
<i>404</i>&nbsp;    public ShardIndexWarmerService warmerService() {
<b class="fc"><i>405</i>&nbsp;        return this.shardWarmerService;</b>
<i>406</i>&nbsp;    }
<i>407</i>&nbsp;
<i>408</i>&nbsp;    public ShardRequestCache requestCache() {
<b class="nc"><i>409</i>&nbsp;        return this.requestCacheStats;</b>
<i>410</i>&nbsp;    }
<i>411</i>&nbsp;
<i>412</i>&nbsp;    public ShardFieldData fieldData() {
<b class="nc"><i>413</i>&nbsp;        return this.shardFieldData;</b>
<i>414</i>&nbsp;    }
<i>415</i>&nbsp;
<i>416</i>&nbsp;    /**
<i>417</i>&nbsp;     * USE THIS METHOD WITH CARE!
<i>418</i>&nbsp;     * Returns the primary term the index shard is supposed to be on. In case of primary promotion or when a replica learns about
<i>419</i>&nbsp;     * a new term due to a new primary, the term that&#39;s exposed here will not be the term that the shard internally uses to assign
<i>420</i>&nbsp;     * to operations. The shard will auto-correct its internal operation term, but this might take time.
<i>421</i>&nbsp;     * See {@link org.elasticsearch.cluster.metadata.IndexMetaData#primaryTerm(int)}
<i>422</i>&nbsp;     */
<i>423</i>&nbsp;    public long getPendingPrimaryTerm() {
<b class="fc"><i>424</i>&nbsp;        return this.pendingPrimaryTerm;</b>
<i>425</i>&nbsp;    }
<i>426</i>&nbsp;
<i>427</i>&nbsp;    /** Returns the primary term that is currently being used to assign to operations */
<i>428</i>&nbsp;    public long getOperationPrimaryTerm() {
<b class="fc"><i>429</i>&nbsp;        return replicationTracker.getOperationPrimaryTerm();</b>
<i>430</i>&nbsp;    }
<i>431</i>&nbsp;
<i>432</i>&nbsp;    /**
<i>433</i>&nbsp;     * Returns the latest cluster routing entry received with this shard.
<i>434</i>&nbsp;     */
<i>435</i>&nbsp;    @Override
<i>436</i>&nbsp;    public ShardRouting routingEntry() {
<b class="fc"><i>437</i>&nbsp;        return this.shardRouting;</b>
<i>438</i>&nbsp;    }
<i>439</i>&nbsp;
<i>440</i>&nbsp;    public QueryCachingPolicy getQueryCachingPolicy() {
<b class="nc"><i>441</i>&nbsp;        return cachingPolicy;</b>
<i>442</i>&nbsp;    }
<i>443</i>&nbsp;
<i>444</i>&nbsp;
<i>445</i>&nbsp;    @Override
<i>446</i>&nbsp;    public void updateShardState(final ShardRouting newRouting,
<i>447</i>&nbsp;                                 final long newPrimaryTerm,
<i>448</i>&nbsp;                                 final BiConsumer&lt;IndexShard, ActionListener&lt;ResyncTask&gt;&gt; primaryReplicaSyncer,
<i>449</i>&nbsp;                                 final long applyingClusterStateVersion,
<i>450</i>&nbsp;                                 final Set&lt;String&gt; inSyncAllocationIds,
<i>451</i>&nbsp;                                 final IndexShardRoutingTable routingTable) throws IOException {
<i>452</i>&nbsp;        final ShardRouting currentRouting;
<b class="fc"><i>453</i>&nbsp;        synchronized (mutex) {</b>
<b class="fc"><i>454</i>&nbsp;            currentRouting = this.shardRouting;</b>
<b class="fc"><i>455</i>&nbsp;            assert currentRouting != null;</b>
<i>456</i>&nbsp;
<b class="fc"><i>457</i>&nbsp;            if (!newRouting.shardId().equals(shardId())) {</b>
<b class="nc"><i>458</i>&nbsp;                throw new IllegalArgumentException(&quot;Trying to set a routing entry with shardId &quot; +</b>
<b class="nc"><i>459</i>&nbsp;                    newRouting.shardId() + &quot; on a shard with shardId &quot; + shardId());</b>
<i>460</i>&nbsp;            }
<b class="fc"><i>461</i>&nbsp;            if (newRouting.isSameAllocation(currentRouting) == false) {</b>
<b class="nc"><i>462</i>&nbsp;                throw new IllegalArgumentException(&quot;Trying to set a routing entry with a different allocation. Current &quot; +</b>
<i>463</i>&nbsp;                    currentRouting + &quot;, new &quot; + newRouting);
<i>464</i>&nbsp;            }
<b class="fc"><i>465</i>&nbsp;            if (currentRouting.primary() &amp;&amp; newRouting.primary() == false) {</b>
<b class="nc"><i>466</i>&nbsp;                throw new IllegalArgumentException(&quot;illegal state: trying to move shard from primary mode to replica mode. Current &quot;</b>
<i>467</i>&nbsp;                    + currentRouting + &quot;, new &quot; + newRouting);
<i>468</i>&nbsp;            }
<i>469</i>&nbsp;
<b class="fc"><i>470</i>&nbsp;            if (newRouting.primary()) {</b>
<b class="fc"><i>471</i>&nbsp;                replicationTracker.updateFromMaster(applyingClusterStateVersion, inSyncAllocationIds, routingTable);</b>
<i>472</i>&nbsp;            }
<i>473</i>&nbsp;
<b class="fc"><i>474</i>&nbsp;            if (state == IndexShardState.POST_RECOVERY &amp;&amp; newRouting.active()) {</b>
<b class="fc"><i>475</i>&nbsp;                assert currentRouting.active() == false : &quot;we are in POST_RECOVERY, but our shard routing is active &quot; + currentRouting;</b>
<b class="fc"><i>476</i>&nbsp;                assert currentRouting.isRelocationTarget()  == false || currentRouting.primary() == false ||</b>
<b class="nc"><i>477</i>&nbsp;                        replicationTracker.isPrimaryMode() :</b>
<i>478</i>&nbsp;                    &quot;a primary relocation is completed by the master, but primary mode is not active &quot; + currentRouting;
<i>479</i>&nbsp;
<b class="fc"><i>480</i>&nbsp;                changeState(IndexShardState.STARTED, &quot;global state is [&quot; + newRouting.state() + &quot;]&quot;);</b>
<b class="nc"><i>481</i>&nbsp;            } else if (currentRouting.primary() &amp;&amp; currentRouting.relocating() &amp;&amp; replicationTracker.isRelocated() &amp;&amp;</b>
<b class="nc"><i>482</i>&nbsp;                (newRouting.relocating() == false || newRouting.equalsIgnoringMetaData(currentRouting) == false)) {</b>
<i>483</i>&nbsp;                // if the shard is not in primary mode anymore (after primary relocation) we have to fail when any changes in shard
<i>484</i>&nbsp;                // routing occur (e.g. due to recovery failure / cancellation). The reason is that at the moment we cannot safely
<i>485</i>&nbsp;                // reactivate primary mode without risking two active primaries.
<b class="nc"><i>486</i>&nbsp;                throw new IndexShardRelocatedException(shardId(), &quot;Shard is marked as relocated, cannot safely move to state &quot; +</b>
<b class="nc"><i>487</i>&nbsp;                    newRouting.state());</b>
<i>488</i>&nbsp;            }
<b class="fc"><i>489</i>&nbsp;            assert newRouting.active() == false || state == IndexShardState.STARTED || state == IndexShardState.CLOSED :</b>
<i>490</i>&nbsp;                &quot;routing is active, but local shard state isn&#39;t. routing: &quot; + newRouting + &quot;, local state: &quot; + state;
<b class="fc"><i>491</i>&nbsp;            persistMetadata(path, indexSettings, newRouting, currentRouting, logger);</b>
<b class="fc"><i>492</i>&nbsp;            final CountDownLatch shardStateUpdated = new CountDownLatch(1);</b>
<i>493</i>&nbsp;
<b class="fc"><i>494</i>&nbsp;            if (newRouting.primary()) {</b>
<b class="fc"><i>495</i>&nbsp;                if (newPrimaryTerm == pendingPrimaryTerm) {</b>
<b class="fc"><i>496</i>&nbsp;                    if (currentRouting.initializing() &amp;&amp; currentRouting.isRelocationTarget() == false &amp;&amp; newRouting.active()) {</b>
<i>497</i>&nbsp;                        // the master started a recovering primary, activate primary mode.
<b class="fc"><i>498</i>&nbsp;                        replicationTracker.activatePrimaryMode(getLocalCheckpoint());</b>
<b class="fc"><i>499</i>&nbsp;                        ensurePeerRecoveryRetentionLeasesExist();</b>
<i>500</i>&nbsp;                    }
<i>501</i>&nbsp;                } else {
<b class="nc"><i>502</i>&nbsp;                    assert currentRouting.primary() == false : &quot;term is only increased as part of primary promotion&quot;;</b>
<i>503</i>&nbsp;                    /* Note that due to cluster state batching an initializing primary shard term can failed and re-assigned
<i>504</i>&nbsp;                     * in one state causing it&#39;s term to be incremented. Note that if both current shard state and new
<i>505</i>&nbsp;                     * shard state are initializing, we could replace the current shard and reinitialize it. It is however
<i>506</i>&nbsp;                     * possible that this shard is being started. This can happen if:
<i>507</i>&nbsp;                     * 1) Shard is post recovery and sends shard started to the master
<i>508</i>&nbsp;                     * 2) Node gets disconnected and rejoins
<i>509</i>&nbsp;                     * 3) Master assigns the shard back to the node
<i>510</i>&nbsp;                     * 4) Master processes the shard started and starts the shard
<i>511</i>&nbsp;                     * 5) The node process the cluster state where the shard is both started and primary term is incremented.
<i>512</i>&nbsp;                     *
<i>513</i>&nbsp;                     * We could fail the shard in that case, but this will cause it to be removed from the insync allocations list
<i>514</i>&nbsp;                     * potentially preventing re-allocation.
<i>515</i>&nbsp;                     */
<b class="nc"><i>516</i>&nbsp;                    assert newRouting.initializing() == false :</b>
<i>517</i>&nbsp;                        &quot;a started primary shard should never update its term; &quot;
<i>518</i>&nbsp;                            + &quot;shard &quot; + newRouting + &quot;, &quot;
<i>519</i>&nbsp;                            + &quot;current term [&quot; + pendingPrimaryTerm + &quot;], &quot;
<i>520</i>&nbsp;                            + &quot;new term [&quot; + newPrimaryTerm + &quot;]&quot;;
<b class="nc"><i>521</i>&nbsp;                    assert newPrimaryTerm &gt; pendingPrimaryTerm :</b>
<i>522</i>&nbsp;                        &quot;primary terms can only go up; current term [&quot; + pendingPrimaryTerm + &quot;], new term [&quot; + newPrimaryTerm + &quot;]&quot;;
<i>523</i>&nbsp;                    /*
<i>524</i>&nbsp;                     * Before this call returns, we are guaranteed that all future operations are delayed and so this happens before we
<i>525</i>&nbsp;                     * increment the primary term. The latch is needed to ensure that we do not unblock operations before the primary
<i>526</i>&nbsp;                     * term is incremented.
<i>527</i>&nbsp;                     */
<i>528</i>&nbsp;                    // to prevent primary relocation handoff while resync is not completed
<b class="nc"><i>529</i>&nbsp;                    boolean resyncStarted = primaryReplicaResyncInProgress.compareAndSet(false, true);</b>
<b class="nc"><i>530</i>&nbsp;                    if (resyncStarted == false) {</b>
<b class="nc"><i>531</i>&nbsp;                        throw new IllegalStateException(&quot;cannot start resync while it&#39;s already in progress&quot;);</b>
<i>532</i>&nbsp;                    }
<b class="nc"><i>533</i>&nbsp;                    bumpPrimaryTerm(newPrimaryTerm,</b>
<i>534</i>&nbsp;                        () -&gt; {
<b class="nc"><i>535</i>&nbsp;                            shardStateUpdated.await();</b>
<b class="nc"><i>536</i>&nbsp;                            assert pendingPrimaryTerm == newPrimaryTerm :</b>
<i>537</i>&nbsp;                                &quot;shard term changed on primary. expected [&quot; + newPrimaryTerm + &quot;] but was [&quot; + pendingPrimaryTerm + &quot;]&quot; +
<i>538</i>&nbsp;                                &quot;, current routing: &quot; + currentRouting + &quot;, new routing: &quot; + newRouting;
<b class="nc"><i>539</i>&nbsp;                            assert getOperationPrimaryTerm() == newPrimaryTerm;</b>
<i>540</i>&nbsp;                            try {
<b class="nc"><i>541</i>&nbsp;                                replicationTracker.activatePrimaryMode(getLocalCheckpoint());</b>
<b class="nc"><i>542</i>&nbsp;                                ensurePeerRecoveryRetentionLeasesExist();</b>
<i>543</i>&nbsp;                                /*
<i>544</i>&nbsp;                                 * If this shard was serving as a replica shard when another shard was promoted to primary then
<i>545</i>&nbsp;                                 * its Lucene index was reset during the primary term transition. In particular, the Lucene index
<i>546</i>&nbsp;                                 * on this shard was reset to the global checkpoint and the operations above the local checkpoint
<i>547</i>&nbsp;                                 * were reverted. If the other shard that was promoted to primary subsequently fails before the
<i>548</i>&nbsp;                                 * primary/replica re-sync completes successfully and we are now being promoted, we have to restore
<i>549</i>&nbsp;                                 * the reverted operations on this shard by replaying the translog to avoid losing acknowledged writes.
<i>550</i>&nbsp;                                 */
<b class="nc"><i>551</i>&nbsp;                                final Engine engine = getEngine();</b>
<b class="nc"><i>552</i>&nbsp;                                engine.restoreLocalHistoryFromTranslog((resettingEngine, snapshot) -&gt;</b>
<b class="nc"><i>553</i>&nbsp;                                    runTranslogRecovery(resettingEngine, snapshot, Engine.Operation.Origin.LOCAL_RESET, () -&gt; {}));</b>
<i>554</i>&nbsp;                                /* Rolling the translog generation is not strictly needed here (as we will never have collisions between
<i>555</i>&nbsp;                                 * sequence numbers in a translog generation in a new primary as it takes the last known sequence number
<i>556</i>&nbsp;                                 * as a starting point), but it simplifies reasoning about the relationship between primary terms and
<i>557</i>&nbsp;                                 * translog generations.
<i>558</i>&nbsp;                                 */
<b class="nc"><i>559</i>&nbsp;                                engine.rollTranslogGeneration();</b>
<b class="nc"><i>560</i>&nbsp;                                engine.fillSeqNoGaps(newPrimaryTerm);</b>
<b class="nc"><i>561</i>&nbsp;                                replicationTracker.updateLocalCheckpoint(currentRouting.allocationId().getId(),</b>
<b class="nc"><i>562</i>&nbsp;                                    getLocalCheckpoint());</b>
<b class="nc"><i>563</i>&nbsp;                                primaryReplicaSyncer.accept(this, new ActionListener&lt;ResyncTask&gt;() {</b>
<i>564</i>&nbsp;                                    @Override
<i>565</i>&nbsp;                                    public void onResponse(ResyncTask resyncTask) {
<i>566</i>&nbsp;                                        logger.info(&quot;primary-replica resync completed with {} operations&quot;,
<i>567</i>&nbsp;                                            resyncTask.getResyncedOperations());
<i>568</i>&nbsp;                                        boolean resyncCompleted =
<i>569</i>&nbsp;                                            primaryReplicaResyncInProgress.compareAndSet(true, false);
<i>570</i>&nbsp;                                        assert resyncCompleted : &quot;primary-replica resync finished but was not started&quot;;
<i>571</i>&nbsp;                                    }
<i>572</i>&nbsp;
<i>573</i>&nbsp;                                    @Override
<i>574</i>&nbsp;                                    public void onFailure(Exception e) {
<i>575</i>&nbsp;                                        boolean resyncCompleted =
<i>576</i>&nbsp;                                            primaryReplicaResyncInProgress.compareAndSet(true, false);
<i>577</i>&nbsp;                                        assert resyncCompleted : &quot;primary-replica resync finished but was not started&quot;;
<i>578</i>&nbsp;                                        if (state == IndexShardState.CLOSED) {
<i>579</i>&nbsp;                                            // ignore, shutting down
<i>580</i>&nbsp;                                        } else {
<i>581</i>&nbsp;                                            failShard(&quot;exception during primary-replica resync&quot;, e);
<i>582</i>&nbsp;                                        }
<i>583</i>&nbsp;                                    }
<i>584</i>&nbsp;                                });
<b class="nc"><i>585</i>&nbsp;                            } catch (final AlreadyClosedException e) {</b>
<i>586</i>&nbsp;                                // okay, the index was deleted
<b class="nc"><i>587</i>&nbsp;                            }</b>
<b class="nc"><i>588</i>&nbsp;                        }, null);</b>
<i>589</i>&nbsp;                }
<i>590</i>&nbsp;            }
<i>591</i>&nbsp;            // set this last, once we finished updating all internal state.
<b class="fc"><i>592</i>&nbsp;            this.shardRouting = newRouting;</b>
<i>593</i>&nbsp;
<b class="fc"><i>594</i>&nbsp;            assert this.shardRouting.primary() == false ||</b>
<b class="fc"><i>595</i>&nbsp;                this.shardRouting.started() == false || // note that we use started and not active to avoid relocating shards</b>
<b class="fc"><i>596</i>&nbsp;                this.indexShardOperationPermits.isBlocked() || // if permits are blocked, we are still transitioning</b>
<b class="fc"><i>597</i>&nbsp;                this.replicationTracker.isPrimaryMode()</b>
<i>598</i>&nbsp;                : &quot;a started primary with non-pending operation term must be in primary mode &quot; + this.shardRouting;
<b class="fc"><i>599</i>&nbsp;            shardStateUpdated.countDown();</b>
<b class="fc"><i>600</i>&nbsp;        }</b>
<b class="fc"><i>601</i>&nbsp;        if (currentRouting.active() == false &amp;&amp; newRouting.active()) {</b>
<b class="fc"><i>602</i>&nbsp;            indexEventListener.afterIndexShardStarted(this);</b>
<i>603</i>&nbsp;        }
<b class="fc"><i>604</i>&nbsp;        if (newRouting.equals(currentRouting) == false) {</b>
<b class="fc"><i>605</i>&nbsp;            indexEventListener.shardRoutingChanged(this, currentRouting, newRouting);</b>
<i>606</i>&nbsp;        }
<i>607</i>&nbsp;
<b class="fc"><i>608</i>&nbsp;        if (indexSettings.isSoftDeleteEnabled() &amp;&amp; useRetentionLeasesInPeerRecovery == false) {</b>
<b class="nc"><i>609</i>&nbsp;            final RetentionLeases retentionLeases = replicationTracker.getRetentionLeases();</b>
<b class="nc"><i>610</i>&nbsp;            final Set&lt;ShardRouting&gt; shardRoutings = new HashSet&lt;&gt;(routingTable.getShards());</b>
<b class="nc"><i>611</i>&nbsp;            shardRoutings.addAll(routingTable.assignedShards()); // include relocation targets</b>
<b class="nc"><i>612</i>&nbsp;            if (shardRoutings.stream().allMatch(</b>
<b class="nc"><i>613</i>&nbsp;                shr -&gt; shr.assignedToNode() &amp;&amp; retentionLeases.contains(ReplicationTracker.getPeerRecoveryRetentionLeaseId(shr)))) {</b>
<b class="nc"><i>614</i>&nbsp;                useRetentionLeasesInPeerRecovery = true;</b>
<b class="nc"><i>615</i>&nbsp;                turnOffTranslogRetention();</b>
<i>616</i>&nbsp;            }
<i>617</i>&nbsp;        }
<b class="fc"><i>618</i>&nbsp;    }</b>
<i>619</i>&nbsp;
<i>620</i>&nbsp;    /**
<i>621</i>&nbsp;     * Marks the shard as recovering based on a recovery state, fails with exception is recovering is not allowed to be set.
<i>622</i>&nbsp;     */
<i>623</i>&nbsp;    public IndexShardState markAsRecovering(String reason, RecoveryState recoveryState) throws IndexShardStartedException,
<i>624</i>&nbsp;        IndexShardRelocatedException, IndexShardRecoveringException, IndexShardClosedException {
<b class="fc"><i>625</i>&nbsp;        synchronized (mutex) {</b>
<b class="fc"><i>626</i>&nbsp;            if (state == IndexShardState.CLOSED) {</b>
<b class="nc"><i>627</i>&nbsp;                throw new IndexShardClosedException(shardId);</b>
<i>628</i>&nbsp;            }
<b class="fc"><i>629</i>&nbsp;            if (state == IndexShardState.STARTED) {</b>
<b class="nc"><i>630</i>&nbsp;                throw new IndexShardStartedException(shardId);</b>
<i>631</i>&nbsp;            }
<b class="fc"><i>632</i>&nbsp;            if (state == IndexShardState.RECOVERING) {</b>
<b class="nc"><i>633</i>&nbsp;                throw new IndexShardRecoveringException(shardId);</b>
<i>634</i>&nbsp;            }
<b class="fc"><i>635</i>&nbsp;            if (state == IndexShardState.POST_RECOVERY) {</b>
<b class="nc"><i>636</i>&nbsp;                throw new IndexShardRecoveringException(shardId);</b>
<i>637</i>&nbsp;            }
<b class="fc"><i>638</i>&nbsp;            this.recoveryState = recoveryState;</b>
<b class="fc"><i>639</i>&nbsp;            return changeState(IndexShardState.RECOVERING, reason);</b>
<b class="nc"><i>640</i>&nbsp;        }</b>
<i>641</i>&nbsp;    }
<i>642</i>&nbsp;
<b class="fc"><i>643</i>&nbsp;    private final AtomicBoolean primaryReplicaResyncInProgress = new AtomicBoolean();</b>
<i>644</i>&nbsp;
<i>645</i>&nbsp;    /**
<i>646</i>&nbsp;     * Completes the relocation. Operations are blocked and current operations are drained before changing state to relocated. The provided
<i>647</i>&nbsp;     * {@link Runnable} is executed after all operations are successfully blocked.
<i>648</i>&nbsp;     *
<i>649</i>&nbsp;     * @param consumer a {@link Runnable} that is executed after operations are blocked
<i>650</i>&nbsp;     * @throws IllegalIndexShardStateException if the shard is not relocating due to concurrent cancellation
<i>651</i>&nbsp;     * @throws IllegalStateException           if the relocation target is no longer part of the replication group
<i>652</i>&nbsp;     * @throws InterruptedException            if blocking operations is interrupted
<i>653</i>&nbsp;     */
<i>654</i>&nbsp;    public void relocated(final String targetAllocationId, final Consumer&lt;ReplicationTracker.PrimaryContext&gt; consumer)
<i>655</i>&nbsp;        throws IllegalIndexShardStateException, IllegalStateException, InterruptedException {
<b class="nc"><i>656</i>&nbsp;        assert shardRouting.primary() : &quot;only primaries can be marked as relocated: &quot; + shardRouting;</b>
<b class="nc"><i>657</i>&nbsp;        try (Releasable forceRefreshes = refreshListeners.forceRefreshes()) {</b>
<b class="nc"><i>658</i>&nbsp;            indexShardOperationPermits.blockOperations(30, TimeUnit.MINUTES, () -&gt; {</b>
<b class="nc"><i>659</i>&nbsp;                forceRefreshes.close();</b>
<i>660</i>&nbsp;                // no shard operation permits are being held here, move state from started to relocated
<b class="nc"><i>661</i>&nbsp;                assert indexShardOperationPermits.getActiveOperationsCount() == OPERATIONS_BLOCKED :</b>
<i>662</i>&nbsp;                        &quot;in-flight operations in progress while moving shard state to relocated&quot;;
<i>663</i>&nbsp;                /*
<i>664</i>&nbsp;                 * We should not invoke the runnable under the mutex as the expected implementation is to handoff the primary context via a
<i>665</i>&nbsp;                 * network operation. Doing this under the mutex can implicitly block the cluster state update thread on network operations.
<i>666</i>&nbsp;                 */
<b class="nc"><i>667</i>&nbsp;                verifyRelocatingState();</b>
<b class="nc"><i>668</i>&nbsp;                final ReplicationTracker.PrimaryContext primaryContext = replicationTracker.startRelocationHandoff(targetAllocationId);</b>
<i>669</i>&nbsp;                try {
<b class="nc"><i>670</i>&nbsp;                    consumer.accept(primaryContext);</b>
<b class="nc"><i>671</i>&nbsp;                    synchronized (mutex) {</b>
<b class="nc"><i>672</i>&nbsp;                        verifyRelocatingState();</b>
<b class="nc"><i>673</i>&nbsp;                        replicationTracker.completeRelocationHandoff(); // make changes to primaryMode and relocated flag only under mutex</b>
<b class="nc"><i>674</i>&nbsp;                    }</b>
<b class="nc"><i>675</i>&nbsp;                } catch (final Exception e) {</b>
<i>676</i>&nbsp;                    try {
<b class="nc"><i>677</i>&nbsp;                        replicationTracker.abortRelocationHandoff();</b>
<b class="nc"><i>678</i>&nbsp;                    } catch (final Exception inner) {</b>
<b class="nc"><i>679</i>&nbsp;                        e.addSuppressed(inner);</b>
<b class="nc"><i>680</i>&nbsp;                    }</b>
<b class="nc"><i>681</i>&nbsp;                    throw e;</b>
<b class="nc"><i>682</i>&nbsp;                }</b>
<b class="nc"><i>683</i>&nbsp;            });</b>
<b class="nc"><i>684</i>&nbsp;        } catch (TimeoutException e) {</b>
<b class="nc"><i>685</i>&nbsp;            logger.warn(&quot;timed out waiting for relocation hand-off to complete&quot;);</b>
<i>686</i>&nbsp;            // This is really bad as ongoing replication operations are preventing this shard from completing relocation hand-off.
<i>687</i>&nbsp;            // Fail primary relocation source and target shards.
<b class="nc"><i>688</i>&nbsp;            failShard(&quot;timed out waiting for relocation hand-off to complete&quot;, null);</b>
<b class="nc"><i>689</i>&nbsp;            throw new IndexShardClosedException(shardId(), &quot;timed out waiting for relocation hand-off to complete&quot;);</b>
<b class="nc"><i>690</i>&nbsp;        }</b>
<b class="nc"><i>691</i>&nbsp;    }</b>
<i>692</i>&nbsp;
<i>693</i>&nbsp;    private void verifyRelocatingState() {
<b class="nc"><i>694</i>&nbsp;        if (state != IndexShardState.STARTED) {</b>
<b class="nc"><i>695</i>&nbsp;            throw new IndexShardNotStartedException(shardId, state);</b>
<i>696</i>&nbsp;        }
<i>697</i>&nbsp;        /*
<i>698</i>&nbsp;         * If the master cancelled recovery, the target will be removed and the recovery will be cancelled. However, it is still possible
<i>699</i>&nbsp;         * that we concurrently end up here and therefore have to protect that we do not mark the shard as relocated when its shard routing
<i>700</i>&nbsp;         * says otherwise.
<i>701</i>&nbsp;         */
<i>702</i>&nbsp;
<b class="nc"><i>703</i>&nbsp;        if (shardRouting.relocating() == false) {</b>
<b class="nc"><i>704</i>&nbsp;            throw new IllegalIndexShardStateException(shardId, IndexShardState.STARTED,</b>
<i>705</i>&nbsp;                &quot;: shard is no longer relocating &quot; + shardRouting);
<i>706</i>&nbsp;        }
<i>707</i>&nbsp;
<b class="nc"><i>708</i>&nbsp;        if (primaryReplicaResyncInProgress.get()) {</b>
<b class="nc"><i>709</i>&nbsp;            throw new IllegalIndexShardStateException(shardId, IndexShardState.STARTED,</b>
<i>710</i>&nbsp;                &quot;: primary relocation is forbidden while primary-replica resync is in progress &quot; + shardRouting);
<i>711</i>&nbsp;        }
<b class="nc"><i>712</i>&nbsp;    }</b>
<i>713</i>&nbsp;
<i>714</i>&nbsp;    @Override
<i>715</i>&nbsp;    public IndexShardState state() {
<b class="fc"><i>716</i>&nbsp;        return state;</b>
<i>717</i>&nbsp;    }
<i>718</i>&nbsp;
<i>719</i>&nbsp;    /**
<i>720</i>&nbsp;     * Changes the state of the current shard
<i>721</i>&nbsp;     *
<i>722</i>&nbsp;     * @param newState the new shard state
<i>723</i>&nbsp;     * @param reason   the reason for the state change
<i>724</i>&nbsp;     * @return the previous shard state
<i>725</i>&nbsp;     */
<i>726</i>&nbsp;    private IndexShardState changeState(IndexShardState newState, String reason) {
<b class="fc"><i>727</i>&nbsp;        assert Thread.holdsLock(mutex);</b>
<b class="fc"><i>728</i>&nbsp;        logger.debug(&quot;state: [{}]-&gt;[{}], reason [{}]&quot;, state, newState, reason);</b>
<b class="fc"><i>729</i>&nbsp;        IndexShardState previousState = state;</b>
<b class="fc"><i>730</i>&nbsp;        state = newState;</b>
<b class="fc"><i>731</i>&nbsp;        this.indexEventListener.indexShardStateChanged(this, previousState, newState, reason);</b>
<b class="fc"><i>732</i>&nbsp;        return previousState;</b>
<i>733</i>&nbsp;    }
<i>734</i>&nbsp;
<i>735</i>&nbsp;    public Engine.IndexResult applyIndexOperationOnPrimary(long version, VersionType versionType, SourceToParse sourceToParse,
<i>736</i>&nbsp;                                                           long ifSeqNo, long ifPrimaryTerm, long autoGeneratedTimestamp,
<i>737</i>&nbsp;                                                           boolean isRetry)
<i>738</i>&nbsp;        throws IOException {
<b class="nc"><i>739</i>&nbsp;        assert versionType.validateVersionForWrites(version);</b>
<b class="nc"><i>740</i>&nbsp;        return applyIndexOperation(getEngine(), UNASSIGNED_SEQ_NO, getOperationPrimaryTerm(), version, versionType, ifSeqNo,</b>
<i>741</i>&nbsp;            ifPrimaryTerm, autoGeneratedTimestamp, isRetry, Engine.Operation.Origin.PRIMARY, sourceToParse);
<i>742</i>&nbsp;    }
<i>743</i>&nbsp;
<i>744</i>&nbsp;    public Engine.IndexResult applyIndexOperationOnReplica(long seqNo, long version, long autoGeneratedTimeStamp,
<i>745</i>&nbsp;                                                           boolean isRetry, SourceToParse sourceToParse)
<i>746</i>&nbsp;        throws IOException {
<b class="nc"><i>747</i>&nbsp;        return applyIndexOperation(getEngine(), seqNo, getOperationPrimaryTerm(), version, null, UNASSIGNED_SEQ_NO, 0,</b>
<i>748</i>&nbsp;            autoGeneratedTimeStamp, isRetry, Engine.Operation.Origin.REPLICA, sourceToParse);
<i>749</i>&nbsp;    }
<i>750</i>&nbsp;
<i>751</i>&nbsp;    private Engine.IndexResult applyIndexOperation(Engine engine, long seqNo, long opPrimaryTerm, long version,
<i>752</i>&nbsp;                                                   @Nullable VersionType versionType, long ifSeqNo, long ifPrimaryTerm,
<i>753</i>&nbsp;                                                   long autoGeneratedTimeStamp, boolean isRetry, Engine.Operation.Origin origin,
<i>754</i>&nbsp;                                                   SourceToParse sourceToParse) throws IOException {
<b class="nc"><i>755</i>&nbsp;        assert opPrimaryTerm &lt;= getOperationPrimaryTerm()</b>
<b class="nc"><i>756</i>&nbsp;                : &quot;op term [ &quot; + opPrimaryTerm + &quot; ] &gt; shard term [&quot; + getOperationPrimaryTerm() + &quot;]&quot;;</b>
<b class="nc"><i>757</i>&nbsp;        ensureWriteAllowed(origin);</b>
<i>758</i>&nbsp;        Engine.Index operation;
<i>759</i>&nbsp;        try {
<b class="nc"><i>760</i>&nbsp;            final String resolvedType = mapperService.resolveDocumentType(sourceToParse.type());</b>
<i>761</i>&nbsp;            final SourceToParse sourceWithResolvedType;
<b class="nc"><i>762</i>&nbsp;            if (resolvedType.equals(sourceToParse.type())) {</b>
<b class="nc"><i>763</i>&nbsp;                sourceWithResolvedType = sourceToParse;</b>
<i>764</i>&nbsp;            } else {
<b class="nc"><i>765</i>&nbsp;                sourceWithResolvedType = new SourceToParse(sourceToParse.index(), resolvedType, sourceToParse.id(),</b>
<b class="nc"><i>766</i>&nbsp;                    sourceToParse.source(), sourceToParse.getXContentType(), sourceToParse.routing());</b>
<i>767</i>&nbsp;            }
<b class="nc"><i>768</i>&nbsp;            operation = prepareIndex(docMapper(resolvedType), sourceWithResolvedType,</b>
<i>769</i>&nbsp;                seqNo, opPrimaryTerm, version, versionType, origin, autoGeneratedTimeStamp, isRetry, ifSeqNo, ifPrimaryTerm);
<b class="nc"><i>770</i>&nbsp;            Mapping update = operation.parsedDoc().dynamicMappingsUpdate();</b>
<b class="nc"><i>771</i>&nbsp;            if (update != null) {</b>
<b class="nc"><i>772</i>&nbsp;                return new Engine.IndexResult(update);</b>
<i>773</i>&nbsp;            }
<b class="nc"><i>774</i>&nbsp;        } catch (Exception e) {</b>
<i>775</i>&nbsp;            // We treat any exception during parsing and or mapping update as a document level failure
<i>776</i>&nbsp;            // with the exception side effects of closing the shard. Since we don&#39;t have the shard, we
<i>777</i>&nbsp;            // can not raise an exception that may block any replication of previous operations to the
<i>778</i>&nbsp;            // replicas
<b class="nc"><i>779</i>&nbsp;            verifyNotClosed(e);</b>
<b class="nc"><i>780</i>&nbsp;            return new Engine.IndexResult(e, version, opPrimaryTerm, seqNo);</b>
<b class="nc"><i>781</i>&nbsp;        }</b>
<i>782</i>&nbsp;
<b class="nc"><i>783</i>&nbsp;        return index(engine, operation);</b>
<i>784</i>&nbsp;    }
<i>785</i>&nbsp;
<i>786</i>&nbsp;    public static Engine.Index prepareIndex(DocumentMapperForType docMapper, SourceToParse source, long seqNo,
<i>787</i>&nbsp;                                            long primaryTerm, long version, VersionType versionType, Engine.Operation.Origin origin,
<i>788</i>&nbsp;                                            long autoGeneratedIdTimestamp, boolean isRetry,
<i>789</i>&nbsp;                                            long ifSeqNo, long ifPrimaryTerm) {
<b class="nc"><i>790</i>&nbsp;        long startTime = System.nanoTime();</b>
<b class="nc"><i>791</i>&nbsp;        ParsedDocument doc = docMapper.getDocumentMapper().parse(source);</b>
<b class="nc"><i>792</i>&nbsp;        if (docMapper.getMapping() != null) {</b>
<b class="nc"><i>793</i>&nbsp;            doc.addDynamicMappingsUpdate(docMapper.getMapping());</b>
<i>794</i>&nbsp;        }
<b class="nc"><i>795</i>&nbsp;        Term uid = new Term(IdFieldMapper.NAME, Uid.encodeId(doc.id()));</b>
<b class="nc"><i>796</i>&nbsp;        return new Engine.Index(uid, doc, seqNo, primaryTerm, version, versionType, origin, startTime, autoGeneratedIdTimestamp, isRetry,</b>
<i>797</i>&nbsp;            ifSeqNo, ifPrimaryTerm);
<i>798</i>&nbsp;    }
<i>799</i>&nbsp;
<i>800</i>&nbsp;    private Engine.IndexResult index(Engine engine, Engine.Index index) throws IOException {
<b class="nc"><i>801</i>&nbsp;        active.set(true);</b>
<i>802</i>&nbsp;        final Engine.IndexResult result;
<b class="nc"><i>803</i>&nbsp;        index = indexingOperationListeners.preIndex(shardId, index);</b>
<i>804</i>&nbsp;        try {
<b class="nc"><i>805</i>&nbsp;            if (logger.isTraceEnabled()) {</b>
<i>806</i>&nbsp;                // don&#39;t use index.source().utf8ToString() here source might not be valid UTF-8
<b class="nc"><i>807</i>&nbsp;                logger.trace(&quot;index [{}][{}] seq# [{}] allocation-id [{}] primaryTerm [{}] operationPrimaryTerm [{}] origin [{}]&quot;,</b>
<b class="nc"><i>808</i>&nbsp;                    index.type(), index.id(), index.seqNo(), routingEntry().allocationId(), index.primaryTerm(), getOperationPrimaryTerm(),</b>
<b class="nc"><i>809</i>&nbsp;                    index.origin());</b>
<i>810</i>&nbsp;            }
<b class="nc"><i>811</i>&nbsp;            result = engine.index(index);</b>
<b class="nc"><i>812</i>&nbsp;            if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>813</i>&nbsp;                logger.trace(&quot;index-done [{}][{}] seq# [{}] allocation-id [{}] primaryTerm [{}] operationPrimaryTerm [{}] origin [{}] &quot; +</b>
<i>814</i>&nbsp;                        &quot;result-seq# [{}] result-term [{}] failure [{}]&quot;,
<b class="nc"><i>815</i>&nbsp;                    index.type(), index.id(), index.seqNo(), routingEntry().allocationId(), index.primaryTerm(), getOperationPrimaryTerm(),</b>
<b class="nc"><i>816</i>&nbsp;                    index.origin(), result.getSeqNo(), result.getTerm(), result.getFailure());</b>
<i>817</i>&nbsp;            }
<b class="nc"><i>818</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>819</i>&nbsp;            if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>820</i>&nbsp;                logger.trace(new ParameterizedMessage(</b>
<i>821</i>&nbsp;                    &quot;index-fail [{}][{}] seq# [{}] allocation-id [{}] primaryTerm [{}] operationPrimaryTerm [{}] origin [{}]&quot;,
<b class="nc"><i>822</i>&nbsp;                    index.type(), index.id(), index.seqNo(), routingEntry().allocationId(), index.primaryTerm(), getOperationPrimaryTerm(),</b>
<b class="nc"><i>823</i>&nbsp;                    index.origin()</b>
<i>824</i>&nbsp;                ), e);
<i>825</i>&nbsp;            }
<b class="nc"><i>826</i>&nbsp;            indexingOperationListeners.postIndex(shardId, index, e);</b>
<b class="nc"><i>827</i>&nbsp;            throw e;</b>
<b class="nc"><i>828</i>&nbsp;        }</b>
<b class="nc"><i>829</i>&nbsp;        indexingOperationListeners.postIndex(shardId, index, result);</b>
<b class="nc"><i>830</i>&nbsp;        return result;</b>
<i>831</i>&nbsp;    }
<i>832</i>&nbsp;
<i>833</i>&nbsp;    public Engine.NoOpResult markSeqNoAsNoop(long seqNo, String reason) throws IOException {
<b class="nc"><i>834</i>&nbsp;        return markSeqNoAsNoop(getEngine(), seqNo, getOperationPrimaryTerm(), reason, Engine.Operation.Origin.REPLICA);</b>
<i>835</i>&nbsp;    }
<i>836</i>&nbsp;
<i>837</i>&nbsp;    private Engine.NoOpResult markSeqNoAsNoop(Engine engine, long seqNo, long opPrimaryTerm, String reason,
<i>838</i>&nbsp;                                              Engine.Operation.Origin origin) throws IOException {
<b class="nc"><i>839</i>&nbsp;        assert opPrimaryTerm &lt;= getOperationPrimaryTerm()</b>
<b class="nc"><i>840</i>&nbsp;                : &quot;op term [ &quot; + opPrimaryTerm + &quot; ] &gt; shard term [&quot; + getOperationPrimaryTerm() + &quot;]&quot;;</b>
<b class="nc"><i>841</i>&nbsp;        long startTime = System.nanoTime();</b>
<b class="nc"><i>842</i>&nbsp;        ensureWriteAllowed(origin);</b>
<b class="nc"><i>843</i>&nbsp;        final Engine.NoOp noOp = new Engine.NoOp(seqNo, opPrimaryTerm, origin, startTime, reason);</b>
<b class="nc"><i>844</i>&nbsp;        return noOp(engine, noOp);</b>
<i>845</i>&nbsp;    }
<i>846</i>&nbsp;
<i>847</i>&nbsp;    private Engine.NoOpResult noOp(Engine engine, Engine.NoOp noOp) throws IOException {
<b class="nc"><i>848</i>&nbsp;        active.set(true);</b>
<b class="nc"><i>849</i>&nbsp;        if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>850</i>&nbsp;            logger.trace(&quot;noop (seq# [{}])&quot;, noOp.seqNo());</b>
<i>851</i>&nbsp;        }
<b class="nc"><i>852</i>&nbsp;        return engine.noOp(noOp);</b>
<i>853</i>&nbsp;    }
<i>854</i>&nbsp;
<i>855</i>&nbsp;    public Engine.IndexResult getFailedIndexResult(Exception e, long version) {
<b class="nc"><i>856</i>&nbsp;        return new Engine.IndexResult(e, version);</b>
<i>857</i>&nbsp;    }
<i>858</i>&nbsp;
<i>859</i>&nbsp;    public Engine.DeleteResult getFailedDeleteResult(Exception e, long version) {
<b class="nc"><i>860</i>&nbsp;        return new Engine.DeleteResult(e, version, getOperationPrimaryTerm());</b>
<i>861</i>&nbsp;    }
<i>862</i>&nbsp;
<i>863</i>&nbsp;    public Engine.DeleteResult applyDeleteOperationOnPrimary(long version, String type, String id, VersionType versionType,
<i>864</i>&nbsp;                                                             long ifSeqNo, long ifPrimaryTerm)
<i>865</i>&nbsp;        throws IOException {
<b class="nc"><i>866</i>&nbsp;        assert versionType.validateVersionForWrites(version);</b>
<b class="nc"><i>867</i>&nbsp;        return applyDeleteOperation(getEngine(), UNASSIGNED_SEQ_NO, getOperationPrimaryTerm(), version, type, id, versionType,</b>
<i>868</i>&nbsp;            ifSeqNo, ifPrimaryTerm, Engine.Operation.Origin.PRIMARY);
<i>869</i>&nbsp;    }
<i>870</i>&nbsp;
<i>871</i>&nbsp;    public Engine.DeleteResult applyDeleteOperationOnReplica(long seqNo, long version, String type, String id) throws IOException {
<b class="nc"><i>872</i>&nbsp;        return applyDeleteOperation(</b>
<b class="nc"><i>873</i>&nbsp;            getEngine(), seqNo, getOperationPrimaryTerm(), version, type, id, null, UNASSIGNED_SEQ_NO, 0, Engine.Operation.Origin.REPLICA);</b>
<i>874</i>&nbsp;    }
<i>875</i>&nbsp;
<i>876</i>&nbsp;    private Engine.DeleteResult applyDeleteOperation(Engine engine, long seqNo, long opPrimaryTerm, long version, String type, String id,
<i>877</i>&nbsp;                                                     @Nullable VersionType versionType, long ifSeqNo, long ifPrimaryTerm,
<i>878</i>&nbsp;                                                     Engine.Operation.Origin origin) throws IOException {
<b class="nc"><i>879</i>&nbsp;        assert opPrimaryTerm &lt;= getOperationPrimaryTerm()</b>
<b class="nc"><i>880</i>&nbsp;                : &quot;op term [ &quot; + opPrimaryTerm + &quot; ] &gt; shard term [&quot; + getOperationPrimaryTerm() + &quot;]&quot;;</b>
<b class="nc"><i>881</i>&nbsp;        ensureWriteAllowed(origin);</b>
<i>882</i>&nbsp;        // When there is a single type, the unique identifier is only composed of the _id,
<i>883</i>&nbsp;        // so there is no way to differentiate foo#1 from bar#1. This is especially an issue
<i>884</i>&nbsp;        // if a user first deletes foo#1 and then indexes bar#1: since we do not encode the
<i>885</i>&nbsp;        // _type in the uid it might look like we are reindexing the same document, which
<i>886</i>&nbsp;        // would fail if bar#1 is indexed with a lower version than foo#1 was deleted with.
<i>887</i>&nbsp;        // In order to work around this issue, we make deletions create types. This way, we
<i>888</i>&nbsp;        // fail if index and delete operations do not use the same type.
<i>889</i>&nbsp;        // TODO: clean this up when types are gone
<i>890</i>&nbsp;        try {
<b class="nc"><i>891</i>&nbsp;            Mapping update = docMapper(type).getMapping();</b>
<b class="nc"><i>892</i>&nbsp;            if (update != null) {</b>
<b class="nc"><i>893</i>&nbsp;                return new Engine.DeleteResult(update);</b>
<i>894</i>&nbsp;            }
<b class="nc"><i>895</i>&nbsp;        } catch (MapperParsingException | IllegalArgumentException | TypeMissingException e) {</b>
<b class="nc"><i>896</i>&nbsp;            return new Engine.DeleteResult(e, version, getOperationPrimaryTerm(), seqNo, false);</b>
<b class="nc"><i>897</i>&nbsp;        }</b>
<b class="nc"><i>898</i>&nbsp;        if (mapperService.resolveDocumentType(type).equals(mapperService.documentMapper().type()) == false) {</b>
<i>899</i>&nbsp;            // We should never get there due to the fact that we generate mapping updates on deletes,
<i>900</i>&nbsp;            // but we still prefer to have a hard exception here as we would otherwise delete a
<i>901</i>&nbsp;            // document in the wrong type.
<b class="nc"><i>902</i>&nbsp;            throw new IllegalStateException(&quot;Deleting document from type [&quot; +</b>
<b class="nc"><i>903</i>&nbsp;                    mapperService.resolveDocumentType(type) + &quot;] while current type is [&quot; +</b>
<b class="nc"><i>904</i>&nbsp;                    mapperService.documentMapper().type() + &quot;]&quot;);</b>
<i>905</i>&nbsp;        }
<b class="nc"><i>906</i>&nbsp;        final Term uid = new Term(IdFieldMapper.NAME, Uid.encodeId(id));</b>
<b class="nc"><i>907</i>&nbsp;        final Engine.Delete delete = prepareDelete(type, id, uid, seqNo, opPrimaryTerm, version,</b>
<i>908</i>&nbsp;            versionType, origin, ifSeqNo, ifPrimaryTerm);
<b class="nc"><i>909</i>&nbsp;        return delete(engine, delete);</b>
<i>910</i>&nbsp;    }
<i>911</i>&nbsp;
<i>912</i>&nbsp;    private Engine.Delete prepareDelete(String type, String id, Term uid, long seqNo, long primaryTerm, long version,
<i>913</i>&nbsp;                                               VersionType versionType, Engine.Operation.Origin origin,
<i>914</i>&nbsp;                                               long ifSeqNo, long ifPrimaryTerm) {
<b class="nc"><i>915</i>&nbsp;        long startTime = System.nanoTime();</b>
<b class="nc"><i>916</i>&nbsp;        return new Engine.Delete(mapperService.resolveDocumentType(type), id, uid, seqNo, primaryTerm, version, versionType,</b>
<i>917</i>&nbsp;            origin, startTime, ifSeqNo, ifPrimaryTerm);
<i>918</i>&nbsp;    }
<i>919</i>&nbsp;
<i>920</i>&nbsp;    private Engine.DeleteResult delete(Engine engine, Engine.Delete delete) throws IOException {
<b class="nc"><i>921</i>&nbsp;        active.set(true);</b>
<i>922</i>&nbsp;        final Engine.DeleteResult result;
<b class="nc"><i>923</i>&nbsp;        delete = indexingOperationListeners.preDelete(shardId, delete);</b>
<i>924</i>&nbsp;        try {
<b class="nc"><i>925</i>&nbsp;            if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>926</i>&nbsp;                logger.trace(&quot;delete [{}] (seq no [{}])&quot;, delete.uid().text(), delete.seqNo());</b>
<i>927</i>&nbsp;            }
<b class="nc"><i>928</i>&nbsp;            result = engine.delete(delete);</b>
<b class="nc"><i>929</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>930</i>&nbsp;            indexingOperationListeners.postDelete(shardId, delete, e);</b>
<b class="nc"><i>931</i>&nbsp;            throw e;</b>
<b class="nc"><i>932</i>&nbsp;        }</b>
<b class="nc"><i>933</i>&nbsp;        indexingOperationListeners.postDelete(shardId, delete, result);</b>
<b class="nc"><i>934</i>&nbsp;        return result;</b>
<i>935</i>&nbsp;    }
<i>936</i>&nbsp;
<i>937</i>&nbsp;    public Engine.GetResult get(Engine.Get get) {
<b class="nc"><i>938</i>&nbsp;        readAllowed();</b>
<b class="nc"><i>939</i>&nbsp;        DocumentMapper mapper = mapperService.documentMapper();</b>
<b class="nc"><i>940</i>&nbsp;        if (mapper == null || mapper.type().equals(mapperService.resolveDocumentType(get.type())) == false) {</b>
<b class="nc"><i>941</i>&nbsp;            return GetResult.NOT_EXISTS;</b>
<i>942</i>&nbsp;        }
<b class="nc"><i>943</i>&nbsp;        return getEngine().get(get, this::acquireSearcher);</b>
<i>944</i>&nbsp;    }
<i>945</i>&nbsp;
<i>946</i>&nbsp;    /**
<i>947</i>&nbsp;     * Writes all indexing changes to disk and opens a new searcher reflecting all changes.  This can throw {@link AlreadyClosedException}.
<i>948</i>&nbsp;     */
<i>949</i>&nbsp;    public void refresh(String source) {
<b class="nc"><i>950</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>951</i>&nbsp;        if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>952</i>&nbsp;            logger.trace(&quot;refresh with source [{}]&quot;, source);</b>
<i>953</i>&nbsp;        }
<b class="nc"><i>954</i>&nbsp;        getEngine().refresh(source);</b>
<b class="nc"><i>955</i>&nbsp;    }</b>
<i>956</i>&nbsp;
<i>957</i>&nbsp;    /**
<i>958</i>&nbsp;     * Returns how many bytes we are currently moving from heap to disk
<i>959</i>&nbsp;     */
<i>960</i>&nbsp;    public long getWritingBytes() {
<b class="fc"><i>961</i>&nbsp;        Engine engine = getEngineOrNull();</b>
<b class="fc"><i>962</i>&nbsp;        if (engine == null) {</b>
<b class="fc"><i>963</i>&nbsp;            return 0;</b>
<i>964</i>&nbsp;        }
<b class="fc"><i>965</i>&nbsp;        return engine.getWritingBytes();</b>
<i>966</i>&nbsp;    }
<i>967</i>&nbsp;
<i>968</i>&nbsp;    public RefreshStats refreshStats() {
<b class="fc"><i>969</i>&nbsp;        int listeners = refreshListeners.pendingCount();</b>
<b class="fc"><i>970</i>&nbsp;        return new RefreshStats(</b>
<b class="fc"><i>971</i>&nbsp;            refreshMetric.count(),</b>
<b class="fc"><i>972</i>&nbsp;            TimeUnit.NANOSECONDS.toMillis(refreshMetric.sum()),</b>
<b class="fc"><i>973</i>&nbsp;            externalRefreshMetric.count(),</b>
<b class="fc"><i>974</i>&nbsp;            TimeUnit.NANOSECONDS.toMillis(externalRefreshMetric.sum()),</b>
<i>975</i>&nbsp;            listeners);
<i>976</i>&nbsp;    }
<i>977</i>&nbsp;
<i>978</i>&nbsp;    public FlushStats flushStats() {
<b class="fc"><i>979</i>&nbsp;        return new FlushStats(flushMetric.count(), periodicFlushMetric.count(), TimeUnit.NANOSECONDS.toMillis(flushMetric.sum()));</b>
<i>980</i>&nbsp;    }
<i>981</i>&nbsp;
<i>982</i>&nbsp;    public DocsStats docStats() {
<b class="nc"><i>983</i>&nbsp;        readAllowed();</b>
<b class="nc"><i>984</i>&nbsp;        return getEngine().docStats();</b>
<i>985</i>&nbsp;    }
<i>986</i>&nbsp;
<i>987</i>&nbsp;    /**
<i>988</i>&nbsp;     * @return {@link CommitStats}
<i>989</i>&nbsp;     * @throws AlreadyClosedException if shard is closed
<i>990</i>&nbsp;     */
<i>991</i>&nbsp;    public CommitStats commitStats() {
<b class="nc"><i>992</i>&nbsp;        return getEngine().commitStats();</b>
<i>993</i>&nbsp;    }
<i>994</i>&nbsp;
<i>995</i>&nbsp;    /**
<i>996</i>&nbsp;     * @return {@link SeqNoStats}
<i>997</i>&nbsp;     * @throws AlreadyClosedException if shard is closed
<i>998</i>&nbsp;     */
<i>999</i>&nbsp;    public SeqNoStats seqNoStats() {
<b class="nc"><i>1000</i>&nbsp;        return getEngine().getSeqNoStats(replicationTracker.getGlobalCheckpoint());</b>
<i>1001</i>&nbsp;    }
<i>1002</i>&nbsp;
<i>1003</i>&nbsp;    public IndexingStats indexingStats(String... types) {
<b class="fc"><i>1004</i>&nbsp;        Engine engine = getEngineOrNull();</b>
<i>1005</i>&nbsp;        final boolean throttled;
<i>1006</i>&nbsp;        final long throttleTimeInMillis;
<b class="fc"><i>1007</i>&nbsp;        if (engine == null) {</b>
<b class="nc"><i>1008</i>&nbsp;            throttled = false;</b>
<b class="nc"><i>1009</i>&nbsp;            throttleTimeInMillis = 0;</b>
<i>1010</i>&nbsp;        } else {
<b class="fc"><i>1011</i>&nbsp;            throttled = engine.isThrottled();</b>
<b class="fc"><i>1012</i>&nbsp;            throttleTimeInMillis = engine.getIndexThrottleTimeInMillis();</b>
<i>1013</i>&nbsp;        }
<b class="fc"><i>1014</i>&nbsp;        return internalIndexingStats.stats(throttled, throttleTimeInMillis, types);</b>
<i>1015</i>&nbsp;    }
<i>1016</i>&nbsp;
<i>1017</i>&nbsp;    public SearchStats searchStats(String... groups) {
<b class="fc"><i>1018</i>&nbsp;        return searchStats.stats(groups);</b>
<i>1019</i>&nbsp;    }
<i>1020</i>&nbsp;
<i>1021</i>&nbsp;    public GetStats getStats() {
<b class="fc"><i>1022</i>&nbsp;        return getService.stats();</b>
<i>1023</i>&nbsp;    }
<i>1024</i>&nbsp;
<i>1025</i>&nbsp;    public StoreStats storeStats() {
<i>1026</i>&nbsp;        try {
<b class="nc"><i>1027</i>&nbsp;            return store.stats();</b>
<b class="nc"><i>1028</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i>1029</i>&nbsp;            failShard(&quot;Failing shard because of exception during storeStats&quot;, e);</b>
<b class="nc"><i>1030</i>&nbsp;            throw new ElasticsearchException(&quot;io exception while building &#39;store stats&#39;&quot;, e);</b>
<i>1031</i>&nbsp;        }
<i>1032</i>&nbsp;    }
<i>1033</i>&nbsp;
<i>1034</i>&nbsp;    public MergeStats mergeStats() {
<b class="fc"><i>1035</i>&nbsp;        final Engine engine = getEngineOrNull();</b>
<b class="fc"><i>1036</i>&nbsp;        if (engine == null) {</b>
<b class="nc"><i>1037</i>&nbsp;            return new MergeStats();</b>
<i>1038</i>&nbsp;        }
<b class="fc"><i>1039</i>&nbsp;        return engine.getMergeStats();</b>
<i>1040</i>&nbsp;    }
<i>1041</i>&nbsp;
<i>1042</i>&nbsp;    public SegmentsStats segmentStats(boolean includeSegmentFileSizes, boolean includeUnloadedSegments) {
<b class="nc"><i>1043</i>&nbsp;        SegmentsStats segmentsStats = getEngine().segmentsStats(includeSegmentFileSizes, includeUnloadedSegments);</b>
<b class="nc"><i>1044</i>&nbsp;        segmentsStats.addBitsetMemoryInBytes(shardBitsetFilterCache.getMemorySizeInBytes());</b>
<b class="nc"><i>1045</i>&nbsp;        return segmentsStats;</b>
<i>1046</i>&nbsp;    }
<i>1047</i>&nbsp;
<i>1048</i>&nbsp;    public WarmerStats warmerStats() {
<b class="nc"><i>1049</i>&nbsp;        return shardWarmerService.stats();</b>
<i>1050</i>&nbsp;    }
<i>1051</i>&nbsp;
<i>1052</i>&nbsp;    public FieldDataStats fieldDataStats(String... fields) {
<b class="nc"><i>1053</i>&nbsp;        return shardFieldData.stats(fields);</b>
<i>1054</i>&nbsp;    }
<i>1055</i>&nbsp;
<i>1056</i>&nbsp;    public TranslogStats translogStats() {
<b class="nc"><i>1057</i>&nbsp;        return getEngine().getTranslogStats();</b>
<i>1058</i>&nbsp;    }
<i>1059</i>&nbsp;
<i>1060</i>&nbsp;    public CompletionStats completionStats(String... fields) {
<b class="nc"><i>1061</i>&nbsp;        readAllowed();</b>
<i>1062</i>&nbsp;        try {
<b class="nc"><i>1063</i>&nbsp;            return getEngine().completionStats(fields);</b>
<b class="nc"><i>1064</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i>1065</i>&nbsp;            throw new UncheckedIOException(e);</b>
<i>1066</i>&nbsp;        }
<i>1067</i>&nbsp;    }
<i>1068</i>&nbsp;
<i>1069</i>&nbsp;    public Engine.SyncedFlushResult syncFlush(String syncId, Engine.CommitId expectedCommitId) {
<b class="nc"><i>1070</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>1071</i>&nbsp;        logger.trace(&quot;trying to sync flush. sync id [{}]. expected commit id [{}]]&quot;, syncId, expectedCommitId);</b>
<b class="nc"><i>1072</i>&nbsp;        return getEngine().syncFlush(syncId, expectedCommitId);</b>
<i>1073</i>&nbsp;    }
<i>1074</i>&nbsp;
<i>1075</i>&nbsp;    /**
<i>1076</i>&nbsp;     * Executes the given flush request against the engine.
<i>1077</i>&nbsp;     *
<i>1078</i>&nbsp;     * @param request the flush request
<i>1079</i>&nbsp;     * @return the commit ID
<i>1080</i>&nbsp;     */
<i>1081</i>&nbsp;    public Engine.CommitId flush(FlushRequest request) {
<b class="nc"><i>1082</i>&nbsp;        final boolean waitIfOngoing = request.waitIfOngoing();</b>
<b class="nc"><i>1083</i>&nbsp;        final boolean force = request.force();</b>
<b class="nc"><i>1084</i>&nbsp;        logger.trace(&quot;flush with {}&quot;, request);</b>
<i>1085</i>&nbsp;        /*
<i>1086</i>&nbsp;         * We allow flushes while recovery since we allow operations to happen while recovering and we want to keep the translog under
<i>1087</i>&nbsp;         * control (up to deletes, which we do not GC). Yet, we do not use flush internally to clear deletes and flush the index writer
<i>1088</i>&nbsp;         * since we use Engine#writeIndexingBuffer for this now.
<i>1089</i>&nbsp;         */
<b class="nc"><i>1090</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>1091</i>&nbsp;        final long time = System.nanoTime();</b>
<b class="nc"><i>1092</i>&nbsp;        final Engine.CommitId commitId = getEngine().flush(force, waitIfOngoing);</b>
<b class="nc"><i>1093</i>&nbsp;        flushMetric.inc(System.nanoTime() - time);</b>
<b class="nc"><i>1094</i>&nbsp;        return commitId;</b>
<i>1095</i>&nbsp;    }
<i>1096</i>&nbsp;
<i>1097</i>&nbsp;    /**
<i>1098</i>&nbsp;     * checks and removes translog files that no longer need to be retained. See
<i>1099</i>&nbsp;     * {@link org.elasticsearch.index.translog.TranslogDeletionPolicy} for details
<i>1100</i>&nbsp;     */
<i>1101</i>&nbsp;    public void trimTranslog() {
<b class="nc"><i>1102</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>1103</i>&nbsp;        final Engine engine = getEngine();</b>
<b class="nc"><i>1104</i>&nbsp;        engine.trimUnreferencedTranslogFiles();</b>
<b class="nc"><i>1105</i>&nbsp;    }</b>
<i>1106</i>&nbsp;
<i>1107</i>&nbsp;    /**
<i>1108</i>&nbsp;     * Rolls the tranlog generation and cleans unneeded.
<i>1109</i>&nbsp;     */
<i>1110</i>&nbsp;    public void rollTranslogGeneration() {
<b class="nc"><i>1111</i>&nbsp;        final Engine engine = getEngine();</b>
<b class="nc"><i>1112</i>&nbsp;        engine.rollTranslogGeneration();</b>
<b class="nc"><i>1113</i>&nbsp;    }</b>
<i>1114</i>&nbsp;
<i>1115</i>&nbsp;    public void forceMerge(ForceMergeRequest forceMerge) throws IOException {
<b class="nc"><i>1116</i>&nbsp;        verifyActive();</b>
<b class="nc"><i>1117</i>&nbsp;        if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>1118</i>&nbsp;            logger.trace(&quot;force merge with {}&quot;, forceMerge);</b>
<i>1119</i>&nbsp;        }
<b class="nc"><i>1120</i>&nbsp;        Engine engine = getEngine();</b>
<b class="nc"><i>1121</i>&nbsp;        engine.forceMerge(forceMerge.flush(), forceMerge.maxNumSegments(),</b>
<b class="nc"><i>1122</i>&nbsp;            forceMerge.onlyExpungeDeletes(), false, false);</b>
<b class="nc"><i>1123</i>&nbsp;    }</b>
<i>1124</i>&nbsp;
<i>1125</i>&nbsp;    /**
<i>1126</i>&nbsp;     * Upgrades the shard to the current version of Lucene and returns the minimum segment version
<i>1127</i>&nbsp;     */
<i>1128</i>&nbsp;    public org.apache.lucene.util.Version upgrade(UpgradeRequest upgrade) throws IOException {
<b class="nc"><i>1129</i>&nbsp;        verifyActive();</b>
<b class="nc"><i>1130</i>&nbsp;        if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>1131</i>&nbsp;            logger.trace(&quot;upgrade with {}&quot;, upgrade);</b>
<i>1132</i>&nbsp;        }
<b class="nc"><i>1133</i>&nbsp;        org.apache.lucene.util.Version previousVersion = minimumCompatibleVersion();</b>
<i>1134</i>&nbsp;        // we just want to upgrade the segments, not actually forge merge to a single segment
<b class="nc"><i>1135</i>&nbsp;        final Engine engine = getEngine();</b>
<b class="nc"><i>1136</i>&nbsp;        engine.forceMerge(true,  // we need to flush at the end to make sure the upgrade is durable</b>
<i>1137</i>&nbsp;            Integer.MAX_VALUE, // we just want to upgrade the segments, not actually optimize to a single segment
<b class="nc"><i>1138</i>&nbsp;            false, true, upgrade.upgradeOnlyAncientSegments());</b>
<b class="nc"><i>1139</i>&nbsp;        org.apache.lucene.util.Version version = minimumCompatibleVersion();</b>
<b class="nc"><i>1140</i>&nbsp;        if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>1141</i>&nbsp;            logger.trace(&quot;upgraded segments for {} from version {} to version {}&quot;, shardId, previousVersion, version);</b>
<i>1142</i>&nbsp;        }
<i>1143</i>&nbsp;
<b class="nc"><i>1144</i>&nbsp;        return version;</b>
<i>1145</i>&nbsp;    }
<i>1146</i>&nbsp;
<i>1147</i>&nbsp;    public org.apache.lucene.util.Version minimumCompatibleVersion() {
<b class="nc"><i>1148</i>&nbsp;        org.apache.lucene.util.Version luceneVersion = null;</b>
<b class="nc"><i>1149</i>&nbsp;        for (Segment segment : getEngine().segments(false)) {</b>
<b class="nc"><i>1150</i>&nbsp;            if (luceneVersion == null || luceneVersion.onOrAfter(segment.getVersion())) {</b>
<b class="nc"><i>1151</i>&nbsp;                luceneVersion = segment.getVersion();</b>
<i>1152</i>&nbsp;            }
<b class="nc"><i>1153</i>&nbsp;        }</b>
<b class="nc"><i>1154</i>&nbsp;        return luceneVersion == null ? indexSettings.getIndexVersionCreated().luceneVersion : luceneVersion;</b>
<i>1155</i>&nbsp;    }
<i>1156</i>&nbsp;
<i>1157</i>&nbsp;    /**
<i>1158</i>&nbsp;     * Creates a new {@link IndexCommit} snapshot from the currently running engine. All resources referenced by this
<i>1159</i>&nbsp;     * commit won&#39;t be freed until the commit / snapshot is closed.
<i>1160</i>&nbsp;     *
<i>1161</i>&nbsp;     * @param flushFirst &lt;code&gt;true&lt;/code&gt; if the index should first be flushed to disk / a low level lucene commit should be executed
<i>1162</i>&nbsp;     */
<i>1163</i>&nbsp;    public Engine.IndexCommitRef acquireLastIndexCommit(boolean flushFirst) throws EngineException {
<b class="nc"><i>1164</i>&nbsp;        final IndexShardState state = this.state; // one time volatile read</b>
<i>1165</i>&nbsp;        // we allow snapshot on closed index shard, since we want to do one after we close the shard and before we close the engine
<b class="nc"><i>1166</i>&nbsp;        if (state == IndexShardState.STARTED || state == IndexShardState.CLOSED) {</b>
<b class="nc"><i>1167</i>&nbsp;            return getEngine().acquireLastIndexCommit(flushFirst);</b>
<i>1168</i>&nbsp;        } else {
<b class="nc"><i>1169</i>&nbsp;            throw new IllegalIndexShardStateException(shardId, state, &quot;snapshot is not allowed&quot;);</b>
<i>1170</i>&nbsp;        }
<i>1171</i>&nbsp;    }
<i>1172</i>&nbsp;
<i>1173</i>&nbsp;    /**
<i>1174</i>&nbsp;     * Snapshots the most recent safe index commit from the currently running engine.
<i>1175</i>&nbsp;     * All index files referenced by this index commit won&#39;t be freed until the commit/snapshot is closed.
<i>1176</i>&nbsp;     */
<i>1177</i>&nbsp;    public Engine.IndexCommitRef acquireSafeIndexCommit() throws EngineException {
<b class="nc"><i>1178</i>&nbsp;        final IndexShardState state = this.state; // one time volatile read</b>
<i>1179</i>&nbsp;        // we allow snapshot on closed index shard, since we want to do one after we close the shard and before we close the engine
<b class="nc"><i>1180</i>&nbsp;        if (state == IndexShardState.STARTED || state == IndexShardState.CLOSED) {</b>
<b class="nc"><i>1181</i>&nbsp;            return getEngine().acquireSafeIndexCommit();</b>
<i>1182</i>&nbsp;        } else {
<b class="nc"><i>1183</i>&nbsp;            throw new IllegalIndexShardStateException(shardId, state, &quot;snapshot is not allowed&quot;);</b>
<i>1184</i>&nbsp;        }
<i>1185</i>&nbsp;    }
<i>1186</i>&nbsp;
<i>1187</i>&nbsp;    /**
<i>1188</i>&nbsp;     * gets a {@link Store.MetadataSnapshot} for the current directory. This method is safe to call in all lifecycle of the index shard,
<i>1189</i>&nbsp;     * without having to worry about the current state of the engine and concurrent flushes.
<i>1190</i>&nbsp;     *
<i>1191</i>&nbsp;     * @throws org.apache.lucene.index.IndexNotFoundException     if no index is found in the current directory
<i>1192</i>&nbsp;     * @throws org.apache.lucene.index.CorruptIndexException      if the lucene index is corrupted. This can be caused by a checksum
<i>1193</i>&nbsp;     *                                                            mismatch or an unexpected exception when opening the index reading the
<i>1194</i>&nbsp;     *                                                            segments file.
<i>1195</i>&nbsp;     * @throws org.apache.lucene.index.IndexFormatTooOldException if the lucene index is too old to be opened.
<i>1196</i>&nbsp;     * @throws org.apache.lucene.index.IndexFormatTooNewException if the lucene index is too new to be opened.
<i>1197</i>&nbsp;     * @throws java.io.FileNotFoundException                      if one or more files referenced by a commit are not present.
<i>1198</i>&nbsp;     * @throws java.nio.file.NoSuchFileException                  if one or more files referenced by a commit are not present.
<i>1199</i>&nbsp;     */
<i>1200</i>&nbsp;    public Store.MetadataSnapshot snapshotStoreMetadata() throws IOException {
<b class="nc"><i>1201</i>&nbsp;        assert Thread.holdsLock(mutex) == false : &quot;snapshotting store metadata under mutex&quot;;</b>
<b class="nc"><i>1202</i>&nbsp;        Engine.IndexCommitRef indexCommit = null;</b>
<b class="nc"><i>1203</i>&nbsp;        store.incRef();</b>
<i>1204</i>&nbsp;        try {
<b class="nc"><i>1205</i>&nbsp;            synchronized (engineMutex) {</b>
<i>1206</i>&nbsp;                // if the engine is not running, we can access the store directly, but we need to make sure no one starts
<i>1207</i>&nbsp;                // the engine on us. If the engine is running, we can get a snapshot via the deletion policy of the engine.
<b class="nc"><i>1208</i>&nbsp;                final Engine engine = getEngineOrNull();</b>
<b class="nc"><i>1209</i>&nbsp;                if (engine != null) {</b>
<b class="nc"><i>1210</i>&nbsp;                    indexCommit = engine.acquireLastIndexCommit(false);</b>
<i>1211</i>&nbsp;                }
<b class="nc"><i>1212</i>&nbsp;                if (indexCommit == null) {</b>
<b class="nc"><i>1213</i>&nbsp;                    return store.getMetadata(null, true);</b>
<i>1214</i>&nbsp;                }
<b class="nc"><i>1215</i>&nbsp;            }</b>
<b class="nc"><i>1216</i>&nbsp;            return store.getMetadata(indexCommit.getIndexCommit());</b>
<i>1217</i>&nbsp;        } finally {
<b class="nc"><i>1218</i>&nbsp;            store.decRef();</b>
<b class="nc"><i>1219</i>&nbsp;            IOUtils.close(indexCommit);</b>
<b class="nc"><i>1220</i>&nbsp;        }</b>
<i>1221</i>&nbsp;    }
<i>1222</i>&nbsp;
<i>1223</i>&nbsp;    /**
<i>1224</i>&nbsp;     * Fails the shard and marks the shard store as corrupted if
<i>1225</i>&nbsp;     * &lt;code&gt;e&lt;/code&gt; is caused by index corruption
<i>1226</i>&nbsp;     */
<i>1227</i>&nbsp;    public void failShard(String reason, @Nullable Exception e) {
<i>1228</i>&nbsp;        // fail the engine. This will cause this shard to also be removed from the node&#39;s index service.
<b class="nc"><i>1229</i>&nbsp;        getEngine().failEngine(reason, e);</b>
<b class="nc"><i>1230</i>&nbsp;    }</b>
<i>1231</i>&nbsp;
<i>1232</i>&nbsp;    /**
<i>1233</i>&nbsp;     * Acquire the searcher without applying the additional reader wrapper.
<i>1234</i>&nbsp;     */
<i>1235</i>&nbsp;    public Engine.Searcher acquireSearcherNoWrap(String source) {
<b class="nc"><i>1236</i>&nbsp;        readAllowed();</b>
<b class="nc"><i>1237</i>&nbsp;        markSearcherAccessed();</b>
<b class="nc"><i>1238</i>&nbsp;        return getEngine().acquireSearcher(source, Engine.SearcherScope.EXTERNAL);</b>
<i>1239</i>&nbsp;    }
<i>1240</i>&nbsp;
<i>1241</i>&nbsp;    public Engine.Searcher acquireSearcher(String source) {
<b class="nc"><i>1242</i>&nbsp;        return acquireSearcher(source, Engine.SearcherScope.EXTERNAL);</b>
<i>1243</i>&nbsp;    }
<i>1244</i>&nbsp;
<i>1245</i>&nbsp;    private void markSearcherAccessed() {
<b class="nc"><i>1246</i>&nbsp;        lastSearcherAccess.lazySet(threadPool.relativeTimeInMillis());</b>
<b class="nc"><i>1247</i>&nbsp;    }</b>
<i>1248</i>&nbsp;
<i>1249</i>&nbsp;    private Engine.Searcher acquireSearcher(String source, Engine.SearcherScope scope) {
<b class="nc"><i>1250</i>&nbsp;        readAllowed();</b>
<b class="nc"><i>1251</i>&nbsp;        markSearcherAccessed();</b>
<b class="nc"><i>1252</i>&nbsp;        final Engine engine = getEngine();</b>
<b class="nc"><i>1253</i>&nbsp;        final Engine.Searcher searcher = engine.acquireSearcher(source, scope);</b>
<b class="nc"><i>1254</i>&nbsp;        assert ElasticsearchDirectoryReader.unwrap(searcher.getDirectoryReader())</b>
<i>1255</i>&nbsp;            != null : &quot;DirectoryReader must be an instance or ElasticsearchDirectoryReader&quot;;
<b class="nc"><i>1256</i>&nbsp;        boolean success = false;</b>
<i>1257</i>&nbsp;        try {
<b class="nc"><i>1258</i>&nbsp;            final Engine.Searcher newSearcher = readerWrapper == null ? searcher : wrapSearcher(searcher, readerWrapper);</b>
<b class="nc"><i>1259</i>&nbsp;            assert newSearcher != null;</b>
<b class="nc"><i>1260</i>&nbsp;            success = true;</b>
<b class="nc"><i>1261</i>&nbsp;            return newSearcher;</b>
<b class="nc"><i>1262</i>&nbsp;        } catch (IOException ex) {</b>
<b class="nc"><i>1263</i>&nbsp;            throw new ElasticsearchException(&quot;failed to wrap searcher&quot;, ex);</b>
<i>1264</i>&nbsp;        } finally {
<b class="nc"><i>1265</i>&nbsp;            if (success == false) {</b>
<b class="nc"><i>1266</i>&nbsp;                Releasables.close(success, searcher);</b>
<i>1267</i>&nbsp;            }
<b class="nc"><i>1268</i>&nbsp;        }</b>
<i>1269</i>&nbsp;    }
<i>1270</i>&nbsp;
<i>1271</i>&nbsp;    static Engine.Searcher wrapSearcher(Engine.Searcher engineSearcher,
<i>1272</i>&nbsp;                                        CheckedFunction&lt;DirectoryReader, DirectoryReader, IOException&gt; readerWrapper) throws IOException {
<b class="nc"><i>1273</i>&nbsp;        assert readerWrapper != null;</b>
<b class="nc"><i>1274</i>&nbsp;        final ElasticsearchDirectoryReader elasticsearchDirectoryReader =</b>
<b class="nc"><i>1275</i>&nbsp;            ElasticsearchDirectoryReader.getElasticsearchDirectoryReader(engineSearcher.getDirectoryReader());</b>
<b class="nc"><i>1276</i>&nbsp;        if (elasticsearchDirectoryReader == null) {</b>
<b class="nc"><i>1277</i>&nbsp;            throw new IllegalStateException(&quot;Can&#39;t wrap non elasticsearch directory reader&quot;);</b>
<i>1278</i>&nbsp;        }
<b class="nc"><i>1279</i>&nbsp;        NonClosingReaderWrapper nonClosingReaderWrapper = new NonClosingReaderWrapper(engineSearcher.getDirectoryReader());</b>
<b class="nc"><i>1280</i>&nbsp;        DirectoryReader reader = readerWrapper.apply(nonClosingReaderWrapper);</b>
<b class="nc"><i>1281</i>&nbsp;        if (reader != nonClosingReaderWrapper) {</b>
<b class="nc"><i>1282</i>&nbsp;            if (reader.getReaderCacheHelper() != elasticsearchDirectoryReader.getReaderCacheHelper()) {</b>
<b class="nc"><i>1283</i>&nbsp;                throw new IllegalStateException(&quot;wrapped directory reader doesn&#39;t delegate IndexReader#getCoreCacheKey,&quot; +</b>
<i>1284</i>&nbsp;                    &quot; wrappers must override this method and delegate to the original readers core cache key. Wrapped readers can&#39;t be &quot; +
<i>1285</i>&nbsp;                    &quot;used as cache keys since their are used only per request which would lead to subtle bugs&quot;);
<i>1286</i>&nbsp;            }
<b class="nc"><i>1287</i>&nbsp;            if (ElasticsearchDirectoryReader.getElasticsearchDirectoryReader(reader) != elasticsearchDirectoryReader) {</b>
<i>1288</i>&nbsp;                // prevent that somebody wraps with a non-filter reader
<b class="nc"><i>1289</i>&nbsp;                throw new IllegalStateException(&quot;wrapped directory reader hides actual ElasticsearchDirectoryReader but shouldn&#39;t&quot;);</b>
<i>1290</i>&nbsp;            }
<i>1291</i>&nbsp;        }
<i>1292</i>&nbsp;
<b class="nc"><i>1293</i>&nbsp;        if (reader == nonClosingReaderWrapper) {</b>
<b class="nc"><i>1294</i>&nbsp;            return engineSearcher;</b>
<i>1295</i>&nbsp;        } else {
<i>1296</i>&nbsp;            // we close the reader to make sure wrappers can release resources if needed....
<i>1297</i>&nbsp;            // our NonClosingReaderWrapper makes sure that our reader is not closed
<b class="nc"><i>1298</i>&nbsp;            return new Engine.Searcher(engineSearcher.source(), reader,</b>
<b class="nc"><i>1299</i>&nbsp;                engineSearcher.getSimilarity(), engineSearcher.getQueryCache(), engineSearcher.getQueryCachingPolicy(),</b>
<b class="nc"><i>1300</i>&nbsp;                () -&gt; IOUtils.close(reader, // this will close the wrappers excluding the NonClosingReaderWrapper</b>
<i>1301</i>&nbsp;                    engineSearcher)); // this will run the closeable on the wrapped engine reader
<i>1302</i>&nbsp;        }
<i>1303</i>&nbsp;    }
<i>1304</i>&nbsp;
<i>1305</i>&nbsp;    private static final class NonClosingReaderWrapper extends FilterDirectoryReader {
<i>1306</i>&nbsp;
<i>1307</i>&nbsp;        private NonClosingReaderWrapper(DirectoryReader in) throws IOException {
<i>1308</i>&nbsp;            super(in, new SubReaderWrapper() {
<i>1309</i>&nbsp;                @Override
<i>1310</i>&nbsp;                public LeafReader wrap(LeafReader reader) {
<i>1311</i>&nbsp;                    return reader;
<i>1312</i>&nbsp;                }
<i>1313</i>&nbsp;            });
<i>1314</i>&nbsp;        }
<i>1315</i>&nbsp;
<i>1316</i>&nbsp;        @Override
<i>1317</i>&nbsp;        protected DirectoryReader doWrapDirectoryReader(DirectoryReader in) throws IOException {
<i>1318</i>&nbsp;            return new NonClosingReaderWrapper(in);
<i>1319</i>&nbsp;        }
<i>1320</i>&nbsp;
<i>1321</i>&nbsp;        @Override
<i>1322</i>&nbsp;        protected void doClose() throws IOException {
<i>1323</i>&nbsp;            // don&#39;t close here - mimic the MultiReader#doClose = false behavior that FilterDirectoryReader doesn&#39;t have
<i>1324</i>&nbsp;        }
<i>1325</i>&nbsp;
<i>1326</i>&nbsp;        @Override
<i>1327</i>&nbsp;        public CacheHelper getReaderCacheHelper() {
<i>1328</i>&nbsp;            return in.getReaderCacheHelper();
<i>1329</i>&nbsp;        }
<i>1330</i>&nbsp;
<i>1331</i>&nbsp;    }
<i>1332</i>&nbsp;
<i>1333</i>&nbsp;    public void close(String reason, boolean flushEngine) throws IOException {
<b class="fc"><i>1334</i>&nbsp;        synchronized (engineMutex) {</b>
<i>1335</i>&nbsp;            try {
<b class="fc"><i>1336</i>&nbsp;                synchronized (mutex) {</b>
<b class="fc"><i>1337</i>&nbsp;                    changeState(IndexShardState.CLOSED, reason);</b>
<b class="fc"><i>1338</i>&nbsp;                }</b>
<i>1339</i>&nbsp;            } finally {
<b class="fc"><i>1340</i>&nbsp;                final Engine engine = this.currentEngineReference.getAndSet(null);</b>
<i>1341</i>&nbsp;                try {
<b class="fc"><i>1342</i>&nbsp;                    if (engine != null &amp;&amp; flushEngine) {</b>
<b class="nc"><i>1343</i>&nbsp;                        engine.flushAndClose();</b>
<i>1344</i>&nbsp;                    }
<i>1345</i>&nbsp;                } finally {
<i>1346</i>&nbsp;                    // playing safe here and close the engine even if the above succeeds - close can be called multiple times
<i>1347</i>&nbsp;                    // Also closing refreshListeners to prevent us from accumulating any more listeners
<b class="fc"><i>1348</i>&nbsp;                    IOUtils.close(engine, globalCheckpointListeners, refreshListeners);</b>
<b class="fc"><i>1349</i>&nbsp;                    indexShardOperationPermits.close();</b>
<b class="fc"><i>1350</i>&nbsp;                }</b>
<b class="fc"><i>1351</i>&nbsp;            }</b>
<b class="fc"><i>1352</i>&nbsp;        }</b>
<b class="fc"><i>1353</i>&nbsp;    }</b>
<i>1354</i>&nbsp;
<i>1355</i>&nbsp;    public void postRecovery(String reason) throws IndexShardStartedException, IndexShardRelocatedException, IndexShardClosedException {
<b class="fc"><i>1356</i>&nbsp;        synchronized (postRecoveryMutex) {</b>
<i>1357</i>&nbsp;            // we need to refresh again to expose all operations that were index until now. Otherwise
<i>1358</i>&nbsp;            // we may not expose operations that were indexed with a refresh listener that was immediately
<i>1359</i>&nbsp;            // responded to in addRefreshListener. The refresh must happen under the same mutex used in addRefreshListener
<i>1360</i>&nbsp;            // and before moving this shard to POST_RECOVERY state (i.e., allow to read from this shard).
<b class="fc"><i>1361</i>&nbsp;            getEngine().refresh(&quot;post_recovery&quot;);</b>
<b class="fc"><i>1362</i>&nbsp;            synchronized (mutex) {</b>
<b class="fc"><i>1363</i>&nbsp;                if (state == IndexShardState.CLOSED) {</b>
<b class="nc"><i>1364</i>&nbsp;                    throw new IndexShardClosedException(shardId);</b>
<i>1365</i>&nbsp;                }
<b class="fc"><i>1366</i>&nbsp;                if (state == IndexShardState.STARTED) {</b>
<b class="nc"><i>1367</i>&nbsp;                    throw new IndexShardStartedException(shardId);</b>
<i>1368</i>&nbsp;                }
<b class="fc"><i>1369</i>&nbsp;                recoveryState.setStage(RecoveryState.Stage.DONE);</b>
<b class="fc"><i>1370</i>&nbsp;                changeState(IndexShardState.POST_RECOVERY, reason);</b>
<b class="fc"><i>1371</i>&nbsp;            }</b>
<b class="fc"><i>1372</i>&nbsp;        }</b>
<b class="fc"><i>1373</i>&nbsp;    }</b>
<i>1374</i>&nbsp;
<i>1375</i>&nbsp;    /**
<i>1376</i>&nbsp;     * called before starting to copy index files over
<i>1377</i>&nbsp;     */
<i>1378</i>&nbsp;    public void prepareForIndexRecovery() {
<b class="fc"><i>1379</i>&nbsp;        if (state != IndexShardState.RECOVERING) {</b>
<b class="nc"><i>1380</i>&nbsp;            throw new IndexShardNotRecoveringException(shardId, state);</b>
<i>1381</i>&nbsp;        }
<b class="fc"><i>1382</i>&nbsp;        recoveryState.setStage(RecoveryState.Stage.INDEX);</b>
<b class="fc"><i>1383</i>&nbsp;        assert currentEngineReference.get() == null;</b>
<b class="fc"><i>1384</i>&nbsp;    }</b>
<i>1385</i>&nbsp;
<i>1386</i>&nbsp;    /**
<i>1387</i>&nbsp;     * A best effort to bring up this shard to the global checkpoint using the local translog before performing a peer recovery.
<i>1388</i>&nbsp;     *
<i>1389</i>&nbsp;     * @return a sequence number that an operation-based peer recovery can start with.
<i>1390</i>&nbsp;     * This is the first operation after the local checkpoint of the safe commit if exists.
<i>1391</i>&nbsp;     */
<i>1392</i>&nbsp;    public long recoverLocallyUpToGlobalCheckpoint() {
<b class="nc"><i>1393</i>&nbsp;        assert Thread.holdsLock(mutex) == false : &quot;recover locally under mutex&quot;;</b>
<b class="nc"><i>1394</i>&nbsp;        if (state != IndexShardState.RECOVERING) {</b>
<b class="nc"><i>1395</i>&nbsp;            throw new IndexShardNotRecoveringException(shardId, state);</b>
<i>1396</i>&nbsp;        }
<b class="nc"><i>1397</i>&nbsp;        assert recoveryState.getStage() == RecoveryState.Stage.INDEX : &quot;unexpected recovery stage [&quot; + recoveryState.getStage() + &quot;]&quot;;</b>
<b class="nc"><i>1398</i>&nbsp;        assert routingEntry().recoverySource().getType() == RecoverySource.Type.PEER : &quot;not a peer recovery [&quot; + routingEntry() + &quot;]&quot;;</b>
<i>1399</i>&nbsp;        final Optional&lt;SequenceNumbers.CommitInfo&gt; safeCommit;
<i>1400</i>&nbsp;        final long globalCheckpoint;
<i>1401</i>&nbsp;        try {
<b class="nc"><i>1402</i>&nbsp;            final String translogUUID = store.readLastCommittedSegmentsInfo().getUserData().get(Translog.TRANSLOG_UUID_KEY);</b>
<b class="nc"><i>1403</i>&nbsp;            globalCheckpoint = Translog.readGlobalCheckpoint(translogConfig.getTranslogPath(), translogUUID);</b>
<b class="nc"><i>1404</i>&nbsp;            safeCommit = store.findSafeIndexCommit(globalCheckpoint);</b>
<b class="nc"><i>1405</i>&nbsp;        } catch (org.apache.lucene.index.IndexNotFoundException e) {</b>
<b class="nc"><i>1406</i>&nbsp;            logger.trace(&quot;skip local recovery as no index commit found&quot;);</b>
<b class="nc"><i>1407</i>&nbsp;            return UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1408</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>1409</i>&nbsp;            logger.debug(&quot;skip local recovery as failed to find the safe commit&quot;, e);</b>
<b class="nc"><i>1410</i>&nbsp;            return UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1411</i>&nbsp;        }</b>
<b class="nc"><i>1412</i>&nbsp;        if (safeCommit.isPresent() == false) {</b>
<b class="nc"><i>1413</i>&nbsp;            logger.trace(&quot;skip local recovery as no safe commit found&quot;);</b>
<b class="nc"><i>1414</i>&nbsp;            return UNASSIGNED_SEQ_NO;</b>
<i>1415</i>&nbsp;        }
<b class="nc"><i>1416</i>&nbsp;        assert safeCommit.get().localCheckpoint &lt;= globalCheckpoint : safeCommit.get().localCheckpoint + &quot; &gt; &quot; + globalCheckpoint;</b>
<i>1417</i>&nbsp;        try {
<b class="nc"><i>1418</i>&nbsp;            maybeCheckIndex(); // check index here and won&#39;t do it again if ops-based recovery occurs</b>
<b class="nc"><i>1419</i>&nbsp;            recoveryState.setStage(RecoveryState.Stage.TRANSLOG);</b>
<b class="nc"><i>1420</i>&nbsp;            if (safeCommit.get().localCheckpoint == globalCheckpoint) {</b>
<b class="nc"><i>1421</i>&nbsp;                logger.trace(&quot;skip local recovery as the safe commit is up to date; safe commit {} global checkpoint {}&quot;,</b>
<b class="nc"><i>1422</i>&nbsp;                    safeCommit.get(), globalCheckpoint);</b>
<b class="nc"><i>1423</i>&nbsp;                recoveryState.getTranslog().totalLocal(0);</b>
<b class="nc"><i>1424</i>&nbsp;                return globalCheckpoint + 1;</b>
<i>1425</i>&nbsp;            }
<b class="nc"><i>1426</i>&nbsp;            if (indexSettings.getIndexMetaData().getState() == IndexMetaData.State.CLOSE ||</b>
<b class="nc"><i>1427</i>&nbsp;                IndexMetaData.INDEX_BLOCKS_WRITE_SETTING.get(indexSettings.getSettings())) {</b>
<b class="nc"><i>1428</i>&nbsp;                logger.trace(&quot;skip local recovery as the index was closed or not allowed to write; safe commit {} global checkpoint {}&quot;,</b>
<b class="nc"><i>1429</i>&nbsp;                    safeCommit.get(), globalCheckpoint);</b>
<b class="nc"><i>1430</i>&nbsp;                recoveryState.getTranslog().totalLocal(0);</b>
<b class="nc"><i>1431</i>&nbsp;                return safeCommit.get().localCheckpoint + 1;</b>
<i>1432</i>&nbsp;            }
<i>1433</i>&nbsp;            try {
<b class="nc"><i>1434</i>&nbsp;                final Engine.TranslogRecoveryRunner translogRecoveryRunner = (engine, snapshot) -&gt; {</b>
<b class="nc"><i>1435</i>&nbsp;                    recoveryState.getTranslog().totalLocal(snapshot.totalOperations());</b>
<b class="nc"><i>1436</i>&nbsp;                    final int recoveredOps = runTranslogRecovery(engine, snapshot, Engine.Operation.Origin.LOCAL_TRANSLOG_RECOVERY,</b>
<b class="nc"><i>1437</i>&nbsp;                        recoveryState.getTranslog()::incrementRecoveredOperations);</b>
<b class="nc"><i>1438</i>&nbsp;                    recoveryState.getTranslog().totalLocal(recoveredOps); // adjust the total local to reflect the actual count</b>
<b class="nc"><i>1439</i>&nbsp;                    return recoveredOps;</b>
<i>1440</i>&nbsp;                };
<b class="nc"><i>1441</i>&nbsp;                innerOpenEngineAndTranslog(() -&gt; globalCheckpoint);</b>
<b class="nc"><i>1442</i>&nbsp;                getEngine().recoverFromTranslog(translogRecoveryRunner, globalCheckpoint);</b>
<b class="nc"><i>1443</i>&nbsp;                logger.trace(&quot;shard locally recovered up to {}&quot;, getEngine().getSeqNoStats(globalCheckpoint));</b>
<i>1444</i>&nbsp;            } finally {
<b class="nc"><i>1445</i>&nbsp;                synchronized (engineMutex) {</b>
<b class="nc"><i>1446</i>&nbsp;                    IOUtils.close(currentEngineReference.getAndSet(null));</b>
<b class="nc"><i>1447</i>&nbsp;                }</b>
<b class="nc"><i>1448</i>&nbsp;            }</b>
<b class="nc"><i>1449</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>1450</i>&nbsp;            logger.debug(new ParameterizedMessage(&quot;failed to recover shard locally up to global checkpoint {}&quot;, globalCheckpoint), e);</b>
<b class="nc"><i>1451</i>&nbsp;            return UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1452</i>&nbsp;        }</b>
<i>1453</i>&nbsp;        try {
<i>1454</i>&nbsp;            // we need to find the safe commit again as we should have created a new one during the local recovery
<b class="nc"><i>1455</i>&nbsp;            final Optional&lt;SequenceNumbers.CommitInfo&gt; newSafeCommit = store.findSafeIndexCommit(globalCheckpoint);</b>
<b class="nc"><i>1456</i>&nbsp;            assert newSafeCommit.isPresent() : &quot;no safe commit found after local recovery&quot;;</b>
<b class="nc"><i>1457</i>&nbsp;            return newSafeCommit.get().localCheckpoint + 1;</b>
<b class="nc"><i>1458</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>1459</i>&nbsp;            logger.debug(new ParameterizedMessage(</b>
<b class="nc"><i>1460</i>&nbsp;                &quot;failed to find the safe commit after recovering shard locally up to global checkpoint {}&quot;, globalCheckpoint), e);</b>
<b class="nc"><i>1461</i>&nbsp;            return UNASSIGNED_SEQ_NO;</b>
<i>1462</i>&nbsp;        }
<i>1463</i>&nbsp;    }
<i>1464</i>&nbsp;
<i>1465</i>&nbsp;    public void trimOperationOfPreviousPrimaryTerms(long aboveSeqNo) {
<b class="nc"><i>1466</i>&nbsp;        getEngine().trimOperationsFromTranslog(getOperationPrimaryTerm(), aboveSeqNo);</b>
<b class="nc"><i>1467</i>&nbsp;    }</b>
<i>1468</i>&nbsp;
<i>1469</i>&nbsp;    /**
<i>1470</i>&nbsp;     * Returns the maximum auto_id_timestamp of all append-only requests have been processed by this shard or the auto_id_timestamp received
<i>1471</i>&nbsp;     * from the primary via {@link #updateMaxUnsafeAutoIdTimestamp(long)} at the beginning of a peer-recovery or a primary-replica resync.
<i>1472</i>&nbsp;     *
<i>1473</i>&nbsp;     * @see #updateMaxUnsafeAutoIdTimestamp(long)
<i>1474</i>&nbsp;     */
<i>1475</i>&nbsp;    public long getMaxSeenAutoIdTimestamp() {
<b class="nc"><i>1476</i>&nbsp;        return getEngine().getMaxSeenAutoIdTimestamp();</b>
<i>1477</i>&nbsp;    }
<i>1478</i>&nbsp;
<i>1479</i>&nbsp;    /**
<i>1480</i>&nbsp;     * Since operations stored in soft-deletes do not have max_auto_id_timestamp, the primary has to propagate its max_auto_id_timestamp
<i>1481</i>&nbsp;     * (via {@link #getMaxSeenAutoIdTimestamp()} of all processed append-only requests to replicas at the beginning of a peer-recovery
<i>1482</i>&nbsp;     * or a primary-replica resync to force a replica to disable optimization for all append-only requests which are replicated via
<i>1483</i>&nbsp;     * replication while its retry variants are replicated via recovery without auto_id_timestamp.
<i>1484</i>&nbsp;     * &lt;p&gt;
<i>1485</i>&nbsp;     * Without this force-update, a replica can generate duplicate documents (for the same id) if it first receives
<i>1486</i>&nbsp;     * a retry append-only (without timestamp) via recovery, then an original append-only (with timestamp) via replication.
<i>1487</i>&nbsp;     */
<i>1488</i>&nbsp;    public void updateMaxUnsafeAutoIdTimestamp(long maxSeenAutoIdTimestampFromPrimary) {
<b class="nc"><i>1489</i>&nbsp;        getEngine().updateMaxUnsafeAutoIdTimestamp(maxSeenAutoIdTimestampFromPrimary);</b>
<b class="nc"><i>1490</i>&nbsp;    }</b>
<i>1491</i>&nbsp;
<i>1492</i>&nbsp;    public Engine.Result applyTranslogOperation(Translog.Operation operation, Engine.Operation.Origin origin) throws IOException {
<b class="nc"><i>1493</i>&nbsp;        return applyTranslogOperation(getEngine(), operation, origin);</b>
<i>1494</i>&nbsp;    }
<i>1495</i>&nbsp;
<i>1496</i>&nbsp;    private Engine.Result applyTranslogOperation(Engine engine, Translog.Operation operation,
<i>1497</i>&nbsp;                                                 Engine.Operation.Origin origin) throws IOException {
<i>1498</i>&nbsp;        // If a translog op is replayed on the primary (eg. ccr), we need to use external instead of null for its version type.
<b class="nc"><i>1499</i>&nbsp;        final VersionType versionType = (origin == Engine.Operation.Origin.PRIMARY) ? VersionType.EXTERNAL : null;</b>
<i>1500</i>&nbsp;        final Engine.Result result;
<b class="pc"><i>1501</i>&nbsp;        switch (operation.opType()) {</b>
<i>1502</i>&nbsp;            case INDEX:
<b class="nc"><i>1503</i>&nbsp;                final Translog.Index index = (Translog.Index) operation;</b>
<i>1504</i>&nbsp;                // we set canHaveDuplicates to true all the time such that we de-optimze the translog case and ensure that all
<i>1505</i>&nbsp;                // autoGeneratedID docs that are coming from the primary are updated correctly.
<b class="nc"><i>1506</i>&nbsp;                result = applyIndexOperation(engine, index.seqNo(), index.primaryTerm(), index.version(),</b>
<b class="nc"><i>1507</i>&nbsp;                    versionType, UNASSIGNED_SEQ_NO, 0, index.getAutoGeneratedIdTimestamp(), true, origin,</b>
<b class="nc"><i>1508</i>&nbsp;                    new SourceToParse(shardId.getIndexName(), index.type(), index.id(), index.source(),</b>
<b class="nc"><i>1509</i>&nbsp;                        XContentHelper.xContentType(index.source()), index.routing()));</b>
<b class="nc"><i>1510</i>&nbsp;                break;</b>
<i>1511</i>&nbsp;            case DELETE:
<b class="nc"><i>1512</i>&nbsp;                final Translog.Delete delete = (Translog.Delete) operation;</b>
<b class="nc"><i>1513</i>&nbsp;                result = applyDeleteOperation(engine, delete.seqNo(), delete.primaryTerm(), delete.version(), delete.type(), delete.id(),</b>
<i>1514</i>&nbsp;                    versionType, UNASSIGNED_SEQ_NO, 0, origin);
<b class="nc"><i>1515</i>&nbsp;                break;</b>
<i>1516</i>&nbsp;            case NO_OP:
<b class="nc"><i>1517</i>&nbsp;                final Translog.NoOp noOp = (Translog.NoOp) operation;</b>
<b class="nc"><i>1518</i>&nbsp;                result = markSeqNoAsNoop(engine, noOp.seqNo(), noOp.primaryTerm(), noOp.reason(), origin);</b>
<b class="nc"><i>1519</i>&nbsp;                break;</b>
<i>1520</i>&nbsp;            default:
<b class="nc"><i>1521</i>&nbsp;                throw new IllegalStateException(&quot;No operation defined for [&quot; + operation + &quot;]&quot;);</b>
<i>1522</i>&nbsp;        }
<b class="nc"><i>1523</i>&nbsp;        return result;</b>
<i>1524</i>&nbsp;    }
<i>1525</i>&nbsp;
<i>1526</i>&nbsp;    /**
<i>1527</i>&nbsp;     * Replays translog operations from the provided translog {@code snapshot} to the current engine using the given {@code origin}.
<i>1528</i>&nbsp;     * The callback {@code onOperationRecovered} is notified after each translog operation is replayed successfully.
<i>1529</i>&nbsp;     */
<i>1530</i>&nbsp;    int runTranslogRecovery(Engine engine, Translog.Snapshot snapshot, Engine.Operation.Origin origin,
<i>1531</i>&nbsp;                            Runnable onOperationRecovered) throws IOException {
<b class="fc"><i>1532</i>&nbsp;        int opsRecovered = 0;</b>
<i>1533</i>&nbsp;        Translog.Operation operation;
<b class="fc"><i>1534</i>&nbsp;        while ((operation = snapshot.next()) != null) {</b>
<i>1535</i>&nbsp;            try {
<b class="nc"><i>1536</i>&nbsp;                logger.trace(&quot;[translog] recover op {}&quot;, operation);</b>
<b class="nc"><i>1537</i>&nbsp;                Engine.Result result = applyTranslogOperation(engine, operation, origin);</b>
<b class="pc"><i>1538</i>&nbsp;                switch (result.getResultType()) {</b>
<i>1539</i>&nbsp;                    case FAILURE:
<b class="nc"><i>1540</i>&nbsp;                        throw result.getFailure();</b>
<i>1541</i>&nbsp;                    case MAPPING_UPDATE_REQUIRED:
<b class="nc"><i>1542</i>&nbsp;                        throw new IllegalArgumentException(&quot;unexpected mapping update: &quot; + result.getRequiredMappingUpdate());</b>
<i>1543</i>&nbsp;                    case SUCCESS:
<b class="nc"><i>1544</i>&nbsp;                        break;</b>
<i>1545</i>&nbsp;                    default:
<b class="nc"><i>1546</i>&nbsp;                        throw new AssertionError(&quot;Unknown result type [&quot; + result.getResultType() + &quot;]&quot;);</b>
<i>1547</i>&nbsp;                }
<i>1548</i>&nbsp;
<b class="nc"><i>1549</i>&nbsp;                opsRecovered++;</b>
<b class="nc"><i>1550</i>&nbsp;                onOperationRecovered.run();</b>
<b class="nc"><i>1551</i>&nbsp;            } catch (Exception e) {</b>
<i>1552</i>&nbsp;                // TODO: Don&#39;t enable this leniency unless users explicitly opt-in
<b class="nc"><i>1553</i>&nbsp;                if (origin == Engine.Operation.Origin.LOCAL_TRANSLOG_RECOVERY &amp;&amp; ExceptionsHelper.status(e) == RestStatus.BAD_REQUEST) {</b>
<i>1554</i>&nbsp;                    // mainly for MapperParsingException and Failure to detect xcontent
<b class="nc"><i>1555</i>&nbsp;                    logger.info(&quot;ignoring recovery of a corrupt translog entry&quot;, e);</b>
<i>1556</i>&nbsp;                } else {
<b class="nc"><i>1557</i>&nbsp;                    throw ExceptionsHelper.convertToRuntime(e);</b>
<i>1558</i>&nbsp;                }
<b class="nc"><i>1559</i>&nbsp;            }</b>
<i>1560</i>&nbsp;        }
<b class="fc"><i>1561</i>&nbsp;        return opsRecovered;</b>
<i>1562</i>&nbsp;    }
<i>1563</i>&nbsp;
<i>1564</i>&nbsp;    private void loadGlobalCheckpointToReplicationTracker() throws IOException {
<i>1565</i>&nbsp;        // we have to set it before we open an engine and recover from the translog because
<i>1566</i>&nbsp;        // acquiring a snapshot from the translog causes a sync which causes the global checkpoint to be pulled in,
<i>1567</i>&nbsp;        // and an engine can be forced to close in ctor which also causes the global checkpoint to be pulled in.
<b class="fc"><i>1568</i>&nbsp;        final String translogUUID = store.readLastCommittedSegmentsInfo().getUserData().get(Translog.TRANSLOG_UUID_KEY);</b>
<b class="fc"><i>1569</i>&nbsp;        final long globalCheckpoint = Translog.readGlobalCheckpoint(translogConfig.getTranslogPath(), translogUUID);</b>
<b class="fc"><i>1570</i>&nbsp;        replicationTracker.updateGlobalCheckpointOnReplica(globalCheckpoint, &quot;read from translog checkpoint&quot;);</b>
<b class="fc"><i>1571</i>&nbsp;    }</b>
<i>1572</i>&nbsp;
<i>1573</i>&nbsp;    /**
<i>1574</i>&nbsp;     * opens the engine on top of the existing lucene engine and translog.
<i>1575</i>&nbsp;     * Operations from the translog will be replayed to bring lucene up to date.
<i>1576</i>&nbsp;     **/
<i>1577</i>&nbsp;    public void openEngineAndRecoverFromTranslog() throws IOException {
<b class="fc"><i>1578</i>&nbsp;        assert recoveryState.getStage() == RecoveryState.Stage.INDEX : &quot;unexpected recovery stage [&quot; + recoveryState.getStage() + &quot;]&quot;;</b>
<b class="fc"><i>1579</i>&nbsp;        maybeCheckIndex();</b>
<b class="fc"><i>1580</i>&nbsp;        recoveryState.setStage(RecoveryState.Stage.TRANSLOG);</b>
<b class="fc"><i>1581</i>&nbsp;        final RecoveryState.Translog translogRecoveryStats = recoveryState.getTranslog();</b>
<b class="fc"><i>1582</i>&nbsp;        final Engine.TranslogRecoveryRunner translogRecoveryRunner = (engine, snapshot) -&gt; {</b>
<b class="fc"><i>1583</i>&nbsp;            translogRecoveryStats.totalOperations(snapshot.totalOperations());</b>
<b class="fc"><i>1584</i>&nbsp;            translogRecoveryStats.totalOperationsOnStart(snapshot.totalOperations());</b>
<b class="fc"><i>1585</i>&nbsp;            return runTranslogRecovery(engine, snapshot, Engine.Operation.Origin.LOCAL_TRANSLOG_RECOVERY,</b>
<b class="fc"><i>1586</i>&nbsp;                translogRecoveryStats::incrementRecoveredOperations);</b>
<i>1587</i>&nbsp;        };
<b class="fc"><i>1588</i>&nbsp;        loadGlobalCheckpointToReplicationTracker();</b>
<b class="fc"><i>1589</i>&nbsp;        innerOpenEngineAndTranslog(replicationTracker);</b>
<b class="fc"><i>1590</i>&nbsp;        getEngine().recoverFromTranslog(translogRecoveryRunner, Long.MAX_VALUE);</b>
<b class="fc"><i>1591</i>&nbsp;    }</b>
<i>1592</i>&nbsp;
<i>1593</i>&nbsp;    /**
<i>1594</i>&nbsp;     * Opens the engine on top of the existing lucene engine and translog.
<i>1595</i>&nbsp;     * The translog is kept but its operations won&#39;t be replayed.
<i>1596</i>&nbsp;     */
<i>1597</i>&nbsp;    public void openEngineAndSkipTranslogRecovery() throws IOException {
<b class="nc"><i>1598</i>&nbsp;        assert routingEntry().recoverySource().getType() == RecoverySource.Type.PEER : &quot;not a peer recovery [&quot; + routingEntry() + &quot;]&quot;;</b>
<b class="nc"><i>1599</i>&nbsp;        assert recoveryState.getStage() == RecoveryState.Stage.TRANSLOG : &quot;unexpected recovery stage [&quot; + recoveryState.getStage() + &quot;]&quot;;</b>
<b class="nc"><i>1600</i>&nbsp;        loadGlobalCheckpointToReplicationTracker();</b>
<b class="nc"><i>1601</i>&nbsp;        innerOpenEngineAndTranslog(replicationTracker);</b>
<b class="nc"><i>1602</i>&nbsp;        getEngine().skipTranslogRecovery();</b>
<b class="nc"><i>1603</i>&nbsp;    }</b>
<i>1604</i>&nbsp;
<i>1605</i>&nbsp;    private void innerOpenEngineAndTranslog(LongSupplier globalCheckpointSupplier) throws IOException {
<b class="fc"><i>1606</i>&nbsp;        assert Thread.holdsLock(mutex) == false : &quot;opening engine under mutex&quot;;</b>
<b class="fc"><i>1607</i>&nbsp;        if (state != IndexShardState.RECOVERING) {</b>
<b class="nc"><i>1608</i>&nbsp;            throw new IndexShardNotRecoveringException(shardId, state);</b>
<i>1609</i>&nbsp;        }
<b class="fc"><i>1610</i>&nbsp;        final EngineConfig config = newEngineConfig(globalCheckpointSupplier);</b>
<i>1611</i>&nbsp;
<i>1612</i>&nbsp;        // we disable deletes since we allow for operations to be executed against the shard while recovering
<i>1613</i>&nbsp;        // but we need to make sure we don&#39;t loose deletes until we are done recovering
<b class="fc"><i>1614</i>&nbsp;        config.setEnableGcDeletes(false);</b>
<b class="fc"><i>1615</i>&nbsp;        updateRetentionLeasesOnReplica(loadRetentionLeases());</b>
<b class="fc"><i>1616</i>&nbsp;        assert recoveryState.getRecoverySource().expectEmptyRetentionLeases() == false || getRetentionLeases().leases().isEmpty()</b>
<b class="nc"><i>1617</i>&nbsp;            : &quot;expected empty set of retention leases with recovery source [&quot; + recoveryState.getRecoverySource()</b>
<b class="nc"><i>1618</i>&nbsp;            + &quot;] but got &quot; + getRetentionLeases();</b>
<b class="fc"><i>1619</i>&nbsp;        synchronized (engineMutex) {</b>
<b class="fc"><i>1620</i>&nbsp;            assert currentEngineReference.get() == null : &quot;engine is running&quot;;</b>
<b class="fc"><i>1621</i>&nbsp;            verifyNotClosed();</b>
<i>1622</i>&nbsp;            // we must create a new engine under mutex (see IndexShard#snapshotStoreMetadata).
<b class="fc"><i>1623</i>&nbsp;            final Engine newEngine = engineFactory.newReadWriteEngine(config);</b>
<b class="fc"><i>1624</i>&nbsp;            onNewEngine(newEngine);</b>
<b class="fc"><i>1625</i>&nbsp;            currentEngineReference.set(newEngine);</b>
<i>1626</i>&nbsp;            // We set active because we are now writing operations to the engine; this way,
<i>1627</i>&nbsp;            // if we go idle after some time and become inactive, we still give sync&#39;d flush a chance to run.
<b class="fc"><i>1628</i>&nbsp;            active.set(true);</b>
<b class="fc"><i>1629</i>&nbsp;        }</b>
<i>1630</i>&nbsp;        // time elapses after the engine is created above (pulling the config settings) until we set the engine reference, during
<i>1631</i>&nbsp;        // which settings changes could possibly have happened, so here we forcefully push any config changes to the new engine.
<b class="fc"><i>1632</i>&nbsp;        onSettingsChanged();</b>
<b class="fc"><i>1633</i>&nbsp;        assert assertSequenceNumbersInCommit();</b>
<b class="fc"><i>1634</i>&nbsp;        assert recoveryState.getStage() == RecoveryState.Stage.TRANSLOG : &quot;TRANSLOG stage expected but was: &quot; + recoveryState.getStage();</b>
<b class="fc"><i>1635</i>&nbsp;    }</b>
<i>1636</i>&nbsp;
<i>1637</i>&nbsp;    private boolean assertSequenceNumbersInCommit() throws IOException {
<b class="fc"><i>1638</i>&nbsp;        final Map&lt;String, String&gt; userData = SegmentInfos.readLatestCommit(store.directory()).getUserData();</b>
<b class="fc"><i>1639</i>&nbsp;        assert userData.containsKey(SequenceNumbers.LOCAL_CHECKPOINT_KEY) : &quot;commit point doesn&#39;t contains a local checkpoint&quot;;</b>
<b class="fc"><i>1640</i>&nbsp;        assert userData.containsKey(SequenceNumbers.MAX_SEQ_NO) : &quot;commit point doesn&#39;t contains a maximum sequence number&quot;;</b>
<b class="fc"><i>1641</i>&nbsp;        assert userData.containsKey(Engine.HISTORY_UUID_KEY) : &quot;commit point doesn&#39;t contains a history uuid&quot;;</b>
<b class="fc"><i>1642</i>&nbsp;        assert userData.get(Engine.HISTORY_UUID_KEY).equals(getHistoryUUID()) : &quot;commit point history uuid [&quot;</b>
<b class="nc"><i>1643</i>&nbsp;            + userData.get(Engine.HISTORY_UUID_KEY) + &quot;] is different than engine [&quot; + getHistoryUUID() + &quot;]&quot;;</b>
<b class="fc"><i>1644</i>&nbsp;        assert userData.containsKey(Engine.MAX_UNSAFE_AUTO_ID_TIMESTAMP_COMMIT_ID) :</b>
<i>1645</i>&nbsp;            &quot;opening index which was created post 5.5.0 but &quot; + Engine.MAX_UNSAFE_AUTO_ID_TIMESTAMP_COMMIT_ID
<i>1646</i>&nbsp;                + &quot; is not found in commit&quot;;
<b class="fc"><i>1647</i>&nbsp;        return true;</b>
<i>1648</i>&nbsp;    }
<i>1649</i>&nbsp;
<i>1650</i>&nbsp;    private void onNewEngine(Engine newEngine) {
<b class="fc"><i>1651</i>&nbsp;        assert Thread.holdsLock(engineMutex);</b>
<b class="fc"><i>1652</i>&nbsp;        refreshListeners.setCurrentRefreshLocationSupplier(newEngine::getTranslogLastWriteLocation);</b>
<b class="fc"><i>1653</i>&nbsp;    }</b>
<i>1654</i>&nbsp;
<i>1655</i>&nbsp;    /**
<i>1656</i>&nbsp;     * called if recovery has to be restarted after network error / delay **
<i>1657</i>&nbsp;     */
<i>1658</i>&nbsp;    public void performRecoveryRestart() throws IOException {
<b class="nc"><i>1659</i>&nbsp;        assert Thread.holdsLock(mutex) == false : &quot;restart recovery under mutex&quot;;</b>
<b class="nc"><i>1660</i>&nbsp;        synchronized (engineMutex) {</b>
<b class="nc"><i>1661</i>&nbsp;            assert refreshListeners.pendingCount() == 0 : &quot;we can&#39;t restart with pending listeners&quot;;</b>
<b class="nc"><i>1662</i>&nbsp;            IOUtils.close(currentEngineReference.getAndSet(null));</b>
<b class="nc"><i>1663</i>&nbsp;            resetRecoveryStage();</b>
<b class="nc"><i>1664</i>&nbsp;        }</b>
<b class="nc"><i>1665</i>&nbsp;    }</b>
<i>1666</i>&nbsp;
<i>1667</i>&nbsp;    /**
<i>1668</i>&nbsp;     * If a file-based recovery occurs, a recovery target calls this method to reset the recovery stage.
<i>1669</i>&nbsp;     */
<i>1670</i>&nbsp;    public void resetRecoveryStage() {
<b class="nc"><i>1671</i>&nbsp;        assert routingEntry().recoverySource().getType() == RecoverySource.Type.PEER : &quot;not a peer recovery [&quot; + routingEntry() + &quot;]&quot;;</b>
<b class="nc"><i>1672</i>&nbsp;        assert currentEngineReference.get() == null;</b>
<b class="nc"><i>1673</i>&nbsp;        if (state != IndexShardState.RECOVERING) {</b>
<b class="nc"><i>1674</i>&nbsp;            throw new IndexShardNotRecoveringException(shardId, state);</b>
<i>1675</i>&nbsp;        }
<b class="nc"><i>1676</i>&nbsp;        recoveryState().setStage(RecoveryState.Stage.INIT);</b>
<b class="nc"><i>1677</i>&nbsp;    }</b>
<i>1678</i>&nbsp;
<i>1679</i>&nbsp;    /**
<i>1680</i>&nbsp;     * returns stats about ongoing recoveries, both source and target
<i>1681</i>&nbsp;     */
<i>1682</i>&nbsp;    public RecoveryStats recoveryStats() {
<b class="fc"><i>1683</i>&nbsp;        return recoveryStats;</b>
<i>1684</i>&nbsp;    }
<i>1685</i>&nbsp;
<i>1686</i>&nbsp;    /**
<i>1687</i>&nbsp;     * Returns the current {@link RecoveryState} if this shard is recovering or has been recovering.
<i>1688</i>&nbsp;     * Returns null if the recovery has not yet started or shard was not recovered (created via an API).
<i>1689</i>&nbsp;     */
<i>1690</i>&nbsp;    @Override
<i>1691</i>&nbsp;    public RecoveryState recoveryState() {
<b class="fc"><i>1692</i>&nbsp;        return this.recoveryState;</b>
<i>1693</i>&nbsp;    }
<i>1694</i>&nbsp;
<i>1695</i>&nbsp;    /**
<i>1696</i>&nbsp;     * perform the last stages of recovery once all translog operations are done.
<i>1697</i>&nbsp;     * note that you should still call {@link #postRecovery(String)}.
<i>1698</i>&nbsp;     */
<i>1699</i>&nbsp;    public void finalizeRecovery() {
<b class="fc"><i>1700</i>&nbsp;        recoveryState().setStage(RecoveryState.Stage.FINALIZE);</b>
<b class="fc"><i>1701</i>&nbsp;        Engine engine = getEngine();</b>
<b class="fc"><i>1702</i>&nbsp;        engine.refresh(&quot;recovery_finalization&quot;);</b>
<b class="fc"><i>1703</i>&nbsp;        engine.config().setEnableGcDeletes(true);</b>
<b class="fc"><i>1704</i>&nbsp;    }</b>
<i>1705</i>&nbsp;
<i>1706</i>&nbsp;    /**
<i>1707</i>&nbsp;     * Returns {@code true} if this shard can ignore a recovery attempt made to it (since the already doing/done it)
<i>1708</i>&nbsp;     */
<i>1709</i>&nbsp;    public boolean ignoreRecoveryAttempt() {
<b class="nc"><i>1710</i>&nbsp;        IndexShardState state = state(); // one time volatile read</b>
<b class="nc"><i>1711</i>&nbsp;        return state == IndexShardState.POST_RECOVERY || state == IndexShardState.RECOVERING || state == IndexShardState.STARTED ||</b>
<i>1712</i>&nbsp;            state == IndexShardState.CLOSED;
<i>1713</i>&nbsp;    }
<i>1714</i>&nbsp;
<i>1715</i>&nbsp;    public void readAllowed() throws IllegalIndexShardStateException {
<b class="nc"><i>1716</i>&nbsp;        IndexShardState state = this.state; // one time volatile read</b>
<b class="nc"><i>1717</i>&nbsp;        if (readAllowedStates.contains(state) == false) {</b>
<b class="nc"><i>1718</i>&nbsp;            throw new IllegalIndexShardStateException(shardId, state, &quot;operations only allowed when shard state is one of &quot; +</b>
<b class="nc"><i>1719</i>&nbsp;                readAllowedStates.toString());</b>
<i>1720</i>&nbsp;        }
<b class="nc"><i>1721</i>&nbsp;    }</b>
<i>1722</i>&nbsp;
<i>1723</i>&nbsp;    /** returns true if the {@link IndexShardState} allows reading */
<i>1724</i>&nbsp;    public boolean isReadAllowed() {
<b class="fc"><i>1725</i>&nbsp;        return readAllowedStates.contains(state);</b>
<i>1726</i>&nbsp;    }
<i>1727</i>&nbsp;
<i>1728</i>&nbsp;    private void ensureWriteAllowed(Engine.Operation.Origin origin) throws IllegalIndexShardStateException {
<b class="nc"><i>1729</i>&nbsp;        IndexShardState state = this.state; // one time volatile read</b>
<i>1730</i>&nbsp;
<b class="nc"><i>1731</i>&nbsp;        if (origin.isRecovery()) {</b>
<b class="nc"><i>1732</i>&nbsp;            if (state != IndexShardState.RECOVERING) {</b>
<b class="nc"><i>1733</i>&nbsp;                throw new IllegalIndexShardStateException(shardId, state,</b>
<i>1734</i>&nbsp;                    &quot;operation only allowed when recovering, origin [&quot; + origin + &quot;]&quot;);
<i>1735</i>&nbsp;            }
<i>1736</i>&nbsp;        } else {
<b class="nc"><i>1737</i>&nbsp;            if (origin == Engine.Operation.Origin.PRIMARY) {</b>
<b class="nc"><i>1738</i>&nbsp;                assert assertPrimaryMode();</b>
<b class="nc"><i>1739</i>&nbsp;            } else if (origin == Engine.Operation.Origin.REPLICA) {</b>
<b class="nc"><i>1740</i>&nbsp;                assert assertReplicationTarget();</b>
<i>1741</i>&nbsp;            } else {
<b class="nc"><i>1742</i>&nbsp;                assert origin == Engine.Operation.Origin.LOCAL_RESET;</b>
<b class="nc"><i>1743</i>&nbsp;                assert getActiveOperationsCount() == OPERATIONS_BLOCKED</b>
<b class="nc"><i>1744</i>&nbsp;                    : &quot;locally resetting without blocking operations, active operations are [&quot; + getActiveOperations() + &quot;]&quot;;</b>
<i>1745</i>&nbsp;            }
<b class="nc"><i>1746</i>&nbsp;            if (writeAllowedStates.contains(state) == false) {</b>
<b class="nc"><i>1747</i>&nbsp;                throw new IllegalIndexShardStateException(shardId, state, &quot;operation only allowed when shard state is one of &quot; +</b>
<i>1748</i>&nbsp;                    writeAllowedStates + &quot;, origin [&quot; + origin + &quot;]&quot;);
<i>1749</i>&nbsp;            }
<i>1750</i>&nbsp;        }
<b class="nc"><i>1751</i>&nbsp;    }</b>
<i>1752</i>&nbsp;
<i>1753</i>&nbsp;    private boolean assertPrimaryMode() {
<b class="nc"><i>1754</i>&nbsp;        assert shardRouting.primary() &amp;&amp; replicationTracker.isPrimaryMode() : &quot;shard &quot; + shardRouting +</b>
<i>1755</i>&nbsp;            &quot; is not a primary shard in primary mode&quot;;
<b class="nc"><i>1756</i>&nbsp;        return true;</b>
<i>1757</i>&nbsp;    }
<i>1758</i>&nbsp;
<i>1759</i>&nbsp;    private boolean assertReplicationTarget() {
<b class="fc"><i>1760</i>&nbsp;        assert replicationTracker.isPrimaryMode() == false : &quot;shard &quot; + shardRouting + &quot; in primary mode cannot be a replication target&quot;;</b>
<b class="fc"><i>1761</i>&nbsp;        return true;</b>
<i>1762</i>&nbsp;    }
<i>1763</i>&nbsp;
<i>1764</i>&nbsp;    private void verifyNotClosed() throws IllegalIndexShardStateException {
<b class="fc"><i>1765</i>&nbsp;        verifyNotClosed(null);</b>
<b class="fc"><i>1766</i>&nbsp;    }</b>
<i>1767</i>&nbsp;
<i>1768</i>&nbsp;    private void verifyNotClosed(Exception suppressed) throws IllegalIndexShardStateException {
<b class="fc"><i>1769</i>&nbsp;        IndexShardState state = this.state; // one time volatile read</b>
<b class="fc"><i>1770</i>&nbsp;        if (state == IndexShardState.CLOSED) {</b>
<b class="nc"><i>1771</i>&nbsp;            final IllegalIndexShardStateException exc = new IndexShardClosedException(shardId, &quot;operation only allowed when not closed&quot;);</b>
<b class="nc"><i>1772</i>&nbsp;            if (suppressed != null) {</b>
<b class="nc"><i>1773</i>&nbsp;                exc.addSuppressed(suppressed);</b>
<i>1774</i>&nbsp;            }
<b class="nc"><i>1775</i>&nbsp;            throw exc;</b>
<i>1776</i>&nbsp;        }
<b class="fc"><i>1777</i>&nbsp;    }</b>
<i>1778</i>&nbsp;
<i>1779</i>&nbsp;    protected final void verifyActive() throws IllegalIndexShardStateException {
<b class="nc"><i>1780</i>&nbsp;        IndexShardState state = this.state; // one time volatile read</b>
<b class="nc"><i>1781</i>&nbsp;        if (state != IndexShardState.STARTED) {</b>
<b class="nc"><i>1782</i>&nbsp;            throw new IllegalIndexShardStateException(shardId, state, &quot;operation only allowed when shard is active&quot;);</b>
<i>1783</i>&nbsp;        }
<b class="nc"><i>1784</i>&nbsp;    }</b>
<i>1785</i>&nbsp;
<i>1786</i>&nbsp;    /**
<i>1787</i>&nbsp;     * Returns number of heap bytes used by the indexing buffer for this shard, or 0 if the shard is closed
<i>1788</i>&nbsp;     */
<i>1789</i>&nbsp;    public long getIndexBufferRAMBytesUsed() {
<b class="fc"><i>1790</i>&nbsp;        Engine engine = getEngineOrNull();</b>
<b class="fc"><i>1791</i>&nbsp;        if (engine == null) {</b>
<b class="fc"><i>1792</i>&nbsp;            return 0;</b>
<i>1793</i>&nbsp;        }
<i>1794</i>&nbsp;        try {
<b class="fc"><i>1795</i>&nbsp;            return engine.getIndexBufferRAMBytesUsed();</b>
<b class="nc"><i>1796</i>&nbsp;        } catch (AlreadyClosedException ex) {</b>
<b class="nc"><i>1797</i>&nbsp;            return 0;</b>
<i>1798</i>&nbsp;        }
<i>1799</i>&nbsp;    }
<i>1800</i>&nbsp;
<i>1801</i>&nbsp;    public void addShardFailureCallback(Consumer&lt;ShardFailure&gt; onShardFailure) {
<b class="fc"><i>1802</i>&nbsp;        this.shardEventListener.delegates.add(onShardFailure);</b>
<b class="fc"><i>1803</i>&nbsp;    }</b>
<i>1804</i>&nbsp;
<i>1805</i>&nbsp;    /**
<i>1806</i>&nbsp;     * Called by {@link IndexingMemoryController} to check whether more than {@code inactiveTimeNS} has passed since the last
<i>1807</i>&nbsp;     * indexing operation, and notify listeners that we are now inactive so e.g. sync&#39;d flush can happen.
<i>1808</i>&nbsp;     */
<i>1809</i>&nbsp;    public void checkIdle(long inactiveTimeNS) {
<b class="fc"><i>1810</i>&nbsp;        Engine engineOrNull = getEngineOrNull();</b>
<b class="fc"><i>1811</i>&nbsp;        if (engineOrNull != null &amp;&amp; System.nanoTime() - engineOrNull.getLastWriteNanos() &gt;= inactiveTimeNS) {</b>
<b class="nc"><i>1812</i>&nbsp;            boolean wasActive = active.getAndSet(false);</b>
<b class="nc"><i>1813</i>&nbsp;            if (wasActive) {</b>
<b class="nc"><i>1814</i>&nbsp;                logger.debug(&quot;shard is now inactive&quot;);</b>
<i>1815</i>&nbsp;                try {
<b class="nc"><i>1816</i>&nbsp;                    indexEventListener.onShardInactive(this);</b>
<b class="nc"><i>1817</i>&nbsp;                } catch (Exception e) {</b>
<b class="nc"><i>1818</i>&nbsp;                    logger.warn(&quot;failed to notify index event listener&quot;, e);</b>
<b class="nc"><i>1819</i>&nbsp;                }</b>
<i>1820</i>&nbsp;            }
<i>1821</i>&nbsp;        }
<b class="fc"><i>1822</i>&nbsp;    }</b>
<i>1823</i>&nbsp;
<i>1824</i>&nbsp;    public boolean isActive() {
<b class="nc"><i>1825</i>&nbsp;        return active.get();</b>
<i>1826</i>&nbsp;    }
<i>1827</i>&nbsp;
<i>1828</i>&nbsp;    public ShardPath shardPath() {
<b class="fc"><i>1829</i>&nbsp;        return path;</b>
<i>1830</i>&nbsp;    }
<i>1831</i>&nbsp;
<i>1832</i>&nbsp;    public boolean recoverFromLocalShards(BiConsumer&lt;String, MappingMetaData&gt; mappingUpdateConsumer,
<i>1833</i>&nbsp;                                                List&lt;IndexShard&gt; localShards) throws IOException {
<b class="nc"><i>1834</i>&nbsp;        assert shardRouting.primary() : &quot;recover from local shards only makes sense if the shard is a primary shard&quot;;</b>
<b class="nc"><i>1835</i>&nbsp;        assert recoveryState.getRecoverySource().getType() == RecoverySource.Type.LOCAL_SHARDS : &quot;invalid recovery type: &quot; +</b>
<b class="nc"><i>1836</i>&nbsp;            recoveryState.getRecoverySource();</b>
<b class="nc"><i>1837</i>&nbsp;        final List&lt;LocalShardSnapshot&gt; snapshots = new ArrayList&lt;&gt;();</b>
<i>1838</i>&nbsp;        try {
<b class="nc"><i>1839</i>&nbsp;            for (IndexShard shard : localShards) {</b>
<b class="nc"><i>1840</i>&nbsp;                snapshots.add(new LocalShardSnapshot(shard));</b>
<b class="nc"><i>1841</i>&nbsp;            }</b>
<i>1842</i>&nbsp;
<i>1843</i>&nbsp;            // we are the first primary, recover from the gateway
<i>1844</i>&nbsp;            // if its post api allocation, the index should exists
<b class="nc"><i>1845</i>&nbsp;            assert shardRouting.primary() : &quot;recover from local shards only makes sense if the shard is a primary shard&quot;;</b>
<b class="nc"><i>1846</i>&nbsp;            StoreRecovery storeRecovery = new StoreRecovery(shardId, logger);</b>
<b class="nc"><i>1847</i>&nbsp;            return storeRecovery.recoverFromLocalShards(mappingUpdateConsumer, this, snapshots);</b>
<i>1848</i>&nbsp;        } finally {
<b class="nc"><i>1849</i>&nbsp;            IOUtils.close(snapshots);</b>
<b class="nc"><i>1850</i>&nbsp;        }</b>
<i>1851</i>&nbsp;    }
<i>1852</i>&nbsp;
<i>1853</i>&nbsp;    public boolean recoverFromStore() {
<i>1854</i>&nbsp;        // we are the first primary, recover from the gateway
<i>1855</i>&nbsp;        // if its post api allocation, the index should exists
<b class="fc"><i>1856</i>&nbsp;        assert shardRouting.primary() : &quot;recover from store only makes sense if the shard is a primary shard&quot;;</b>
<b class="fc"><i>1857</i>&nbsp;        assert shardRouting.initializing() : &quot;can only start recovery on initializing shard&quot;;</b>
<b class="fc"><i>1858</i>&nbsp;        StoreRecovery storeRecovery = new StoreRecovery(shardId, logger);</b>
<b class="fc"><i>1859</i>&nbsp;        return storeRecovery.recoverFromStore(this);</b>
<i>1860</i>&nbsp;    }
<i>1861</i>&nbsp;
<i>1862</i>&nbsp;    public boolean restoreFromRepository(Repository repository) {
<b class="nc"><i>1863</i>&nbsp;        assert shardRouting.primary() : &quot;recover from store only makes sense if the shard is a primary shard&quot;;</b>
<b class="nc"><i>1864</i>&nbsp;        assert recoveryState.getRecoverySource().getType() == RecoverySource.Type.SNAPSHOT : &quot;invalid recovery type: &quot; +</b>
<b class="nc"><i>1865</i>&nbsp;            recoveryState.getRecoverySource();</b>
<b class="nc"><i>1866</i>&nbsp;        StoreRecovery storeRecovery = new StoreRecovery(shardId, logger);</b>
<b class="nc"><i>1867</i>&nbsp;        return storeRecovery.recoverFromRepository(this, repository);</b>
<i>1868</i>&nbsp;    }
<i>1869</i>&nbsp;
<i>1870</i>&nbsp;    /**
<i>1871</i>&nbsp;     * Tests whether or not the engine should be flushed periodically.
<i>1872</i>&nbsp;     * This test is based on the current size of the translog compared to the configured flush threshold size.
<i>1873</i>&nbsp;     *
<i>1874</i>&nbsp;     * @return {@code true} if the engine should be flushed
<i>1875</i>&nbsp;     */
<i>1876</i>&nbsp;    boolean shouldPeriodicallyFlush() {
<b class="nc"><i>1877</i>&nbsp;        final Engine engine = getEngineOrNull();</b>
<b class="nc"><i>1878</i>&nbsp;        if (engine != null) {</b>
<i>1879</i>&nbsp;            try {
<b class="nc"><i>1880</i>&nbsp;                return engine.shouldPeriodicallyFlush();</b>
<b class="nc"><i>1881</i>&nbsp;            } catch (final AlreadyClosedException e) {</b>
<i>1882</i>&nbsp;                // we are already closed, no need to flush or roll
<i>1883</i>&nbsp;            }
<i>1884</i>&nbsp;        }
<b class="nc"><i>1885</i>&nbsp;        return false;</b>
<i>1886</i>&nbsp;    }
<i>1887</i>&nbsp;
<i>1888</i>&nbsp;    /**
<i>1889</i>&nbsp;     * Tests whether or not the translog generation should be rolled to a new generation. This test is based on the size of the current
<i>1890</i>&nbsp;     * generation compared to the configured generation threshold size.
<i>1891</i>&nbsp;     *
<i>1892</i>&nbsp;     * @return {@code true} if the current generation should be rolled to a new generation
<i>1893</i>&nbsp;     */
<i>1894</i>&nbsp;    boolean shouldRollTranslogGeneration() {
<b class="nc"><i>1895</i>&nbsp;        final Engine engine = getEngineOrNull();</b>
<b class="nc"><i>1896</i>&nbsp;        if (engine != null) {</b>
<i>1897</i>&nbsp;            try {
<b class="nc"><i>1898</i>&nbsp;                return engine.shouldRollTranslogGeneration();</b>
<b class="nc"><i>1899</i>&nbsp;            } catch (final AlreadyClosedException e) {</b>
<i>1900</i>&nbsp;                // we are already closed, no need to flush or roll
<i>1901</i>&nbsp;            }
<i>1902</i>&nbsp;        }
<b class="nc"><i>1903</i>&nbsp;        return false;</b>
<i>1904</i>&nbsp;    }
<i>1905</i>&nbsp;
<i>1906</i>&nbsp;    public void onSettingsChanged() {
<b class="fc"><i>1907</i>&nbsp;        Engine engineOrNull = getEngineOrNull();</b>
<b class="fc"><i>1908</i>&nbsp;        if (engineOrNull != null) {</b>
<b class="fc"><i>1909</i>&nbsp;            final boolean useRetentionLeasesInPeerRecovery = this.useRetentionLeasesInPeerRecovery;</b>
<b class="fc"><i>1910</i>&nbsp;            engineOrNull.onSettingsChanged(</b>
<b class="fc"><i>1911</i>&nbsp;                useRetentionLeasesInPeerRecovery ? TimeValue.MINUS_ONE : indexSettings.getTranslogRetentionAge(),</b>
<b class="fc"><i>1912</i>&nbsp;                useRetentionLeasesInPeerRecovery ? new ByteSizeValue(-1) : indexSettings.getTranslogRetentionSize(),</b>
<b class="fc"><i>1913</i>&nbsp;                indexSettings.getSoftDeleteRetentionOperations()</b>
<i>1914</i>&nbsp;            );
<i>1915</i>&nbsp;        }
<b class="fc"><i>1916</i>&nbsp;    }</b>
<i>1917</i>&nbsp;
<i>1918</i>&nbsp;    private void turnOffTranslogRetention() {
<b class="nc"><i>1919</i>&nbsp;        logger.debug(&quot;turn off the translog retention for the replication group {} &quot; +</b>
<i>1920</i>&nbsp;            &quot;as it starts using retention leases exclusively in peer recoveries&quot;, shardId);
<i>1921</i>&nbsp;        // Off to the generic threadPool as pruning the delete tombstones can be expensive.
<b class="nc"><i>1922</i>&nbsp;        threadPool.generic().execute(new AbstractRunnable() {</b>
<i>1923</i>&nbsp;            @Override
<i>1924</i>&nbsp;            public void onFailure(Exception e) {
<i>1925</i>&nbsp;                if (state != IndexShardState.CLOSED) {
<i>1926</i>&nbsp;                    logger.warn(&quot;failed to turn off translog retention&quot;, e);
<i>1927</i>&nbsp;                }
<i>1928</i>&nbsp;            }
<i>1929</i>&nbsp;
<i>1930</i>&nbsp;            @Override
<i>1931</i>&nbsp;            protected void doRun() {
<i>1932</i>&nbsp;                onSettingsChanged();
<i>1933</i>&nbsp;                trimTranslog();
<i>1934</i>&nbsp;            }
<i>1935</i>&nbsp;        });
<b class="nc"><i>1936</i>&nbsp;    }</b>
<i>1937</i>&nbsp;
<i>1938</i>&nbsp;    /**
<i>1939</i>&nbsp;     * Acquires a lock on the translog files and Lucene soft-deleted documents to prevent them from being trimmed
<i>1940</i>&nbsp;     */
<i>1941</i>&nbsp;    public Closeable acquireHistoryRetentionLock(Engine.HistorySource source) {
<b class="nc"><i>1942</i>&nbsp;        return getEngine().acquireHistoryRetentionLock(source);</b>
<i>1943</i>&nbsp;    }
<i>1944</i>&nbsp;
<i>1945</i>&nbsp;    /**
<i>1946</i>&nbsp;     * Returns the estimated number of history operations whose seq# at least the provided seq# in this shard.
<i>1947</i>&nbsp;     */
<i>1948</i>&nbsp;    public int estimateNumberOfHistoryOperations(String reason, Engine.HistorySource source, long startingSeqNo) throws IOException {
<b class="nc"><i>1949</i>&nbsp;        return getEngine().estimateNumberOfHistoryOperations(reason, source, mapperService, startingSeqNo);</b>
<i>1950</i>&nbsp;    }
<i>1951</i>&nbsp;
<i>1952</i>&nbsp;    /**
<i>1953</i>&nbsp;     * Creates a new history snapshot for reading operations since the provided starting seqno (inclusive).
<i>1954</i>&nbsp;     * The returned snapshot can be retrieved from either Lucene index or translog files.
<i>1955</i>&nbsp;     */
<i>1956</i>&nbsp;    public Translog.Snapshot getHistoryOperations(String reason, Engine.HistorySource source, long startingSeqNo) throws IOException {
<b class="nc"><i>1957</i>&nbsp;        return getEngine().readHistoryOperations(reason, source, mapperService, startingSeqNo);</b>
<i>1958</i>&nbsp;    }
<i>1959</i>&nbsp;
<i>1960</i>&nbsp;    /**
<i>1961</i>&nbsp;     * Checks if we have a completed history of operations since the given starting seqno (inclusive).
<i>1962</i>&nbsp;     * This method should be called after acquiring the retention lock; See {@link #acquireHistoryRetentionLock(Engine.HistorySource)}
<i>1963</i>&nbsp;     */
<i>1964</i>&nbsp;    public boolean hasCompleteHistoryOperations(String reason, Engine.HistorySource source, long startingSeqNo) throws IOException {
<b class="nc"><i>1965</i>&nbsp;        return getEngine().hasCompleteOperationHistory(reason, source, mapperService, startingSeqNo);</b>
<i>1966</i>&nbsp;    }
<i>1967</i>&nbsp;
<i>1968</i>&nbsp;    /**
<i>1969</i>&nbsp;     * Gets the minimum retained sequence number for this engine.
<i>1970</i>&nbsp;     *
<i>1971</i>&nbsp;     * @return the minimum retained sequence number
<i>1972</i>&nbsp;     */
<i>1973</i>&nbsp;    public long getMinRetainedSeqNo() {
<b class="nc"><i>1974</i>&nbsp;        return getEngine().getMinRetainedSeqNo();</b>
<i>1975</i>&nbsp;    }
<i>1976</i>&nbsp;
<i>1977</i>&nbsp;    /**
<i>1978</i>&nbsp;     * Creates a new changes snapshot for reading operations whose seq_no are between {@code fromSeqNo}(inclusive)
<i>1979</i>&nbsp;     * and {@code toSeqNo}(inclusive). The caller has to close the returned snapshot after finishing the reading.
<i>1980</i>&nbsp;     *
<i>1981</i>&nbsp;     * @param source            the source of the request
<i>1982</i>&nbsp;     * @param fromSeqNo         the from seq_no (inclusive) to read
<i>1983</i>&nbsp;     * @param toSeqNo           the to seq_no (inclusive) to read
<i>1984</i>&nbsp;     * @param requiredFullRange if {@code true} then {@link Translog.Snapshot#next()} will throw {@link IllegalStateException}
<i>1985</i>&nbsp;     *                          if any operation between {@code fromSeqNo} and {@code toSeqNo} is missing.
<i>1986</i>&nbsp;     *                          This parameter should be only enabled when the entire requesting range is below the global checkpoint.
<i>1987</i>&nbsp;     */
<i>1988</i>&nbsp;    public Translog.Snapshot newChangesSnapshot(String source, long fromSeqNo,
<i>1989</i>&nbsp;                                                    long toSeqNo, boolean requiredFullRange) throws IOException {
<b class="nc"><i>1990</i>&nbsp;        return getEngine().newChangesSnapshot(source, mapperService, fromSeqNo, toSeqNo, requiredFullRange);</b>
<i>1991</i>&nbsp;    }
<i>1992</i>&nbsp;
<i>1993</i>&nbsp;    public List&lt;Segment&gt; segments(boolean verbose) {
<b class="nc"><i>1994</i>&nbsp;        return getEngine().segments(verbose);</b>
<i>1995</i>&nbsp;    }
<i>1996</i>&nbsp;
<i>1997</i>&nbsp;    public String getHistoryUUID() {
<b class="fc"><i>1998</i>&nbsp;        return getEngine().getHistoryUUID();</b>
<i>1999</i>&nbsp;    }
<i>2000</i>&nbsp;
<i>2001</i>&nbsp;    public IndexEventListener getIndexEventListener() {
<b class="fc"><i>2002</i>&nbsp;        return indexEventListener;</b>
<i>2003</i>&nbsp;    }
<i>2004</i>&nbsp;
<i>2005</i>&nbsp;    public void activateThrottling() {
<i>2006</i>&nbsp;        try {
<b class="nc"><i>2007</i>&nbsp;            getEngine().activateThrottling();</b>
<b class="nc"><i>2008</i>&nbsp;        } catch (AlreadyClosedException ex) {</b>
<i>2009</i>&nbsp;            // ignore
<b class="nc"><i>2010</i>&nbsp;        }</b>
<b class="nc"><i>2011</i>&nbsp;    }</b>
<i>2012</i>&nbsp;
<i>2013</i>&nbsp;    public void deactivateThrottling() {
<i>2014</i>&nbsp;        try {
<b class="nc"><i>2015</i>&nbsp;            getEngine().deactivateThrottling();</b>
<b class="nc"><i>2016</i>&nbsp;        } catch (AlreadyClosedException ex) {</b>
<i>2017</i>&nbsp;            // ignore
<b class="nc"><i>2018</i>&nbsp;        }</b>
<b class="nc"><i>2019</i>&nbsp;    }</b>
<i>2020</i>&nbsp;
<i>2021</i>&nbsp;    private void handleRefreshException(Exception e) {
<b class="nc"><i>2022</i>&nbsp;        if (e instanceof AlreadyClosedException) {</b>
<i>2023</i>&nbsp;            // ignore
<b class="nc"><i>2024</i>&nbsp;        } else if (e instanceof RefreshFailedEngineException) {</b>
<b class="nc"><i>2025</i>&nbsp;            RefreshFailedEngineException rfee = (RefreshFailedEngineException) e;</b>
<b class="nc"><i>2026</i>&nbsp;            if (rfee.getCause() instanceof InterruptedException) {</b>
<i>2027</i>&nbsp;                // ignore, we are being shutdown
<b class="nc"><i>2028</i>&nbsp;            } else if (rfee.getCause() instanceof ClosedByInterruptException) {</b>
<i>2029</i>&nbsp;                // ignore, we are being shutdown
<b class="nc"><i>2030</i>&nbsp;            } else if (rfee.getCause() instanceof ThreadInterruptedException) {</b>
<i>2031</i>&nbsp;                // ignore, we are being shutdown
<i>2032</i>&nbsp;            } else {
<b class="nc"><i>2033</i>&nbsp;                if (state != IndexShardState.CLOSED) {</b>
<b class="nc"><i>2034</i>&nbsp;                    logger.warn(&quot;Failed to perform engine refresh&quot;, e);</b>
<i>2035</i>&nbsp;                }
<i>2036</i>&nbsp;            }
<b class="nc"><i>2037</i>&nbsp;        } else {</b>
<b class="nc"><i>2038</i>&nbsp;            if (state != IndexShardState.CLOSED) {</b>
<b class="nc"><i>2039</i>&nbsp;                logger.warn(&quot;Failed to perform engine refresh&quot;, e);</b>
<i>2040</i>&nbsp;            }
<i>2041</i>&nbsp;        }
<b class="nc"><i>2042</i>&nbsp;    }</b>
<i>2043</i>&nbsp;
<i>2044</i>&nbsp;    /**
<i>2045</i>&nbsp;     * Called when our shard is using too much heap and should move buffered indexed/deleted documents to disk.
<i>2046</i>&nbsp;     */
<i>2047</i>&nbsp;    public void writeIndexingBuffer() {
<i>2048</i>&nbsp;        try {
<b class="nc"><i>2049</i>&nbsp;            Engine engine = getEngine();</b>
<b class="nc"><i>2050</i>&nbsp;            engine.writeIndexingBuffer();</b>
<b class="nc"><i>2051</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>2052</i>&nbsp;            handleRefreshException(e);</b>
<b class="nc"><i>2053</i>&nbsp;        }</b>
<b class="nc"><i>2054</i>&nbsp;    }</b>
<i>2055</i>&nbsp;
<i>2056</i>&nbsp;    /**
<i>2057</i>&nbsp;     * Notifies the service to update the local checkpoint for the shard with the provided allocation ID. See
<i>2058</i>&nbsp;     * {@link ReplicationTracker#updateLocalCheckpoint(String, long)} for
<i>2059</i>&nbsp;     * details.
<i>2060</i>&nbsp;     *
<i>2061</i>&nbsp;     * @param allocationId the allocation ID of the shard to update the local checkpoint for
<i>2062</i>&nbsp;     * @param checkpoint   the local checkpoint for the shard
<i>2063</i>&nbsp;     */
<i>2064</i>&nbsp;    public void updateLocalCheckpointForShard(final String allocationId, final long checkpoint) {
<b class="nc"><i>2065</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2066</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2067</i>&nbsp;        replicationTracker.updateLocalCheckpoint(allocationId, checkpoint);</b>
<b class="nc"><i>2068</i>&nbsp;    }</b>
<i>2069</i>&nbsp;
<i>2070</i>&nbsp;    /**
<i>2071</i>&nbsp;     * Update the local knowledge of the persisted global checkpoint for the specified allocation ID.
<i>2072</i>&nbsp;     *
<i>2073</i>&nbsp;     * @param allocationId     the allocation ID to update the global checkpoint for
<i>2074</i>&nbsp;     * @param globalCheckpoint the global checkpoint
<i>2075</i>&nbsp;     */
<i>2076</i>&nbsp;    public void updateGlobalCheckpointForShard(final String allocationId, final long globalCheckpoint) {
<b class="nc"><i>2077</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2078</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2079</i>&nbsp;        replicationTracker.updateGlobalCheckpointForShard(allocationId, globalCheckpoint);</b>
<b class="nc"><i>2080</i>&nbsp;    }</b>
<i>2081</i>&nbsp;
<i>2082</i>&nbsp;    /**
<i>2083</i>&nbsp;     * Add a global checkpoint listener. If the global checkpoint is equal to or above the global checkpoint the listener is waiting for,
<i>2084</i>&nbsp;     * then the listener will be notified immediately via an executor (so possibly not on the current thread). If the specified timeout
<i>2085</i>&nbsp;     * elapses before the listener is notified, the listener will be notified with an {@link TimeoutException}. A caller may pass null to
<i>2086</i>&nbsp;     * specify no timeout.
<i>2087</i>&nbsp;     *
<i>2088</i>&nbsp;     * @param waitingForGlobalCheckpoint the global checkpoint the listener is waiting for
<i>2089</i>&nbsp;     * @param listener                   the listener
<i>2090</i>&nbsp;     * @param timeout                    the timeout
<i>2091</i>&nbsp;     */
<i>2092</i>&nbsp;    public void addGlobalCheckpointListener(
<i>2093</i>&nbsp;            final long waitingForGlobalCheckpoint,
<i>2094</i>&nbsp;            final GlobalCheckpointListeners.GlobalCheckpointListener listener,
<i>2095</i>&nbsp;            final TimeValue timeout) {
<b class="nc"><i>2096</i>&nbsp;        this.globalCheckpointListeners.add(waitingForGlobalCheckpoint, listener, timeout);</b>
<b class="nc"><i>2097</i>&nbsp;    }</b>
<i>2098</i>&nbsp;
<i>2099</i>&nbsp;    private void ensureSoftDeletesEnabled(String feature) {
<b class="nc"><i>2100</i>&nbsp;        if (indexSettings.isSoftDeleteEnabled() == false) {</b>
<b class="nc"><i>2101</i>&nbsp;            String message = feature + &quot; requires soft deletes but &quot; + indexSettings.getIndex() + &quot; does not have soft deletes enabled&quot;;</b>
<b class="nc"><i>2102</i>&nbsp;            assert false : message;</b>
<b class="nc"><i>2103</i>&nbsp;            throw new IllegalStateException(message);</b>
<i>2104</i>&nbsp;        }
<b class="nc"><i>2105</i>&nbsp;    }</b>
<i>2106</i>&nbsp;
<i>2107</i>&nbsp;    /**
<i>2108</i>&nbsp;     * Get all retention leases tracked on this shard.
<i>2109</i>&nbsp;     *
<i>2110</i>&nbsp;     * @return the retention leases
<i>2111</i>&nbsp;     */
<i>2112</i>&nbsp;    public RetentionLeases getRetentionLeases() {
<b class="fc"><i>2113</i>&nbsp;        return getRetentionLeases(false).v2();</b>
<i>2114</i>&nbsp;    }
<i>2115</i>&nbsp;
<i>2116</i>&nbsp;    /**
<i>2117</i>&nbsp;     * If the expire leases parameter is false, gets all retention leases tracked on this shard and otherwise first calculates
<i>2118</i>&nbsp;     * expiration of existing retention leases, and then gets all non-expired retention leases tracked on this shard. Note that only the
<i>2119</i>&nbsp;     * primary shard calculates which leases are expired, and if any have expired, syncs the retention leases to any replicas. If the
<i>2120</i>&nbsp;     * expire leases parameter is true, this replication tracker must be in primary mode.
<i>2121</i>&nbsp;     *
<i>2122</i>&nbsp;     * @return a tuple indicating whether or not any retention leases were expired, and the non-expired retention leases
<i>2123</i>&nbsp;     */
<i>2124</i>&nbsp;    public Tuple&lt;Boolean, RetentionLeases&gt; getRetentionLeases(final boolean expireLeases) {
<b class="fc"><i>2125</i>&nbsp;        assert expireLeases == false || assertPrimaryMode();</b>
<b class="fc"><i>2126</i>&nbsp;        verifyNotClosed();</b>
<b class="fc"><i>2127</i>&nbsp;        return replicationTracker.getRetentionLeases(expireLeases);</b>
<i>2128</i>&nbsp;    }
<i>2129</i>&nbsp;
<i>2130</i>&nbsp;    public RetentionLeaseStats getRetentionLeaseStats() {
<b class="nc"><i>2131</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2132</i>&nbsp;        return new RetentionLeaseStats(getRetentionLeases());</b>
<i>2133</i>&nbsp;    }
<i>2134</i>&nbsp;
<i>2135</i>&nbsp;    /**
<i>2136</i>&nbsp;     * Adds a new retention lease.
<i>2137</i>&nbsp;     *
<i>2138</i>&nbsp;     * @param id                      the identifier of the retention lease
<i>2139</i>&nbsp;     * @param retainingSequenceNumber the retaining sequence number
<i>2140</i>&nbsp;     * @param source                  the source of the retention lease
<i>2141</i>&nbsp;     * @param listener                the callback when the retention lease is successfully added and synced to replicas
<i>2142</i>&nbsp;     * @return the new retention lease
<i>2143</i>&nbsp;     * @throws IllegalArgumentException if the specified retention lease already exists
<i>2144</i>&nbsp;     */
<i>2145</i>&nbsp;    public RetentionLease addRetentionLease(
<i>2146</i>&nbsp;            final String id,
<i>2147</i>&nbsp;            final long retainingSequenceNumber,
<i>2148</i>&nbsp;            final String source,
<i>2149</i>&nbsp;            final ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>2150</i>&nbsp;        Objects.requireNonNull(listener);</b>
<b class="nc"><i>2151</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2152</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2153</i>&nbsp;        ensureSoftDeletesEnabled(&quot;retention leases&quot;);</b>
<b class="nc"><i>2154</i>&nbsp;        try (Closeable ignore = acquireHistoryRetentionLock(Engine.HistorySource.INDEX)) {</b>
<i>2155</i>&nbsp;            final long actualRetainingSequenceNumber =
<b class="nc"><i>2156</i>&nbsp;                retainingSequenceNumber == RETAIN_ALL ? getMinRetainedSeqNo() : retainingSequenceNumber;</b>
<b class="nc"><i>2157</i>&nbsp;            return replicationTracker.addRetentionLease(id, actualRetainingSequenceNumber, source, listener);</b>
<b class="nc"><i>2158</i>&nbsp;        } catch (final IOException e) {</b>
<b class="nc"><i>2159</i>&nbsp;            throw new AssertionError(e);</b>
<i>2160</i>&nbsp;        }
<i>2161</i>&nbsp;    }
<i>2162</i>&nbsp;
<i>2163</i>&nbsp;    /**
<i>2164</i>&nbsp;     * Renews an existing retention lease.
<i>2165</i>&nbsp;     *
<i>2166</i>&nbsp;     * @param id                      the identifier of the retention lease
<i>2167</i>&nbsp;     * @param retainingSequenceNumber the retaining sequence number
<i>2168</i>&nbsp;     * @param source                  the source of the retention lease
<i>2169</i>&nbsp;     * @return the renewed retention lease
<i>2170</i>&nbsp;     * @throws IllegalArgumentException if the specified retention lease does not exist
<i>2171</i>&nbsp;     */
<i>2172</i>&nbsp;    public RetentionLease renewRetentionLease(final String id, final long retainingSequenceNumber, final String source) {
<b class="nc"><i>2173</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2174</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2175</i>&nbsp;        ensureSoftDeletesEnabled(&quot;retention leases&quot;);</b>
<b class="nc"><i>2176</i>&nbsp;        try (Closeable ignore = acquireHistoryRetentionLock(Engine.HistorySource.INDEX)) {</b>
<i>2177</i>&nbsp;            final long actualRetainingSequenceNumber =
<b class="nc"><i>2178</i>&nbsp;                    retainingSequenceNumber == RETAIN_ALL ? getMinRetainedSeqNo() : retainingSequenceNumber;</b>
<b class="nc"><i>2179</i>&nbsp;            return replicationTracker.renewRetentionLease(id, actualRetainingSequenceNumber, source);</b>
<b class="nc"><i>2180</i>&nbsp;        } catch (final IOException e) {</b>
<b class="nc"><i>2181</i>&nbsp;            throw new AssertionError(e);</b>
<i>2182</i>&nbsp;        }
<i>2183</i>&nbsp;    }
<i>2184</i>&nbsp;
<i>2185</i>&nbsp;    /**
<i>2186</i>&nbsp;     * Removes an existing retention lease.
<i>2187</i>&nbsp;     *
<i>2188</i>&nbsp;     * @param id       the identifier of the retention lease
<i>2189</i>&nbsp;     * @param listener the callback when the retention lease is successfully removed and synced to replicas
<i>2190</i>&nbsp;     */
<i>2191</i>&nbsp;    public void removeRetentionLease(final String id, final ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>2192</i>&nbsp;        Objects.requireNonNull(listener);</b>
<b class="nc"><i>2193</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2194</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2195</i>&nbsp;        ensureSoftDeletesEnabled(&quot;retention leases&quot;);</b>
<b class="nc"><i>2196</i>&nbsp;        replicationTracker.removeRetentionLease(id, listener);</b>
<b class="nc"><i>2197</i>&nbsp;    }</b>
<i>2198</i>&nbsp;
<i>2199</i>&nbsp;    /**
<i>2200</i>&nbsp;     * Updates retention leases on a replica.
<i>2201</i>&nbsp;     *
<i>2202</i>&nbsp;     * @param retentionLeases the retention leases
<i>2203</i>&nbsp;     */
<i>2204</i>&nbsp;    public void updateRetentionLeasesOnReplica(final RetentionLeases retentionLeases) {
<b class="fc"><i>2205</i>&nbsp;        assert assertReplicationTarget();</b>
<b class="fc"><i>2206</i>&nbsp;        verifyNotClosed();</b>
<b class="fc"><i>2207</i>&nbsp;        replicationTracker.updateRetentionLeasesOnReplica(retentionLeases);</b>
<b class="fc"><i>2208</i>&nbsp;    }</b>
<i>2209</i>&nbsp;
<i>2210</i>&nbsp;    /**
<i>2211</i>&nbsp;     * Loads the latest retention leases from their dedicated state file.
<i>2212</i>&nbsp;     *
<i>2213</i>&nbsp;     * @return the retention leases
<i>2214</i>&nbsp;     * @throws IOException if an I/O exception occurs reading the retention leases
<i>2215</i>&nbsp;     */
<i>2216</i>&nbsp;    public RetentionLeases loadRetentionLeases() throws IOException {
<b class="fc"><i>2217</i>&nbsp;        verifyNotClosed();</b>
<b class="fc"><i>2218</i>&nbsp;        return replicationTracker.loadRetentionLeases(path.getShardStatePath());</b>
<i>2219</i>&nbsp;    }
<i>2220</i>&nbsp;
<i>2221</i>&nbsp;    /**
<i>2222</i>&nbsp;     * Persists the current retention leases to their dedicated state file.
<i>2223</i>&nbsp;     *
<i>2224</i>&nbsp;     * @throws WriteStateException if an exception occurs writing the state file
<i>2225</i>&nbsp;     */
<i>2226</i>&nbsp;    public void persistRetentionLeases() throws WriteStateException {
<b class="fc"><i>2227</i>&nbsp;        verifyNotClosed();</b>
<b class="fc"><i>2228</i>&nbsp;        replicationTracker.persistRetentionLeases(path.getShardStatePath());</b>
<b class="fc"><i>2229</i>&nbsp;    }</b>
<i>2230</i>&nbsp;
<i>2231</i>&nbsp;    public boolean assertRetentionLeasesPersisted() throws IOException {
<b class="nc"><i>2232</i>&nbsp;        return replicationTracker.assertRetentionLeasesPersisted(path.getShardStatePath());</b>
<i>2233</i>&nbsp;    }
<i>2234</i>&nbsp;
<i>2235</i>&nbsp;    /**
<i>2236</i>&nbsp;     * Syncs the current retention leases to all replicas.
<i>2237</i>&nbsp;     */
<i>2238</i>&nbsp;    public void syncRetentionLeases() {
<b class="nc"><i>2239</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2240</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2241</i>&nbsp;        ensureSoftDeletesEnabled(&quot;retention leases&quot;);</b>
<b class="nc"><i>2242</i>&nbsp;        replicationTracker.renewPeerRecoveryRetentionLeases();</b>
<b class="nc"><i>2243</i>&nbsp;        final Tuple&lt;Boolean, RetentionLeases&gt; retentionLeases = getRetentionLeases(true);</b>
<b class="nc"><i>2244</i>&nbsp;        if (retentionLeases.v1()) {</b>
<b class="nc"><i>2245</i>&nbsp;            logger.trace(&quot;syncing retention leases [{}] after expiration check&quot;, retentionLeases.v2());</b>
<b class="nc"><i>2246</i>&nbsp;            retentionLeaseSyncer.sync(</b>
<i>2247</i>&nbsp;                    shardId,
<b class="nc"><i>2248</i>&nbsp;                    retentionLeases.v2(),</b>
<b class="nc"><i>2249</i>&nbsp;                    ActionListener.wrap(</b>
<b class="nc"><i>2250</i>&nbsp;                            r -&gt; {},</b>
<b class="nc"><i>2251</i>&nbsp;                            e -&gt; logger.warn(new ParameterizedMessage(</b>
<i>2252</i>&nbsp;                                            &quot;failed to sync retention leases [{}] after expiration check&quot;,
<i>2253</i>&nbsp;                                            retentionLeases),
<i>2254</i>&nbsp;                                    e)));
<i>2255</i>&nbsp;        } else {
<b class="nc"><i>2256</i>&nbsp;            logger.trace(&quot;background syncing retention leases [{}] after expiration check&quot;, retentionLeases.v2());</b>
<b class="nc"><i>2257</i>&nbsp;            retentionLeaseSyncer.backgroundSync(shardId, retentionLeases.v2());</b>
<i>2258</i>&nbsp;        }
<b class="nc"><i>2259</i>&nbsp;    }</b>
<i>2260</i>&nbsp;
<i>2261</i>&nbsp;    /**
<i>2262</i>&nbsp;     * Called when the recovery process for a shard has opened the engine on the target shard. Ensures that the right data structures
<i>2263</i>&nbsp;     * have been set up locally to track local checkpoint information for the shard and that the shard is added to the replication group.
<i>2264</i>&nbsp;     *
<i>2265</i>&nbsp;     * @param allocationId  the allocation ID of the shard for which recovery was initiated
<i>2266</i>&nbsp;     */
<i>2267</i>&nbsp;    public void initiateTracking(final String allocationId) {
<b class="nc"><i>2268</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2269</i>&nbsp;        replicationTracker.initiateTracking(allocationId);</b>
<b class="nc"><i>2270</i>&nbsp;    }</b>
<i>2271</i>&nbsp;
<i>2272</i>&nbsp;    /**
<i>2273</i>&nbsp;     * Marks the shard with the provided allocation ID as in-sync with the primary shard. See
<i>2274</i>&nbsp;     * {@link ReplicationTracker#markAllocationIdAsInSync(String, long)}
<i>2275</i>&nbsp;     * for additional details.
<i>2276</i>&nbsp;     *
<i>2277</i>&nbsp;     * @param allocationId    the allocation ID of the shard to mark as in-sync
<i>2278</i>&nbsp;     * @param localCheckpoint the current local checkpoint on the shard
<i>2279</i>&nbsp;     */
<i>2280</i>&nbsp;    public void markAllocationIdAsInSync(final String allocationId, final long localCheckpoint) throws InterruptedException {
<b class="nc"><i>2281</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2282</i>&nbsp;        replicationTracker.markAllocationIdAsInSync(allocationId, localCheckpoint);</b>
<b class="nc"><i>2283</i>&nbsp;    }</b>
<i>2284</i>&nbsp;
<i>2285</i>&nbsp;    /**
<i>2286</i>&nbsp;     * Returns the persisted local checkpoint for the shard.
<i>2287</i>&nbsp;     *
<i>2288</i>&nbsp;     * @return the local checkpoint
<i>2289</i>&nbsp;     */
<i>2290</i>&nbsp;    public long getLocalCheckpoint() {
<b class="fc"><i>2291</i>&nbsp;        return getEngine().getPersistedLocalCheckpoint();</b>
<i>2292</i>&nbsp;    }
<i>2293</i>&nbsp;
<i>2294</i>&nbsp;    /**
<i>2295</i>&nbsp;     * Returns the global checkpoint for the shard.
<i>2296</i>&nbsp;     *
<i>2297</i>&nbsp;     * @return the global checkpoint
<i>2298</i>&nbsp;     */
<i>2299</i>&nbsp;    public long getLastKnownGlobalCheckpoint() {
<b class="nc"><i>2300</i>&nbsp;        return replicationTracker.getGlobalCheckpoint();</b>
<i>2301</i>&nbsp;    }
<i>2302</i>&nbsp;
<i>2303</i>&nbsp;    /**
<i>2304</i>&nbsp;     * Returns the latest global checkpoint value that has been persisted in the underlying storage (i.e. translog&#39;s checkpoint)
<i>2305</i>&nbsp;     */
<i>2306</i>&nbsp;    public long getLastSyncedGlobalCheckpoint() {
<b class="nc"><i>2307</i>&nbsp;        return getEngine().getLastSyncedGlobalCheckpoint();</b>
<i>2308</i>&nbsp;    }
<i>2309</i>&nbsp;
<i>2310</i>&nbsp;    /**
<i>2311</i>&nbsp;     * Get the local knowledge of the global checkpoints for all in-sync allocation IDs.
<i>2312</i>&nbsp;     *
<i>2313</i>&nbsp;     * @return a map from allocation ID to the local knowledge of the global checkpoint for that allocation ID
<i>2314</i>&nbsp;     */
<i>2315</i>&nbsp;    public ObjectLongMap&lt;String&gt; getInSyncGlobalCheckpoints() {
<b class="nc"><i>2316</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2317</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2318</i>&nbsp;        return replicationTracker.getInSyncGlobalCheckpoints();</b>
<i>2319</i>&nbsp;    }
<i>2320</i>&nbsp;
<i>2321</i>&nbsp;    /**
<i>2322</i>&nbsp;     * Syncs the global checkpoint to the replicas if the global checkpoint on at least one replica is behind the global checkpoint on the
<i>2323</i>&nbsp;     * primary.
<i>2324</i>&nbsp;     */
<i>2325</i>&nbsp;    public void maybeSyncGlobalCheckpoint(final String reason) {
<b class="nc"><i>2326</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2327</i>&nbsp;        assert shardRouting.primary() : &quot;only call maybeSyncGlobalCheckpoint on primary shard&quot;;</b>
<b class="nc"><i>2328</i>&nbsp;        if (replicationTracker.isPrimaryMode() == false) {</b>
<b class="nc"><i>2329</i>&nbsp;            return;</b>
<i>2330</i>&nbsp;        }
<b class="nc"><i>2331</i>&nbsp;        assert assertPrimaryMode();</b>
<i>2332</i>&nbsp;        // only sync if there are no operations in flight, or when using async durability
<b class="nc"><i>2333</i>&nbsp;        final SeqNoStats stats = getEngine().getSeqNoStats(replicationTracker.getGlobalCheckpoint());</b>
<b class="nc"><i>2334</i>&nbsp;        final boolean asyncDurability = indexSettings().getTranslogDurability() == Translog.Durability.ASYNC;</b>
<b class="nc"><i>2335</i>&nbsp;        if (stats.getMaxSeqNo() == stats.getGlobalCheckpoint() || asyncDurability) {</b>
<b class="nc"><i>2336</i>&nbsp;            final ObjectLongMap&lt;String&gt; globalCheckpoints = getInSyncGlobalCheckpoints();</b>
<b class="nc"><i>2337</i>&nbsp;            final long globalCheckpoint = replicationTracker.getGlobalCheckpoint();</b>
<i>2338</i>&nbsp;            // async durability means that the local checkpoint might lag (as it is only advanced on fsync)
<i>2339</i>&nbsp;            // periodically ask for the newest local checkpoint by syncing the global checkpoint, so that ultimately the global
<i>2340</i>&nbsp;            // checkpoint can be synced. Also take into account that a shard might be pending sync, which means that it isn&#39;t
<i>2341</i>&nbsp;            // in the in-sync set just yet but might be blocked on waiting for its persisted local checkpoint to catch up to
<i>2342</i>&nbsp;            // the global checkpoint.
<b class="nc"><i>2343</i>&nbsp;            final boolean syncNeeded =</b>
<b class="nc"><i>2344</i>&nbsp;                (asyncDurability &amp;&amp; (stats.getGlobalCheckpoint() &lt; stats.getMaxSeqNo() || replicationTracker.pendingInSync()))</b>
<i>2345</i>&nbsp;                    // check if the persisted global checkpoint
<i>2346</i>&nbsp;                    || StreamSupport
<b class="nc"><i>2347</i>&nbsp;                            .stream(globalCheckpoints.values().spliterator(), false)</b>
<b class="nc"><i>2348</i>&nbsp;                            .anyMatch(v -&gt; v.value &lt; globalCheckpoint);</b>
<i>2349</i>&nbsp;            // only sync if index is not closed and there is a shard lagging the primary
<b class="nc"><i>2350</i>&nbsp;            if (syncNeeded &amp;&amp; indexSettings.getIndexMetaData().getState() == IndexMetaData.State.OPEN) {</b>
<b class="nc"><i>2351</i>&nbsp;                logger.trace(&quot;syncing global checkpoint for [{}]&quot;, reason);</b>
<b class="nc"><i>2352</i>&nbsp;                globalCheckpointSyncer.run();</b>
<i>2353</i>&nbsp;            }
<i>2354</i>&nbsp;        }
<b class="nc"><i>2355</i>&nbsp;    }</b>
<i>2356</i>&nbsp;
<i>2357</i>&nbsp;    /**
<i>2358</i>&nbsp;     * Returns the current replication group for the shard.
<i>2359</i>&nbsp;     *
<i>2360</i>&nbsp;     * @return the replication group
<i>2361</i>&nbsp;     */
<i>2362</i>&nbsp;    public ReplicationGroup getReplicationGroup() {
<b class="nc"><i>2363</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2364</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2365</i>&nbsp;        return replicationTracker.getReplicationGroup();</b>
<i>2366</i>&nbsp;    }
<i>2367</i>&nbsp;
<i>2368</i>&nbsp;    /**
<i>2369</i>&nbsp;     * Updates the global checkpoint on a replica shard after it has been updated by the primary.
<i>2370</i>&nbsp;     *
<i>2371</i>&nbsp;     * @param globalCheckpoint the global checkpoint
<i>2372</i>&nbsp;     * @param reason           the reason the global checkpoint was updated
<i>2373</i>&nbsp;     */
<i>2374</i>&nbsp;    public void updateGlobalCheckpointOnReplica(final long globalCheckpoint, final String reason) {
<b class="nc"><i>2375</i>&nbsp;        assert assertReplicationTarget();</b>
<b class="nc"><i>2376</i>&nbsp;        final long localCheckpoint = getLocalCheckpoint();</b>
<b class="nc"><i>2377</i>&nbsp;        if (globalCheckpoint &gt; localCheckpoint) {</b>
<i>2378</i>&nbsp;            /*
<i>2379</i>&nbsp;             * This can happen during recovery when the shard has started its engine but recovery is not finalized and is receiving global
<i>2380</i>&nbsp;             * checkpoint updates. However, since this shard is not yet contributing to calculating the global checkpoint, it can be the
<i>2381</i>&nbsp;             * case that the global checkpoint update from the primary is ahead of the local checkpoint on this shard. In this case, we
<i>2382</i>&nbsp;             * ignore the global checkpoint update. This can happen if we are in the translog stage of recovery. Prior to this, the engine
<i>2383</i>&nbsp;             * is not opened and this shard will not receive global checkpoint updates, and after this the shard will be contributing to
<i>2384</i>&nbsp;             * calculations of the global checkpoint. However, we can not assert that we are in the translog stage of recovery here as
<i>2385</i>&nbsp;             * while the global checkpoint update may have emanated from the primary when we were in that state, we could subsequently move
<i>2386</i>&nbsp;             * to recovery finalization, or even finished recovery before the update arrives here.
<i>2387</i>&nbsp;             */
<b class="nc"><i>2388</i>&nbsp;            assert state() != IndexShardState.POST_RECOVERY &amp;&amp; state() != IndexShardState.STARTED :</b>
<i>2389</i>&nbsp;                &quot;supposedly in-sync shard copy received a global checkpoint [&quot; + globalCheckpoint + &quot;] &quot; +
<i>2390</i>&nbsp;                    &quot;that is higher than its local checkpoint [&quot; + localCheckpoint + &quot;]&quot;;
<b class="nc"><i>2391</i>&nbsp;            return;</b>
<i>2392</i>&nbsp;        }
<b class="nc"><i>2393</i>&nbsp;        replicationTracker.updateGlobalCheckpointOnReplica(globalCheckpoint, reason);</b>
<b class="nc"><i>2394</i>&nbsp;    }</b>
<i>2395</i>&nbsp;
<i>2396</i>&nbsp;    /**
<i>2397</i>&nbsp;     * Updates the known allocation IDs and the local checkpoints for the corresponding allocations from a primary relocation source.
<i>2398</i>&nbsp;     *
<i>2399</i>&nbsp;     * @param primaryContext the sequence number context
<i>2400</i>&nbsp;     */
<i>2401</i>&nbsp;    public void activateWithPrimaryContext(final ReplicationTracker.PrimaryContext primaryContext) {
<b class="nc"><i>2402</i>&nbsp;        assert shardRouting.primary() &amp;&amp; shardRouting.isRelocationTarget() :</b>
<i>2403</i>&nbsp;            &quot;only primary relocation target can update allocation IDs from primary context: &quot; + shardRouting;
<b class="nc"><i>2404</i>&nbsp;        assert primaryContext.getCheckpointStates().containsKey(routingEntry().allocationId().getId()) :</b>
<b class="nc"><i>2405</i>&nbsp;            &quot;primary context [&quot; + primaryContext + &quot;] does not contain relocation target [&quot; + routingEntry() + &quot;]&quot;;</b>
<b class="nc"><i>2406</i>&nbsp;        assert getLocalCheckpoint() == primaryContext.getCheckpointStates().get(routingEntry().allocationId().getId())</b>
<b class="nc"><i>2407</i>&nbsp;            .getLocalCheckpoint() || indexSettings().getTranslogDurability() == Translog.Durability.ASYNC :</b>
<b class="nc"><i>2408</i>&nbsp;            &quot;local checkpoint [&quot; + getLocalCheckpoint() + &quot;] does not match checkpoint from primary context [&quot; + primaryContext + &quot;]&quot;;</b>
<b class="nc"><i>2409</i>&nbsp;        synchronized (mutex) {</b>
<b class="nc"><i>2410</i>&nbsp;            replicationTracker.activateWithPrimaryContext(primaryContext); // make changes to primaryMode flag only under mutex</b>
<b class="nc"><i>2411</i>&nbsp;        }</b>
<b class="nc"><i>2412</i>&nbsp;        ensurePeerRecoveryRetentionLeasesExist();</b>
<b class="nc"><i>2413</i>&nbsp;    }</b>
<i>2414</i>&nbsp;
<i>2415</i>&nbsp;    private void ensurePeerRecoveryRetentionLeasesExist() {
<b class="fc"><i>2416</i>&nbsp;        threadPool.generic().execute(() -&gt; replicationTracker.createMissingPeerRecoveryRetentionLeases(ActionListener.wrap(</b>
<b class="fc"><i>2417</i>&nbsp;            r -&gt; logger.trace(&quot;created missing peer recovery retention leases&quot;),</b>
<b class="nc"><i>2418</i>&nbsp;            e -&gt; logger.debug(&quot;failed creating missing peer recovery retention leases&quot;, e))));</b>
<b class="fc"><i>2419</i>&nbsp;    }</b>
<i>2420</i>&nbsp;
<i>2421</i>&nbsp;    /**
<i>2422</i>&nbsp;     * Check if there are any recoveries pending in-sync.
<i>2423</i>&nbsp;     *
<i>2424</i>&nbsp;     * @return {@code true} if there is at least one shard pending in-sync, otherwise false
<i>2425</i>&nbsp;     */
<i>2426</i>&nbsp;    public boolean pendingInSync() {
<b class="nc"><i>2427</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2428</i>&nbsp;        return replicationTracker.pendingInSync();</b>
<i>2429</i>&nbsp;    }
<i>2430</i>&nbsp;
<i>2431</i>&nbsp;    /**
<i>2432</i>&nbsp;     * Should be called for each no-op update operation to increment relevant statistics.
<i>2433</i>&nbsp;     *
<i>2434</i>&nbsp;     * @param type the doc type of the update
<i>2435</i>&nbsp;     */
<i>2436</i>&nbsp;    public void noopUpdate(String type) {
<b class="nc"><i>2437</i>&nbsp;        internalIndexingStats.noopUpdate(type);</b>
<b class="nc"><i>2438</i>&nbsp;    }</b>
<i>2439</i>&nbsp;
<i>2440</i>&nbsp;    public void maybeCheckIndex() {
<b class="fc"><i>2441</i>&nbsp;        recoveryState.setStage(RecoveryState.Stage.VERIFY_INDEX);</b>
<b class="fc"><i>2442</i>&nbsp;        if (Booleans.isTrue(checkIndexOnStartup) || &quot;checksum&quot;.equals(checkIndexOnStartup)) {</b>
<i>2443</i>&nbsp;            try {
<b class="nc"><i>2444</i>&nbsp;                checkIndex();</b>
<b class="nc"><i>2445</i>&nbsp;            } catch (IOException ex) {</b>
<b class="nc"><i>2446</i>&nbsp;                throw new RecoveryFailedException(recoveryState, &quot;check index failed&quot;, ex);</b>
<b class="nc"><i>2447</i>&nbsp;            }</b>
<i>2448</i>&nbsp;        }
<b class="fc"><i>2449</i>&nbsp;    }</b>
<i>2450</i>&nbsp;
<i>2451</i>&nbsp;    void checkIndex() throws IOException {
<b class="nc"><i>2452</i>&nbsp;        if (store.tryIncRef()) {</b>
<i>2453</i>&nbsp;            try {
<b class="nc"><i>2454</i>&nbsp;                doCheckIndex();</b>
<b class="nc"><i>2455</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i>2456</i>&nbsp;                store.markStoreCorrupted(e);</b>
<b class="nc"><i>2457</i>&nbsp;                throw e;</b>
<i>2458</i>&nbsp;            } finally {
<b class="nc"><i>2459</i>&nbsp;                store.decRef();</b>
<b class="nc"><i>2460</i>&nbsp;            }</b>
<i>2461</i>&nbsp;        }
<b class="nc"><i>2462</i>&nbsp;    }</b>
<i>2463</i>&nbsp;
<i>2464</i>&nbsp;    private void doCheckIndex() throws IOException {
<b class="nc"><i>2465</i>&nbsp;        long timeNS = System.nanoTime();</b>
<b class="nc"><i>2466</i>&nbsp;        if (!Lucene.indexExists(store.directory())) {</b>
<b class="nc"><i>2467</i>&nbsp;            return;</b>
<i>2468</i>&nbsp;        }
<b class="nc"><i>2469</i>&nbsp;        BytesStreamOutput os = new BytesStreamOutput();</b>
<b class="nc"><i>2470</i>&nbsp;        PrintStream out = new PrintStream(os, false, StandardCharsets.UTF_8.name());</b>
<i>2471</i>&nbsp;
<b class="nc"><i>2472</i>&nbsp;        if (&quot;checksum&quot;.equals(checkIndexOnStartup)) {</b>
<i>2473</i>&nbsp;            // physical verification only: verify all checksums for the latest commit
<b class="nc"><i>2474</i>&nbsp;            IOException corrupt = null;</b>
<b class="nc"><i>2475</i>&nbsp;            MetadataSnapshot metadata = snapshotStoreMetadata();</b>
<b class="nc"><i>2476</i>&nbsp;            for (Map.Entry&lt;String, StoreFileMetaData&gt; entry : metadata.asMap().entrySet()) {</b>
<i>2477</i>&nbsp;                try {
<b class="nc"><i>2478</i>&nbsp;                    Store.checkIntegrity(entry.getValue(), store.directory());</b>
<b class="nc"><i>2479</i>&nbsp;                    out.println(&quot;checksum passed: &quot; + entry.getKey());</b>
<b class="nc"><i>2480</i>&nbsp;                } catch (IOException exc) {</b>
<b class="nc"><i>2481</i>&nbsp;                    out.println(&quot;checksum failed: &quot; + entry.getKey());</b>
<b class="nc"><i>2482</i>&nbsp;                    exc.printStackTrace(out);</b>
<b class="nc"><i>2483</i>&nbsp;                    corrupt = exc;</b>
<b class="nc"><i>2484</i>&nbsp;                }</b>
<b class="nc"><i>2485</i>&nbsp;            }</b>
<b class="nc"><i>2486</i>&nbsp;            out.flush();</b>
<b class="nc"><i>2487</i>&nbsp;            if (corrupt != null) {</b>
<b class="nc"><i>2488</i>&nbsp;                logger.warn(&quot;check index [failure]\n{}&quot;, os.bytes().utf8ToString());</b>
<b class="nc"><i>2489</i>&nbsp;                throw corrupt;</b>
<i>2490</i>&nbsp;            }
<b class="nc"><i>2491</i>&nbsp;        } else {</b>
<i>2492</i>&nbsp;            // full checkindex
<b class="nc"><i>2493</i>&nbsp;            final CheckIndex.Status status = store.checkIndex(out);</b>
<b class="nc"><i>2494</i>&nbsp;            out.flush();</b>
<b class="nc"><i>2495</i>&nbsp;            if (!status.clean) {</b>
<b class="nc"><i>2496</i>&nbsp;                if (state == IndexShardState.CLOSED) {</b>
<i>2497</i>&nbsp;                    // ignore if closed....
<b class="nc"><i>2498</i>&nbsp;                    return;</b>
<i>2499</i>&nbsp;                }
<b class="nc"><i>2500</i>&nbsp;                logger.warn(&quot;check index [failure]\n{}&quot;, os.bytes().utf8ToString());</b>
<b class="nc"><i>2501</i>&nbsp;                throw new IOException(&quot;index check failure&quot;);</b>
<i>2502</i>&nbsp;            }
<i>2503</i>&nbsp;        }
<i>2504</i>&nbsp;
<b class="nc"><i>2505</i>&nbsp;        if (logger.isDebugEnabled()) {</b>
<b class="nc"><i>2506</i>&nbsp;            logger.debug(&quot;check index [success]\n{}&quot;, os.bytes().utf8ToString());</b>
<i>2507</i>&nbsp;        }
<i>2508</i>&nbsp;
<b class="nc"><i>2509</i>&nbsp;        recoveryState.getVerifyIndex().checkIndexTime(Math.max(0, TimeValue.nsecToMSec(System.nanoTime() - timeNS)));</b>
<b class="nc"><i>2510</i>&nbsp;    }</b>
<i>2511</i>&nbsp;
<i>2512</i>&nbsp;    Engine getEngine() {
<b class="fc"><i>2513</i>&nbsp;        Engine engine = getEngineOrNull();</b>
<b class="fc"><i>2514</i>&nbsp;        if (engine == null) {</b>
<b class="fc"><i>2515</i>&nbsp;            throw new AlreadyClosedException(&quot;engine is closed&quot;);</b>
<i>2516</i>&nbsp;        }
<b class="fc"><i>2517</i>&nbsp;        return engine;</b>
<i>2518</i>&nbsp;    }
<i>2519</i>&nbsp;
<i>2520</i>&nbsp;    /**
<i>2521</i>&nbsp;     * NOTE: returns null if engine is not yet started (e.g. recovery phase 1, copying over index files, is still running), or if engine is
<i>2522</i>&nbsp;     * closed.
<i>2523</i>&nbsp;     */
<i>2524</i>&nbsp;    protected Engine getEngineOrNull() {
<b class="fc"><i>2525</i>&nbsp;        return this.currentEngineReference.get();</b>
<i>2526</i>&nbsp;    }
<i>2527</i>&nbsp;
<i>2528</i>&nbsp;    public void startRecovery(RecoveryState recoveryState, PeerRecoveryTargetService recoveryTargetService,
<i>2529</i>&nbsp;                              PeerRecoveryTargetService.RecoveryListener recoveryListener, RepositoriesService repositoriesService,
<i>2530</i>&nbsp;                              BiConsumer&lt;String, MappingMetaData&gt; mappingUpdateConsumer,
<i>2531</i>&nbsp;                              IndicesService indicesService) {
<i>2532</i>&nbsp;        // TODO: Create a proper object to encapsulate the recovery context
<i>2533</i>&nbsp;        // all of the current methods here follow a pattern of:
<i>2534</i>&nbsp;        // resolve context which isn&#39;t really dependent on the local shards and then async
<i>2535</i>&nbsp;        // call some external method with this pointer.
<i>2536</i>&nbsp;        // with a proper recovery context object we can simply change this to:
<i>2537</i>&nbsp;        // startRecovery(RecoveryState recoveryState, ShardRecoverySource source ) {
<i>2538</i>&nbsp;        //     markAsRecovery(&quot;from &quot; + source.getShortDescription(), recoveryState);
<i>2539</i>&nbsp;        //     threadPool.generic().execute()  {
<i>2540</i>&nbsp;        //           onFailure () { listener.failure() };
<i>2541</i>&nbsp;        //           doRun() {
<i>2542</i>&nbsp;        //                if (source.recover(this)) {
<i>2543</i>&nbsp;        //                  recoveryListener.onRecoveryDone(recoveryState);
<i>2544</i>&nbsp;        //                }
<i>2545</i>&nbsp;        //           }
<i>2546</i>&nbsp;        //     }}
<i>2547</i>&nbsp;        // }
<b class="fc"><i>2548</i>&nbsp;        assert recoveryState.getRecoverySource().equals(shardRouting.recoverySource());</b>
<b class="fc"><i>2549</i>&nbsp;        switch (recoveryState.getRecoverySource().getType()) {</b>
<i>2550</i>&nbsp;            case EMPTY_STORE:
<i>2551</i>&nbsp;            case EXISTING_STORE:
<b class="fc"><i>2552</i>&nbsp;                markAsRecovering(&quot;from store&quot;, recoveryState); // mark the shard as recovering on the cluster state thread</b>
<b class="fc"><i>2553</i>&nbsp;                threadPool.generic().execute(() -&gt; {</b>
<i>2554</i>&nbsp;                    try {
<b class="fc"><i>2555</i>&nbsp;                        if (recoverFromStore()) {</b>
<b class="fc"><i>2556</i>&nbsp;                            recoveryListener.onRecoveryDone(recoveryState);</b>
<i>2557</i>&nbsp;                        }
<b class="nc"><i>2558</i>&nbsp;                    } catch (Exception e) {</b>
<b class="nc"><i>2559</i>&nbsp;                        recoveryListener.onRecoveryFailure(recoveryState,</b>
<i>2560</i>&nbsp;                            new RecoveryFailedException(recoveryState, null, e), true);
<b class="fc"><i>2561</i>&nbsp;                    }</b>
<b class="fc"><i>2562</i>&nbsp;                });</b>
<b class="fc"><i>2563</i>&nbsp;                break;</b>
<i>2564</i>&nbsp;            case PEER:
<i>2565</i>&nbsp;                try {
<b class="nc"><i>2566</i>&nbsp;                    markAsRecovering(&quot;from &quot; + recoveryState.getSourceNode(), recoveryState);</b>
<b class="nc"><i>2567</i>&nbsp;                    recoveryTargetService.startRecovery(this, recoveryState.getSourceNode(), recoveryListener);</b>
<b class="nc"><i>2568</i>&nbsp;                } catch (Exception e) {</b>
<b class="nc"><i>2569</i>&nbsp;                    failShard(&quot;corrupted preexisting index&quot;, e);</b>
<b class="nc"><i>2570</i>&nbsp;                    recoveryListener.onRecoveryFailure(recoveryState,</b>
<i>2571</i>&nbsp;                        new RecoveryFailedException(recoveryState, null, e), true);
<b class="nc"><i>2572</i>&nbsp;                }</b>
<b class="nc"><i>2573</i>&nbsp;                break;</b>
<i>2574</i>&nbsp;            case SNAPSHOT:
<b class="nc"><i>2575</i>&nbsp;                markAsRecovering(&quot;from snapshot&quot;, recoveryState); // mark the shard as recovering on the cluster state thread</b>
<b class="nc"><i>2576</i>&nbsp;                SnapshotRecoverySource recoverySource = (SnapshotRecoverySource) recoveryState.getRecoverySource();</b>
<b class="nc"><i>2577</i>&nbsp;                threadPool.generic().execute(() -&gt; {</b>
<i>2578</i>&nbsp;                    try {
<b class="nc"><i>2579</i>&nbsp;                        final Repository repository = repositoriesService.repository(recoverySource.snapshot().getRepository());</b>
<b class="nc"><i>2580</i>&nbsp;                        if (restoreFromRepository(repository)) {</b>
<b class="nc"><i>2581</i>&nbsp;                            recoveryListener.onRecoveryDone(recoveryState);</b>
<i>2582</i>&nbsp;                        }
<b class="nc"><i>2583</i>&nbsp;                    } catch (Exception e) {</b>
<b class="nc"><i>2584</i>&nbsp;                        recoveryListener.onRecoveryFailure(recoveryState,</b>
<i>2585</i>&nbsp;                            new RecoveryFailedException(recoveryState, null, e), true);
<b class="nc"><i>2586</i>&nbsp;                    }</b>
<b class="nc"><i>2587</i>&nbsp;                });</b>
<b class="nc"><i>2588</i>&nbsp;                break;</b>
<i>2589</i>&nbsp;            case LOCAL_SHARDS:
<b class="nc"><i>2590</i>&nbsp;                final IndexMetaData indexMetaData = indexSettings().getIndexMetaData();</b>
<b class="nc"><i>2591</i>&nbsp;                final Index resizeSourceIndex = indexMetaData.getResizeSourceIndex();</b>
<b class="nc"><i>2592</i>&nbsp;                final List&lt;IndexShard&gt; startedShards = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>2593</i>&nbsp;                final IndexService sourceIndexService = indicesService.indexService(resizeSourceIndex);</b>
<i>2594</i>&nbsp;                final Set&lt;ShardId&gt; requiredShards;
<i>2595</i>&nbsp;                final int numShards;
<b class="nc"><i>2596</i>&nbsp;                if (sourceIndexService != null) {</b>
<b class="nc"><i>2597</i>&nbsp;                    requiredShards = IndexMetaData.selectRecoverFromShards(shardId().id(),</b>
<b class="nc"><i>2598</i>&nbsp;                        sourceIndexService.getMetaData(), indexMetaData.getNumberOfShards());</b>
<b class="nc"><i>2599</i>&nbsp;                    for (IndexShard shard : sourceIndexService) {</b>
<b class="nc"><i>2600</i>&nbsp;                        if (shard.state() == IndexShardState.STARTED &amp;&amp; requiredShards.contains(shard.shardId())) {</b>
<b class="nc"><i>2601</i>&nbsp;                            startedShards.add(shard);</b>
<i>2602</i>&nbsp;                        }
<b class="nc"><i>2603</i>&nbsp;                    }</b>
<b class="nc"><i>2604</i>&nbsp;                    numShards = requiredShards.size();</b>
<i>2605</i>&nbsp;                } else {
<b class="nc"><i>2606</i>&nbsp;                    numShards = -1;</b>
<b class="nc"><i>2607</i>&nbsp;                    requiredShards = Collections.emptySet();</b>
<i>2608</i>&nbsp;                }
<i>2609</i>&nbsp;
<b class="nc"><i>2610</i>&nbsp;                if (numShards == startedShards.size()) {</b>
<b class="nc"><i>2611</i>&nbsp;                    assert requiredShards.isEmpty() == false;</b>
<b class="nc"><i>2612</i>&nbsp;                    markAsRecovering(&quot;from local shards&quot;, recoveryState); // mark the shard as recovering on the cluster state thread</b>
<b class="nc"><i>2613</i>&nbsp;                    threadPool.generic().execute(() -&gt; {</b>
<i>2614</i>&nbsp;                        try {
<b class="nc"><i>2615</i>&nbsp;                            if (recoverFromLocalShards(mappingUpdateConsumer, startedShards.stream()</b>
<b class="nc"><i>2616</i>&nbsp;                                .filter((s) -&gt; requiredShards.contains(s.shardId())).collect(Collectors.toList()))) {</b>
<b class="nc"><i>2617</i>&nbsp;                                recoveryListener.onRecoveryDone(recoveryState);</b>
<i>2618</i>&nbsp;                            }
<b class="nc"><i>2619</i>&nbsp;                        } catch (Exception e) {</b>
<b class="nc"><i>2620</i>&nbsp;                            recoveryListener.onRecoveryFailure(recoveryState,</b>
<i>2621</i>&nbsp;                                new RecoveryFailedException(recoveryState, null, e), true);
<b class="nc"><i>2622</i>&nbsp;                        }</b>
<b class="nc"><i>2623</i>&nbsp;                    });</b>
<i>2624</i>&nbsp;                } else {
<i>2625</i>&nbsp;                    final RuntimeException e;
<b class="nc"><i>2626</i>&nbsp;                    if (numShards == -1) {</b>
<b class="nc"><i>2627</i>&nbsp;                        e = new IndexNotFoundException(resizeSourceIndex);</b>
<i>2628</i>&nbsp;                    } else {
<b class="nc"><i>2629</i>&nbsp;                        e = new IllegalStateException(&quot;not all required shards of index &quot; + resizeSourceIndex</b>
<b class="nc"><i>2630</i>&nbsp;                            + &quot; are started yet, expected &quot; + numShards + &quot; found &quot; + startedShards.size() + &quot; can&#39;t recover shard &quot;</b>
<b class="nc"><i>2631</i>&nbsp;                            + shardId());</b>
<i>2632</i>&nbsp;                    }
<b class="nc"><i>2633</i>&nbsp;                    throw e;</b>
<i>2634</i>&nbsp;                }
<i>2635</i>&nbsp;                break;
<i>2636</i>&nbsp;            default:
<b class="nc"><i>2637</i>&nbsp;                throw new IllegalArgumentException(&quot;Unknown recovery source &quot; + recoveryState.getRecoverySource());</b>
<i>2638</i>&nbsp;        }
<b class="fc"><i>2639</i>&nbsp;    }</b>
<i>2640</i>&nbsp;
<i>2641</i>&nbsp;    /**
<i>2642</i>&nbsp;     * Returns whether the shard is a relocated primary, i.e. not in charge anymore of replicating changes (see {@link ReplicationTracker}).
<i>2643</i>&nbsp;     */
<i>2644</i>&nbsp;    public boolean isRelocatedPrimary() {
<b class="nc"><i>2645</i>&nbsp;        assert shardRouting.primary() : &quot;only call isRelocatedPrimary on primary shard&quot;;</b>
<b class="nc"><i>2646</i>&nbsp;        return replicationTracker.isRelocated();</b>
<i>2647</i>&nbsp;    }
<i>2648</i>&nbsp;
<i>2649</i>&nbsp;    public RetentionLease addPeerRecoveryRetentionLease(String nodeId, long globalCheckpoint,
<i>2650</i>&nbsp;                                                        ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>2651</i>&nbsp;        assert assertPrimaryMode();</b>
<i>2652</i>&nbsp;        // only needed for BWC reasons involving rolling upgrades from versions that do not support PRRLs:
<b class="nc"><i>2653</i>&nbsp;        assert indexSettings.getIndexVersionCreated().before(Version.V_7_4_0);</b>
<b class="nc"><i>2654</i>&nbsp;        return replicationTracker.addPeerRecoveryRetentionLease(nodeId, globalCheckpoint, listener);</b>
<i>2655</i>&nbsp;    }
<i>2656</i>&nbsp;
<i>2657</i>&nbsp;    public RetentionLease cloneLocalPeerRecoveryRetentionLease(String nodeId, ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>2658</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2659</i>&nbsp;        return replicationTracker.cloneLocalPeerRecoveryRetentionLease(nodeId, listener);</b>
<i>2660</i>&nbsp;    }
<i>2661</i>&nbsp;
<i>2662</i>&nbsp;    public void removePeerRecoveryRetentionLease(String nodeId, ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>2663</i>&nbsp;        assert assertPrimaryMode();</b>
<b class="nc"><i>2664</i>&nbsp;        replicationTracker.removePeerRecoveryRetentionLease(nodeId, listener);</b>
<b class="nc"><i>2665</i>&nbsp;    }</b>
<i>2666</i>&nbsp;
<i>2667</i>&nbsp;    /**
<i>2668</i>&nbsp;     * Returns a list of retention leases for peer recovery installed in this shard copy.
<i>2669</i>&nbsp;     */
<i>2670</i>&nbsp;    public List&lt;RetentionLease&gt; getPeerRecoveryRetentionLeases() {
<b class="nc"><i>2671</i>&nbsp;        return replicationTracker.getPeerRecoveryRetentionLeases();</b>
<i>2672</i>&nbsp;    }
<i>2673</i>&nbsp;
<i>2674</i>&nbsp;    public boolean useRetentionLeasesInPeerRecovery() {
<b class="nc"><i>2675</i>&nbsp;        return useRetentionLeasesInPeerRecovery;</b>
<i>2676</i>&nbsp;    }
<i>2677</i>&nbsp;
<i>2678</i>&nbsp;    private SafeCommitInfo getSafeCommitInfo() {
<b class="nc"><i>2679</i>&nbsp;        final Engine engine = getEngineOrNull();</b>
<b class="nc"><i>2680</i>&nbsp;        return engine == null ? SafeCommitInfo.EMPTY : engine.getSafeCommitInfo();</b>
<i>2681</i>&nbsp;    }
<i>2682</i>&nbsp;
<b class="fc"><i>2683</i>&nbsp;    class ShardEventListener implements Engine.EventListener {</b>
<b class="fc"><i>2684</i>&nbsp;        private final CopyOnWriteArrayList&lt;Consumer&lt;ShardFailure&gt;&gt; delegates = new CopyOnWriteArrayList&lt;&gt;();</b>
<i>2685</i>&nbsp;
<i>2686</i>&nbsp;        // called by the current engine
<i>2687</i>&nbsp;        @Override
<i>2688</i>&nbsp;        public void onFailedEngine(String reason, @Nullable Exception failure) {
<b class="nc"><i>2689</i>&nbsp;            final ShardFailure shardFailure = new ShardFailure(shardRouting, reason, failure);</b>
<b class="nc"><i>2690</i>&nbsp;            for (Consumer&lt;ShardFailure&gt; listener : delegates) {</b>
<i>2691</i>&nbsp;                try {
<b class="nc"><i>2692</i>&nbsp;                    listener.accept(shardFailure);</b>
<b class="nc"><i>2693</i>&nbsp;                } catch (Exception inner) {</b>
<b class="nc"><i>2694</i>&nbsp;                    inner.addSuppressed(failure);</b>
<b class="nc"><i>2695</i>&nbsp;                    logger.warn(&quot;exception while notifying engine failure&quot;, inner);</b>
<b class="nc"><i>2696</i>&nbsp;                }</b>
<b class="nc"><i>2697</i>&nbsp;            }</b>
<b class="nc"><i>2698</i>&nbsp;        }</b>
<i>2699</i>&nbsp;    }
<i>2700</i>&nbsp;
<i>2701</i>&nbsp;    private static void persistMetadata(
<i>2702</i>&nbsp;            final ShardPath shardPath,
<i>2703</i>&nbsp;            final IndexSettings indexSettings,
<i>2704</i>&nbsp;            final ShardRouting newRouting,
<i>2705</i>&nbsp;            final @Nullable ShardRouting currentRouting,
<i>2706</i>&nbsp;            final Logger logger) throws IOException {
<b class="fc"><i>2707</i>&nbsp;        assert newRouting != null : &quot;newRouting must not be null&quot;;</b>
<i>2708</i>&nbsp;
<i>2709</i>&nbsp;        // only persist metadata if routing information that is persisted in shard state metadata actually changed
<b class="fc"><i>2710</i>&nbsp;        final ShardId shardId = newRouting.shardId();</b>
<b class="fc"><i>2711</i>&nbsp;        if (currentRouting == null</b>
<b class="fc"><i>2712</i>&nbsp;            || currentRouting.primary() != newRouting.primary()</b>
<b class="fc"><i>2713</i>&nbsp;            || currentRouting.allocationId().equals(newRouting.allocationId()) == false) {</b>
<b class="fc"><i>2714</i>&nbsp;            assert currentRouting == null || currentRouting.isSameAllocation(newRouting);</b>
<i>2715</i>&nbsp;            final String writeReason;
<b class="fc"><i>2716</i>&nbsp;            if (currentRouting == null) {</b>
<b class="fc"><i>2717</i>&nbsp;                writeReason = &quot;initial state with allocation id [&quot; + newRouting.allocationId() + &quot;]&quot;;</b>
<i>2718</i>&nbsp;            } else {
<b class="nc"><i>2719</i>&nbsp;                writeReason = &quot;routing changed from &quot; + currentRouting + &quot; to &quot; + newRouting;</b>
<i>2720</i>&nbsp;            }
<b class="fc"><i>2721</i>&nbsp;            logger.trace(&quot;{} writing shard state, reason [{}]&quot;, shardId, writeReason);</b>
<b class="fc"><i>2722</i>&nbsp;            final ShardStateMetaData newShardStateMetadata =</b>
<b class="fc"><i>2723</i>&nbsp;                    new ShardStateMetaData(newRouting.primary(), indexSettings.getUUID(), newRouting.allocationId());</b>
<b class="fc"><i>2724</i>&nbsp;            ShardStateMetaData.FORMAT.writeAndCleanup(newShardStateMetadata, shardPath.getShardStatePath());</b>
<b class="fc"><i>2725</i>&nbsp;        } else {</b>
<b class="fc"><i>2726</i>&nbsp;            logger.trace(&quot;{} skip writing shard state, has been written before&quot;, shardId);</b>
<i>2727</i>&nbsp;        }
<b class="fc"><i>2728</i>&nbsp;    }</b>
<i>2729</i>&nbsp;
<i>2730</i>&nbsp;
<i>2731</i>&nbsp;    private DocumentMapperForType docMapper(String type) {
<b class="nc"><i>2732</i>&nbsp;        return mapperService.documentMapperWithAutoCreate(</b>
<b class="nc"><i>2733</i>&nbsp;            mapperService.resolveDocumentType(type));</b>
<i>2734</i>&nbsp;    }
<i>2735</i>&nbsp;
<i>2736</i>&nbsp;    private EngineConfig newEngineConfig(LongSupplier globalCheckpointSupplier) {
<b class="fc"><i>2737</i>&nbsp;        final Sort indexSort = indexSortSupplier.get();</b>
<b class="fc"><i>2738</i>&nbsp;        final Engine.Warmer warmer = reader -&gt; {</b>
<b class="fc"><i>2739</i>&nbsp;            assert Thread.holdsLock(mutex) == false : &quot;warming engine under mutex&quot;;</b>
<b class="fc"><i>2740</i>&nbsp;            assert reader != null;</b>
<b class="fc"><i>2741</i>&nbsp;            if (this.warmer != null) {</b>
<b class="fc"><i>2742</i>&nbsp;                this.warmer.warm(reader);</b>
<i>2743</i>&nbsp;            }
<b class="fc"><i>2744</i>&nbsp;        };</b>
<b class="fc"><i>2745</i>&nbsp;        return new EngineConfig(shardId, shardRouting.allocationId().getId(),</b>
<b class="fc"><i>2746</i>&nbsp;                threadPool, indexSettings, warmer, store, indexSettings.getMergePolicy(),</b>
<b class="fc"><i>2747</i>&nbsp;                mapperService != null ? mapperService.indexAnalyzer() : null,</b>
<b class="fc"><i>2748</i>&nbsp;                similarityService.similarity(mapperService), codecService, shardEventListener,</b>
<b class="fc"><i>2749</i>&nbsp;                indexCache != null ? indexCache.query() : null, cachingPolicy, translogConfig,</b>
<b class="fc"><i>2750</i>&nbsp;                IndexingMemoryController.SHARD_INACTIVE_TIME_SETTING.get(indexSettings.getSettings()),</b>
<b class="fc"><i>2751</i>&nbsp;                Collections.singletonList(refreshListeners),</b>
<b class="fc"><i>2752</i>&nbsp;                Collections.singletonList(new RefreshMetricUpdater(refreshMetric)),</b>
<b class="fc"><i>2753</i>&nbsp;                indexSort, circuitBreakerService, globalCheckpointSupplier, replicationTracker::getRetentionLeases,</b>
<b class="fc"><i>2754</i>&nbsp;                () -&gt; getOperationPrimaryTerm(), tombstoneDocSupplier());</b>
<i>2755</i>&nbsp;    }
<i>2756</i>&nbsp;
<i>2757</i>&nbsp;    /**
<i>2758</i>&nbsp;     * Acquire a primary operation permit whenever the shard is ready for indexing. If a permit is directly available, the provided
<i>2759</i>&nbsp;     * ActionListener will be called on the calling thread. During relocation hand-off, permit acquisition can be delayed. The provided
<i>2760</i>&nbsp;     * ActionListener will then be called using the provided executor.
<i>2761</i>&nbsp;     *
<i>2762</i>&nbsp;     * @param debugInfo an extra information that can be useful when tracing an unreleased permit. When assertions are enabled
<i>2763</i>&nbsp;     *                  the tracing will capture the supplied object&#39;s {@link Object#toString()} value. Otherwise the object
<i>2764</i>&nbsp;     *                  isn&#39;t used
<i>2765</i>&nbsp;     */
<i>2766</i>&nbsp;    public void acquirePrimaryOperationPermit(ActionListener&lt;Releasable&gt; onPermitAcquired, String executorOnDelay, Object debugInfo) {
<b class="nc"><i>2767</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2768</i>&nbsp;        assert shardRouting.primary() : &quot;acquirePrimaryOperationPermit should only be called on primary shard: &quot; + shardRouting;</b>
<i>2769</i>&nbsp;
<b class="nc"><i>2770</i>&nbsp;        indexShardOperationPermits.acquire(wrapPrimaryOperationPermitListener(onPermitAcquired), executorOnDelay, false, debugInfo);</b>
<b class="nc"><i>2771</i>&nbsp;    }</b>
<i>2772</i>&nbsp;
<i>2773</i>&nbsp;    /**
<i>2774</i>&nbsp;     * Acquire all primary operation permits. Once all permits are acquired, the provided ActionListener is called.
<i>2775</i>&nbsp;     * It is the responsibility of the caller to close the {@link Releasable}.
<i>2776</i>&nbsp;     */
<i>2777</i>&nbsp;    public void acquireAllPrimaryOperationsPermits(final ActionListener&lt;Releasable&gt; onPermitAcquired, final TimeValue timeout) {
<b class="nc"><i>2778</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2779</i>&nbsp;        assert shardRouting.primary() : &quot;acquireAllPrimaryOperationsPermits should only be called on primary shard: &quot; + shardRouting;</b>
<i>2780</i>&nbsp;
<b class="nc"><i>2781</i>&nbsp;        asyncBlockOperations(wrapPrimaryOperationPermitListener(onPermitAcquired), timeout.duration(), timeout.timeUnit());</b>
<b class="nc"><i>2782</i>&nbsp;    }</b>
<i>2783</i>&nbsp;
<i>2784</i>&nbsp;    /**
<i>2785</i>&nbsp;     * Wraps the action to run on a primary after acquiring permit. This wrapping is used to check if the shard is in primary mode before
<i>2786</i>&nbsp;     * executing the action.
<i>2787</i>&nbsp;     *
<i>2788</i>&nbsp;     * @param listener the listener to wrap
<i>2789</i>&nbsp;     * @return the wrapped listener
<i>2790</i>&nbsp;     */
<i>2791</i>&nbsp;    private ActionListener&lt;Releasable&gt; wrapPrimaryOperationPermitListener(final ActionListener&lt;Releasable&gt; listener) {
<b class="nc"><i>2792</i>&nbsp;        return ActionListener.delegateFailure(</b>
<i>2793</i>&nbsp;                listener,
<i>2794</i>&nbsp;                (l, r) -&gt; {
<b class="nc"><i>2795</i>&nbsp;                    if (replicationTracker.isPrimaryMode()) {</b>
<b class="nc"><i>2796</i>&nbsp;                        l.onResponse(r);</b>
<i>2797</i>&nbsp;                    } else {
<b class="nc"><i>2798</i>&nbsp;                        r.close();</b>
<b class="nc"><i>2799</i>&nbsp;                        l.onFailure(new ShardNotInPrimaryModeException(shardId, state));</b>
<i>2800</i>&nbsp;                    }
<b class="nc"><i>2801</i>&nbsp;                });</b>
<i>2802</i>&nbsp;    }
<i>2803</i>&nbsp;
<i>2804</i>&nbsp;    private void asyncBlockOperations(ActionListener&lt;Releasable&gt; onPermitAcquired, long timeout, TimeUnit timeUnit) {
<b class="nc"><i>2805</i>&nbsp;        final Releasable forceRefreshes = refreshListeners.forceRefreshes();</b>
<b class="nc"><i>2806</i>&nbsp;        final ActionListener&lt;Releasable&gt; wrappedListener = ActionListener.wrap(r -&gt; {</b>
<b class="nc"><i>2807</i>&nbsp;            forceRefreshes.close();</b>
<b class="nc"><i>2808</i>&nbsp;            onPermitAcquired.onResponse(r);</b>
<b class="nc"><i>2809</i>&nbsp;        }, e -&gt; {</b>
<b class="nc"><i>2810</i>&nbsp;            forceRefreshes.close();</b>
<b class="nc"><i>2811</i>&nbsp;            onPermitAcquired.onFailure(e);</b>
<b class="nc"><i>2812</i>&nbsp;        });</b>
<i>2813</i>&nbsp;        try {
<b class="nc"><i>2814</i>&nbsp;            indexShardOperationPermits.asyncBlockOperations(wrappedListener, timeout, timeUnit);</b>
<b class="nc"><i>2815</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>2816</i>&nbsp;            forceRefreshes.close();</b>
<b class="nc"><i>2817</i>&nbsp;            throw e;</b>
<b class="nc"><i>2818</i>&nbsp;        }</b>
<b class="nc"><i>2819</i>&nbsp;    }</b>
<i>2820</i>&nbsp;
<i>2821</i>&nbsp;    /**
<i>2822</i>&nbsp;     * Runs the specified runnable under a permit and otherwise calling back the specified failure callback. This method is really a
<i>2823</i>&nbsp;     * convenience for {@link #acquirePrimaryOperationPermit(ActionListener, String, Object)} where the listener equates to
<i>2824</i>&nbsp;     * try-with-resources closing the releasable after executing the runnable on successfully acquiring the permit, an otherwise calling
<i>2825</i>&nbsp;     * back the failure callback.
<i>2826</i>&nbsp;     *
<i>2827</i>&nbsp;     * @param runnable the runnable to execute under permit
<i>2828</i>&nbsp;     * @param onFailure the callback on failure
<i>2829</i>&nbsp;     * @param executorOnDelay the executor to execute the runnable on if permit acquisition is blocked
<i>2830</i>&nbsp;     * @param debugInfo debug info
<i>2831</i>&nbsp;     */
<i>2832</i>&nbsp;    public void runUnderPrimaryPermit(
<i>2833</i>&nbsp;            final Runnable runnable,
<i>2834</i>&nbsp;            final Consumer&lt;Exception&gt; onFailure,
<i>2835</i>&nbsp;            final String executorOnDelay,
<i>2836</i>&nbsp;            final Object debugInfo) {
<b class="nc"><i>2837</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>2838</i>&nbsp;        assert shardRouting.primary() : &quot;runUnderPrimaryPermit should only be called on primary shard but was &quot; + shardRouting;</b>
<b class="nc"><i>2839</i>&nbsp;        final ActionListener&lt;Releasable&gt; onPermitAcquired = ActionListener.wrap(</b>
<i>2840</i>&nbsp;                releasable -&gt; {
<b class="nc"><i>2841</i>&nbsp;                    try (Releasable ignore = releasable) {</b>
<b class="nc"><i>2842</i>&nbsp;                        runnable.run();</b>
<b class="nc"><i>2843</i>&nbsp;                    }</b>
<b class="nc"><i>2844</i>&nbsp;                },</b>
<i>2845</i>&nbsp;                onFailure);
<b class="nc"><i>2846</i>&nbsp;        acquirePrimaryOperationPermit(onPermitAcquired, executorOnDelay, debugInfo);</b>
<b class="nc"><i>2847</i>&nbsp;    }</b>
<i>2848</i>&nbsp;
<i>2849</i>&nbsp;    private &lt;E extends Exception&gt; void bumpPrimaryTerm(final long newPrimaryTerm,
<i>2850</i>&nbsp;                                                       final CheckedRunnable&lt;E&gt; onBlocked,
<i>2851</i>&nbsp;                                                       @Nullable ActionListener&lt;Releasable&gt; combineWithAction) {
<b class="nc"><i>2852</i>&nbsp;        assert Thread.holdsLock(mutex);</b>
<b class="nc"><i>2853</i>&nbsp;        assert newPrimaryTerm &gt; pendingPrimaryTerm || (newPrimaryTerm &gt;= pendingPrimaryTerm &amp;&amp; combineWithAction != null);</b>
<b class="nc"><i>2854</i>&nbsp;        assert getOperationPrimaryTerm() &lt;= pendingPrimaryTerm;</b>
<b class="nc"><i>2855</i>&nbsp;        final CountDownLatch termUpdated = new CountDownLatch(1);</b>
<b class="nc"><i>2856</i>&nbsp;        asyncBlockOperations(new ActionListener&lt;Releasable&gt;() {</b>
<i>2857</i>&nbsp;            @Override
<i>2858</i>&nbsp;            public void onFailure(final Exception e) {
<i>2859</i>&nbsp;                try {
<i>2860</i>&nbsp;                    innerFail(e);
<i>2861</i>&nbsp;                } finally {
<i>2862</i>&nbsp;                    if (combineWithAction != null) {
<i>2863</i>&nbsp;                        combineWithAction.onFailure(e);
<i>2864</i>&nbsp;                    }
<i>2865</i>&nbsp;                }
<i>2866</i>&nbsp;            }
<i>2867</i>&nbsp;
<i>2868</i>&nbsp;            private void innerFail(final Exception e) {
<i>2869</i>&nbsp;                try {
<i>2870</i>&nbsp;                    failShard(&quot;exception during primary term transition&quot;, e);
<i>2871</i>&nbsp;                } catch (AlreadyClosedException ace) {
<i>2872</i>&nbsp;                    // ignore, shard is already closed
<i>2873</i>&nbsp;                }
<i>2874</i>&nbsp;            }
<i>2875</i>&nbsp;
<i>2876</i>&nbsp;            @Override
<i>2877</i>&nbsp;            public void onResponse(final Releasable releasable) {
<i>2878</i>&nbsp;                final RunOnce releaseOnce = new RunOnce(releasable::close);
<i>2879</i>&nbsp;                try {
<i>2880</i>&nbsp;                    assert getOperationPrimaryTerm() &lt;= pendingPrimaryTerm;
<i>2881</i>&nbsp;                    termUpdated.await();
<i>2882</i>&nbsp;                    // indexShardOperationPermits doesn&#39;t guarantee that async submissions are executed
<i>2883</i>&nbsp;                    // in the order submitted. We need to guard against another term bump
<i>2884</i>&nbsp;                    if (getOperationPrimaryTerm() &lt; newPrimaryTerm) {
<i>2885</i>&nbsp;                        replicationTracker.setOperationPrimaryTerm(newPrimaryTerm);
<i>2886</i>&nbsp;                        onBlocked.run();
<i>2887</i>&nbsp;                    }
<i>2888</i>&nbsp;                } catch (final Exception e) {
<i>2889</i>&nbsp;                    if (combineWithAction == null) {
<i>2890</i>&nbsp;                        // otherwise leave it to combineWithAction to release the permit
<i>2891</i>&nbsp;                        releaseOnce.run();
<i>2892</i>&nbsp;                    }
<i>2893</i>&nbsp;                    innerFail(e);
<i>2894</i>&nbsp;                } finally {
<i>2895</i>&nbsp;                    if (combineWithAction != null) {
<i>2896</i>&nbsp;                        combineWithAction.onResponse(releasable);
<i>2897</i>&nbsp;                    } else {
<i>2898</i>&nbsp;                        releaseOnce.run();
<i>2899</i>&nbsp;                    }
<i>2900</i>&nbsp;                }
<i>2901</i>&nbsp;            }
<i>2902</i>&nbsp;        }, 30, TimeUnit.MINUTES);
<b class="nc"><i>2903</i>&nbsp;        pendingPrimaryTerm = newPrimaryTerm;</b>
<b class="nc"><i>2904</i>&nbsp;        termUpdated.countDown();</b>
<b class="nc"><i>2905</i>&nbsp;    }</b>
<i>2906</i>&nbsp;
<i>2907</i>&nbsp;    /**
<i>2908</i>&nbsp;     * Acquire a replica operation permit whenever the shard is ready for indexing (see
<i>2909</i>&nbsp;     * {@link #acquirePrimaryOperationPermit(ActionListener, String, Object)}). If the given primary term is lower than then one in
<i>2910</i>&nbsp;     * {@link #shardRouting}, the {@link ActionListener#onFailure(Exception)} method of the provided listener is invoked with an
<i>2911</i>&nbsp;     * {@link IllegalStateException}. If permit acquisition is delayed, the listener will be invoked on the executor with the specified
<i>2912</i>&nbsp;     * name.
<i>2913</i>&nbsp;     *
<i>2914</i>&nbsp;     * @param opPrimaryTerm              the operation primary term
<i>2915</i>&nbsp;     * @param globalCheckpoint           the global checkpoint associated with the request
<i>2916</i>&nbsp;     * @param maxSeqNoOfUpdatesOrDeletes the max seq_no of updates (index operations overwrite Lucene) or deletes captured on the primary
<i>2917</i>&nbsp;     *                                   after this replication request was executed on it (see {@link #getMaxSeqNoOfUpdatesOrDeletes()}
<i>2918</i>&nbsp;     * @param onPermitAcquired           the listener for permit acquisition
<i>2919</i>&nbsp;     * @param executorOnDelay            the name of the executor to invoke the listener on if permit acquisition is delayed
<i>2920</i>&nbsp;     * @param debugInfo                  an extra information that can be useful when tracing an unreleased permit. When assertions are
<i>2921</i>&nbsp;     *                                   enabled the tracing will capture the supplied object&#39;s {@link Object#toString()} value.
<i>2922</i>&nbsp;     *                                   Otherwise the object isn&#39;t used
<i>2923</i>&nbsp;     */
<i>2924</i>&nbsp;    public void acquireReplicaOperationPermit(final long opPrimaryTerm, final long globalCheckpoint, final long maxSeqNoOfUpdatesOrDeletes,
<i>2925</i>&nbsp;                                              final ActionListener&lt;Releasable&gt; onPermitAcquired, final String executorOnDelay,
<i>2926</i>&nbsp;                                              final Object debugInfo) {
<b class="nc"><i>2927</i>&nbsp;        innerAcquireReplicaOperationPermit(opPrimaryTerm, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes, onPermitAcquired, false,</b>
<b class="nc"><i>2928</i>&nbsp;            (listener) -&gt; indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo));</b>
<b class="nc"><i>2929</i>&nbsp;    }</b>
<i>2930</i>&nbsp;
<i>2931</i>&nbsp;    /**
<i>2932</i>&nbsp;     * Acquire all replica operation permits whenever the shard is ready for indexing (see
<i>2933</i>&nbsp;     * {@link #acquireAllPrimaryOperationsPermits(ActionListener, TimeValue)}. If the given primary term is lower than then one in
<i>2934</i>&nbsp;     * {@link #shardRouting}, the {@link ActionListener#onFailure(Exception)} method of the provided listener is invoked with an
<i>2935</i>&nbsp;     * {@link IllegalStateException}.
<i>2936</i>&nbsp;     *
<i>2937</i>&nbsp;     * @param opPrimaryTerm              the operation primary term
<i>2938</i>&nbsp;     * @param globalCheckpoint           the global checkpoint associated with the request
<i>2939</i>&nbsp;     * @param maxSeqNoOfUpdatesOrDeletes the max seq_no of updates (index operations overwrite Lucene) or deletes captured on the primary
<i>2940</i>&nbsp;     *                                   after this replication request was executed on it (see {@link #getMaxSeqNoOfUpdatesOrDeletes()}
<i>2941</i>&nbsp;     * @param onPermitAcquired           the listener for permit acquisition
<i>2942</i>&nbsp;     * @param timeout                    the maximum time to wait for the in-flight operations block
<i>2943</i>&nbsp;     */
<i>2944</i>&nbsp;    public void acquireAllReplicaOperationsPermits(final long opPrimaryTerm,
<i>2945</i>&nbsp;                                                   final long globalCheckpoint,
<i>2946</i>&nbsp;                                                   final long maxSeqNoOfUpdatesOrDeletes,
<i>2947</i>&nbsp;                                                   final ActionListener&lt;Releasable&gt; onPermitAcquired,
<i>2948</i>&nbsp;                                                   final TimeValue timeout) {
<b class="nc"><i>2949</i>&nbsp;        innerAcquireReplicaOperationPermit(opPrimaryTerm, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes,</b>
<i>2950</i>&nbsp;            onPermitAcquired, true,
<b class="nc"><i>2951</i>&nbsp;            listener -&gt; asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit())</b>
<i>2952</i>&nbsp;        );
<b class="nc"><i>2953</i>&nbsp;    }</b>
<i>2954</i>&nbsp;
<i>2955</i>&nbsp;    private void innerAcquireReplicaOperationPermit(final long opPrimaryTerm,
<i>2956</i>&nbsp;                                                    final long globalCheckpoint,
<i>2957</i>&nbsp;                                                    final long maxSeqNoOfUpdatesOrDeletes,
<i>2958</i>&nbsp;                                                    final ActionListener&lt;Releasable&gt; onPermitAcquired,
<i>2959</i>&nbsp;                                                    final boolean allowCombineOperationWithPrimaryTermUpdate,
<i>2960</i>&nbsp;                                                    final Consumer&lt;ActionListener&lt;Releasable&gt;&gt; operationExecutor) {
<b class="nc"><i>2961</i>&nbsp;        verifyNotClosed();</b>
<i>2962</i>&nbsp;
<i>2963</i>&nbsp;        // This listener is used for the execution of the operation. If the operation requires all the permits for its
<i>2964</i>&nbsp;        // execution and the primary term must be updated first, we can combine the operation execution with the
<i>2965</i>&nbsp;        // primary term update. Since indexShardOperationPermits doesn&#39;t guarantee that async submissions are executed
<i>2966</i>&nbsp;        // in the order submitted, combining both operations ensure that the term is updated before the operation is
<i>2967</i>&nbsp;        // executed. It also has the side effect of acquiring all the permits one time instead of two.
<b class="nc"><i>2968</i>&nbsp;        final ActionListener&lt;Releasable&gt; operationListener = ActionListener.delegateFailure(onPermitAcquired,</b>
<i>2969</i>&nbsp;            (delegatedListener, releasable) -&gt; {
<b class="nc"><i>2970</i>&nbsp;                if (opPrimaryTerm &lt; getOperationPrimaryTerm()) {</b>
<b class="nc"><i>2971</i>&nbsp;                    releasable.close();</b>
<b class="nc"><i>2972</i>&nbsp;                    final String message = String.format(</b>
<i>2973</i>&nbsp;                        Locale.ROOT,
<i>2974</i>&nbsp;                        &quot;%s operation primary term [%d] is too old (current [%d])&quot;,
<i>2975</i>&nbsp;                        shardId,
<b class="nc"><i>2976</i>&nbsp;                        opPrimaryTerm,</b>
<b class="nc"><i>2977</i>&nbsp;                        getOperationPrimaryTerm());</b>
<b class="nc"><i>2978</i>&nbsp;                    delegatedListener.onFailure(new IllegalStateException(message));</b>
<b class="nc"><i>2979</i>&nbsp;                } else {</b>
<b class="nc"><i>2980</i>&nbsp;                    assert assertReplicationTarget();</b>
<i>2981</i>&nbsp;                    try {
<b class="nc"><i>2982</i>&nbsp;                        updateGlobalCheckpointOnReplica(globalCheckpoint, &quot;operation&quot;);</b>
<b class="nc"><i>2983</i>&nbsp;                        advanceMaxSeqNoOfUpdatesOrDeletes(maxSeqNoOfUpdatesOrDeletes);</b>
<b class="nc"><i>2984</i>&nbsp;                    } catch (Exception e) {</b>
<b class="nc"><i>2985</i>&nbsp;                        releasable.close();</b>
<b class="nc"><i>2986</i>&nbsp;                        delegatedListener.onFailure(e);</b>
<b class="nc"><i>2987</i>&nbsp;                        return;</b>
<b class="nc"><i>2988</i>&nbsp;                    }</b>
<b class="nc"><i>2989</i>&nbsp;                    delegatedListener.onResponse(releasable);</b>
<i>2990</i>&nbsp;                }
<b class="nc"><i>2991</i>&nbsp;            });</b>
<i>2992</i>&nbsp;
<b class="nc"><i>2993</i>&nbsp;        if (requirePrimaryTermUpdate(opPrimaryTerm, allowCombineOperationWithPrimaryTermUpdate)) {</b>
<b class="nc"><i>2994</i>&nbsp;            synchronized (mutex) {</b>
<b class="nc"><i>2995</i>&nbsp;                if (requirePrimaryTermUpdate(opPrimaryTerm, allowCombineOperationWithPrimaryTermUpdate)) {</b>
<b class="nc"><i>2996</i>&nbsp;                    final IndexShardState shardState = state();</b>
<i>2997</i>&nbsp;                    // only roll translog and update primary term if shard has made it past recovery
<i>2998</i>&nbsp;                    // Having a new primary term here means that the old primary failed and that there is a new primary, which again
<i>2999</i>&nbsp;                    // means that the master will fail this shard as all initializing shards are failed when a primary is selected
<i>3000</i>&nbsp;                    // We abort early here to prevent an ongoing recovery from the failed primary to mess with the global / local checkpoint
<b class="nc"><i>3001</i>&nbsp;                    if (shardState != IndexShardState.POST_RECOVERY &amp;&amp;</b>
<i>3002</i>&nbsp;                        shardState != IndexShardState.STARTED) {
<b class="nc"><i>3003</i>&nbsp;                        throw new IndexShardNotStartedException(shardId, shardState);</b>
<i>3004</i>&nbsp;                    }
<i>3005</i>&nbsp;
<b class="nc"><i>3006</i>&nbsp;                    bumpPrimaryTerm(opPrimaryTerm, () -&gt; {</b>
<b class="nc"><i>3007</i>&nbsp;                        updateGlobalCheckpointOnReplica(globalCheckpoint, &quot;primary term transition&quot;);</b>
<b class="nc"><i>3008</i>&nbsp;                        final long currentGlobalCheckpoint = getLastKnownGlobalCheckpoint();</b>
<b class="nc"><i>3009</i>&nbsp;                        final long maxSeqNo = seqNoStats().getMaxSeqNo();</b>
<b class="nc"><i>3010</i>&nbsp;                        logger.info(&quot;detected new primary with primary term [{}], global checkpoint [{}], max_seq_no [{}]&quot;,</b>
<b class="nc"><i>3011</i>&nbsp;                            opPrimaryTerm, currentGlobalCheckpoint, maxSeqNo);</b>
<b class="nc"><i>3012</i>&nbsp;                        if (currentGlobalCheckpoint &lt; maxSeqNo) {</b>
<b class="nc"><i>3013</i>&nbsp;                            resetEngineToGlobalCheckpoint();</b>
<i>3014</i>&nbsp;                        } else {
<b class="nc"><i>3015</i>&nbsp;                            getEngine().rollTranslogGeneration();</b>
<i>3016</i>&nbsp;                        }
<b class="nc"><i>3017</i>&nbsp;                    }, allowCombineOperationWithPrimaryTermUpdate ? operationListener : null);</b>
<i>3018</i>&nbsp;
<b class="nc"><i>3019</i>&nbsp;                    if (allowCombineOperationWithPrimaryTermUpdate) {</b>
<b class="nc"><i>3020</i>&nbsp;                        logger.debug(&quot;operation execution has been combined with primary term update&quot;);</b>
<b class="nc"><i>3021</i>&nbsp;                        return;</b>
<i>3022</i>&nbsp;                    }
<i>3023</i>&nbsp;                }
<b class="nc"><i>3024</i>&nbsp;            }</b>
<i>3025</i>&nbsp;        }
<b class="nc"><i>3026</i>&nbsp;        assert opPrimaryTerm &lt;= pendingPrimaryTerm</b>
<i>3027</i>&nbsp;            : &quot;operation primary term [&quot; + opPrimaryTerm + &quot;] should be at most [&quot; + pendingPrimaryTerm + &quot;]&quot;;
<b class="nc"><i>3028</i>&nbsp;        operationExecutor.accept(operationListener);</b>
<b class="nc"><i>3029</i>&nbsp;    }</b>
<i>3030</i>&nbsp;
<i>3031</i>&nbsp;    private boolean requirePrimaryTermUpdate(final long opPrimaryTerm, final boolean allPermits) {
<b class="nc"><i>3032</i>&nbsp;        return (opPrimaryTerm &gt; pendingPrimaryTerm) || (allPermits &amp;&amp; opPrimaryTerm &gt; getOperationPrimaryTerm());</b>
<i>3033</i>&nbsp;    }
<i>3034</i>&nbsp;
<i>3035</i>&nbsp;    public static final int OPERATIONS_BLOCKED = -1;
<i>3036</i>&nbsp;
<i>3037</i>&nbsp;    /**
<i>3038</i>&nbsp;     * Obtain the active operation count, or {@link IndexShard#OPERATIONS_BLOCKED} if all permits are held (even if there are
<i>3039</i>&nbsp;     * outstanding operations in flight).
<i>3040</i>&nbsp;     *
<i>3041</i>&nbsp;     * @return the active operation count, or {@link IndexShard#OPERATIONS_BLOCKED} when all permits are held.
<i>3042</i>&nbsp;     */
<i>3043</i>&nbsp;    public int getActiveOperationsCount() {
<b class="nc"><i>3044</i>&nbsp;        return indexShardOperationPermits.getActiveOperationsCount();</b>
<i>3045</i>&nbsp;    }
<i>3046</i>&nbsp;
<i>3047</i>&nbsp;    /**
<i>3048</i>&nbsp;     * @return a list of describing each permit that wasn&#39;t released yet. The description consist of the debugInfo supplied
<i>3049</i>&nbsp;     *         when the permit was acquired plus a stack traces that was captured when the permit was request.
<i>3050</i>&nbsp;     */
<i>3051</i>&nbsp;    public List&lt;String&gt; getActiveOperations() {
<b class="nc"><i>3052</i>&nbsp;        return indexShardOperationPermits.getActiveOperations();</b>
<i>3053</i>&nbsp;    }
<i>3054</i>&nbsp;
<i>3055</i>&nbsp;    private final AsyncIOProcessor&lt;Translog.Location&gt; translogSyncProcessor;
<i>3056</i>&nbsp;
<i>3057</i>&nbsp;    private static AsyncIOProcessor&lt;Translog.Location&gt; createTranslogSyncProcessor(Logger logger, ThreadContext threadContext,
<i>3058</i>&nbsp;                                                                                   Supplier&lt;Engine&gt; engineSupplier) {
<b class="fc"><i>3059</i>&nbsp;        return new AsyncIOProcessor&lt;Translog.Location&gt;(logger, 1024, threadContext) {</b>
<i>3060</i>&nbsp;            @Override
<i>3061</i>&nbsp;            protected void write(List&lt;Tuple&lt;Translog.Location, Consumer&lt;Exception&gt;&gt;&gt; candidates) throws IOException {
<i>3062</i>&nbsp;                try {
<b class="nc"><i>3063</i>&nbsp;                    engineSupplier.get().ensureTranslogSynced(candidates.stream().map(Tuple::v1));</b>
<b class="nc"><i>3064</i>&nbsp;                } catch (AlreadyClosedException ex) {</b>
<i>3065</i>&nbsp;                    // that&#39;s fine since we already synced everything on engine close - this also is conform with the methods
<i>3066</i>&nbsp;                    // documentation
<b class="nc"><i>3067</i>&nbsp;                } catch (IOException ex) { // if this fails we are in deep shit - fail the request</b>
<b class="nc"><i>3068</i>&nbsp;                    logger.debug(&quot;failed to sync translog&quot;, ex);</b>
<b class="nc"><i>3069</i>&nbsp;                    throw ex;</b>
<b class="nc"><i>3070</i>&nbsp;                }</b>
<b class="nc"><i>3071</i>&nbsp;            }</b>
<i>3072</i>&nbsp;        };
<i>3073</i>&nbsp;    }
<i>3074</i>&nbsp;
<i>3075</i>&nbsp;    /**
<i>3076</i>&nbsp;     * Syncs the given location with the underlying storage unless already synced. This method might return immediately without
<i>3077</i>&nbsp;     * actually fsyncing the location until the sync listener is called. Yet, unless there is already another thread fsyncing
<i>3078</i>&nbsp;     * the transaction log the caller thread will be hijacked to run the fsync for all pending fsync operations.
<i>3079</i>&nbsp;     * This method allows indexing threads to continue indexing without blocking on fsync calls. We ensure that there is only
<i>3080</i>&nbsp;     * one thread blocking on the sync an all others can continue indexing.
<i>3081</i>&nbsp;     * NOTE: if the syncListener throws an exception when it&#39;s processed the exception will only be logged. Users should make sure that the
<i>3082</i>&nbsp;     * listener handles all exception cases internally.
<i>3083</i>&nbsp;     */
<i>3084</i>&nbsp;    public final void sync(Translog.Location location, Consumer&lt;Exception&gt; syncListener) {
<b class="nc"><i>3085</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>3086</i>&nbsp;        translogSyncProcessor.put(location, syncListener);</b>
<b class="nc"><i>3087</i>&nbsp;    }</b>
<i>3088</i>&nbsp;
<i>3089</i>&nbsp;    public void sync() throws IOException {
<b class="nc"><i>3090</i>&nbsp;        verifyNotClosed();</b>
<b class="nc"><i>3091</i>&nbsp;        getEngine().syncTranslog();</b>
<b class="nc"><i>3092</i>&nbsp;    }</b>
<i>3093</i>&nbsp;
<i>3094</i>&nbsp;    /**
<i>3095</i>&nbsp;     * Checks if the underlying storage sync is required.
<i>3096</i>&nbsp;     */
<i>3097</i>&nbsp;    public boolean isSyncNeeded() {
<b class="nc"><i>3098</i>&nbsp;        return getEngine().isTranslogSyncNeeded();</b>
<i>3099</i>&nbsp;    }
<i>3100</i>&nbsp;
<i>3101</i>&nbsp;    /**
<i>3102</i>&nbsp;     * Returns the current translog durability mode
<i>3103</i>&nbsp;     */
<i>3104</i>&nbsp;    public Translog.Durability getTranslogDurability() {
<b class="nc"><i>3105</i>&nbsp;        return indexSettings.getTranslogDurability();</b>
<i>3106</i>&nbsp;    }
<i>3107</i>&nbsp;
<i>3108</i>&nbsp;    // we can not protect with a lock since we &quot;release&quot; on a different thread
<b class="fc"><i>3109</i>&nbsp;    private final AtomicBoolean flushOrRollRunning = new AtomicBoolean();</b>
<i>3110</i>&nbsp;
<i>3111</i>&nbsp;    /**
<i>3112</i>&nbsp;     * Schedules a flush or translog generation roll if needed but will not schedule more than one concurrently. The operation will be
<i>3113</i>&nbsp;     * executed asynchronously on the flush thread pool.
<i>3114</i>&nbsp;     */
<i>3115</i>&nbsp;    public void afterWriteOperation() {
<b class="nc"><i>3116</i>&nbsp;        if (shouldPeriodicallyFlush() || shouldRollTranslogGeneration()) {</b>
<b class="nc"><i>3117</i>&nbsp;            if (flushOrRollRunning.compareAndSet(false, true)) {</b>
<i>3118</i>&nbsp;                /*
<i>3119</i>&nbsp;                 * We have to check again since otherwise there is a race when a thread passes the first check next to another thread which
<i>3120</i>&nbsp;                 * performs the operation quickly enough to  finish before the current thread could flip the flag. In that situation, we
<i>3121</i>&nbsp;                 * have an extra operation.
<i>3122</i>&nbsp;                 *
<i>3123</i>&nbsp;                 * Additionally, a flush implicitly executes a translog generation roll so if we execute a flush then we do not need to
<i>3124</i>&nbsp;                 * check if we should roll the translog generation.
<i>3125</i>&nbsp;                 */
<b class="nc"><i>3126</i>&nbsp;                if (shouldPeriodicallyFlush()) {</b>
<b class="nc"><i>3127</i>&nbsp;                    logger.debug(&quot;submitting async flush request&quot;);</b>
<b class="nc"><i>3128</i>&nbsp;                    final AbstractRunnable flush = new AbstractRunnable() {</b>
<i>3129</i>&nbsp;                        @Override
<i>3130</i>&nbsp;                        public void onFailure(final Exception e) {
<i>3131</i>&nbsp;                            if (state != IndexShardState.CLOSED) {
<i>3132</i>&nbsp;                                logger.warn(&quot;failed to flush index&quot;, e);
<i>3133</i>&nbsp;                            }
<i>3134</i>&nbsp;                        }
<i>3135</i>&nbsp;
<i>3136</i>&nbsp;                        @Override
<i>3137</i>&nbsp;                        protected void doRun() throws IOException {
<i>3138</i>&nbsp;                            flush(new FlushRequest());
<i>3139</i>&nbsp;                            periodicFlushMetric.inc();
<i>3140</i>&nbsp;                        }
<i>3141</i>&nbsp;
<i>3142</i>&nbsp;                        @Override
<i>3143</i>&nbsp;                        public void onAfter() {
<i>3144</i>&nbsp;                            flushOrRollRunning.compareAndSet(true, false);
<i>3145</i>&nbsp;                            afterWriteOperation();
<i>3146</i>&nbsp;                        }
<i>3147</i>&nbsp;                    };
<b class="nc"><i>3148</i>&nbsp;                    threadPool.executor(ThreadPool.Names.FLUSH).execute(flush);</b>
<b class="nc"><i>3149</i>&nbsp;                } else if (shouldRollTranslogGeneration()) {</b>
<b class="nc"><i>3150</i>&nbsp;                    logger.debug(&quot;submitting async roll translog generation request&quot;);</b>
<b class="nc"><i>3151</i>&nbsp;                    final AbstractRunnable roll = new AbstractRunnable() {</b>
<i>3152</i>&nbsp;                        @Override
<i>3153</i>&nbsp;                        public void onFailure(final Exception e) {
<i>3154</i>&nbsp;                            if (state != IndexShardState.CLOSED) {
<i>3155</i>&nbsp;                                logger.warn(&quot;failed to roll translog generation&quot;, e);
<i>3156</i>&nbsp;                            }
<i>3157</i>&nbsp;                        }
<i>3158</i>&nbsp;
<i>3159</i>&nbsp;                        @Override
<i>3160</i>&nbsp;                        protected void doRun() throws Exception {
<i>3161</i>&nbsp;                            rollTranslogGeneration();
<i>3162</i>&nbsp;                        }
<i>3163</i>&nbsp;
<i>3164</i>&nbsp;                        @Override
<i>3165</i>&nbsp;                        public void onAfter() {
<i>3166</i>&nbsp;                            flushOrRollRunning.compareAndSet(true, false);
<i>3167</i>&nbsp;                            afterWriteOperation();
<i>3168</i>&nbsp;                        }
<i>3169</i>&nbsp;                    };
<b class="nc"><i>3170</i>&nbsp;                    threadPool.executor(ThreadPool.Names.FLUSH).execute(roll);</b>
<b class="nc"><i>3171</i>&nbsp;                } else {</b>
<b class="nc"><i>3172</i>&nbsp;                    flushOrRollRunning.compareAndSet(true, false);</b>
<i>3173</i>&nbsp;                }
<i>3174</i>&nbsp;            }
<i>3175</i>&nbsp;        }
<b class="nc"><i>3176</i>&nbsp;    }</b>
<i>3177</i>&nbsp;
<i>3178</i>&nbsp;    /**
<i>3179</i>&nbsp;     * Build {@linkplain RefreshListeners} for this shard.
<i>3180</i>&nbsp;     */
<i>3181</i>&nbsp;    private RefreshListeners buildRefreshListeners() {
<b class="fc"><i>3182</i>&nbsp;        return new RefreshListeners(</b>
<b class="fc"><i>3183</i>&nbsp;            indexSettings::getMaxRefreshListeners,</b>
<b class="nc"><i>3184</i>&nbsp;            () -&gt; refresh(&quot;too_many_listeners&quot;),</b>
<b class="fc"><i>3185</i>&nbsp;            threadPool.executor(ThreadPool.Names.LISTENER),</b>
<b class="fc"><i>3186</i>&nbsp;            logger, threadPool.getThreadContext(),</b>
<i>3187</i>&nbsp;            externalRefreshMetric);
<i>3188</i>&nbsp;    }
<i>3189</i>&nbsp;
<i>3190</i>&nbsp;    /**
<i>3191</i>&nbsp;     * Simple struct encapsulating a shard failure
<i>3192</i>&nbsp;     *
<i>3193</i>&nbsp;     * @see IndexShard#addShardFailureCallback(Consumer)
<i>3194</i>&nbsp;     */
<i>3195</i>&nbsp;    public static final class ShardFailure {
<i>3196</i>&nbsp;        public final ShardRouting routing;
<i>3197</i>&nbsp;        public final String reason;
<i>3198</i>&nbsp;        @Nullable
<i>3199</i>&nbsp;        public final Exception cause;
<i>3200</i>&nbsp;
<i>3201</i>&nbsp;        public ShardFailure(ShardRouting routing, String reason, @Nullable Exception cause) {
<i>3202</i>&nbsp;            this.routing = routing;
<i>3203</i>&nbsp;            this.reason = reason;
<i>3204</i>&nbsp;            this.cause = cause;
<i>3205</i>&nbsp;        }
<i>3206</i>&nbsp;    }
<i>3207</i>&nbsp;
<i>3208</i>&nbsp;    EngineFactory getEngineFactory() {
<b class="nc"><i>3209</i>&nbsp;        return engineFactory;</b>
<i>3210</i>&nbsp;    }
<i>3211</i>&nbsp;
<i>3212</i>&nbsp;    // for tests
<i>3213</i>&nbsp;    ReplicationTracker getReplicationTracker() {
<b class="nc"><i>3214</i>&nbsp;        return replicationTracker;</b>
<i>3215</i>&nbsp;    }
<i>3216</i>&nbsp;
<i>3217</i>&nbsp;    /**
<i>3218</i>&nbsp;     * Executes a scheduled refresh if necessary.
<i>3219</i>&nbsp;     *
<i>3220</i>&nbsp;     * @return &lt;code&gt;true&lt;/code&gt; iff the engine got refreshed otherwise &lt;code&gt;false&lt;/code&gt;
<i>3221</i>&nbsp;     */
<i>3222</i>&nbsp;    public boolean scheduledRefresh() {
<b class="fc"><i>3223</i>&nbsp;        verifyNotClosed();</b>
<b class="fc"><i>3224</i>&nbsp;        boolean listenerNeedsRefresh = refreshListeners.refreshNeeded();</b>
<b class="fc"><i>3225</i>&nbsp;        if (isReadAllowed() &amp;&amp; (listenerNeedsRefresh || getEngine().refreshNeeded())) {</b>
<b class="nc"><i>3226</i>&nbsp;            if (listenerNeedsRefresh == false // if we have a listener that is waiting for a refresh we need to force it</b>
<b class="nc"><i>3227</i>&nbsp;                &amp;&amp; isSearchIdle()</b>
<b class="nc"><i>3228</i>&nbsp;                &amp;&amp; indexSettings.isExplicitRefresh() == false</b>
<b class="nc"><i>3229</i>&nbsp;                &amp;&amp; active.get()) { // it must be active otherwise we might not free up segment memory once the shard became inactive</b>
<i>3230</i>&nbsp;                // lets skip this refresh since we are search idle and
<i>3231</i>&nbsp;                // don&#39;t necessarily need to refresh. the next searcher access will register a refreshListener and that will
<i>3232</i>&nbsp;                // cause the next schedule to refresh.
<b class="nc"><i>3233</i>&nbsp;                final Engine engine = getEngine();</b>
<b class="nc"><i>3234</i>&nbsp;                engine.maybePruneDeletes(); // try to prune the deletes in the engine if we accumulated some</b>
<b class="nc"><i>3235</i>&nbsp;                setRefreshPending(engine);</b>
<b class="nc"><i>3236</i>&nbsp;                return false;</b>
<i>3237</i>&nbsp;            } else {
<b class="nc"><i>3238</i>&nbsp;                if (logger.isTraceEnabled()) {</b>
<b class="nc"><i>3239</i>&nbsp;                    logger.trace(&quot;refresh with source [schedule]&quot;);</b>
<i>3240</i>&nbsp;                }
<b class="nc"><i>3241</i>&nbsp;                return getEngine().maybeRefresh(&quot;schedule&quot;);</b>
<i>3242</i>&nbsp;            }
<i>3243</i>&nbsp;        }
<b class="fc"><i>3244</i>&nbsp;        final Engine engine = getEngine();</b>
<b class="fc"><i>3245</i>&nbsp;        engine.maybePruneDeletes(); // try to prune the deletes in the engine if we accumulated some</b>
<b class="fc"><i>3246</i>&nbsp;        return false;</b>
<i>3247</i>&nbsp;    }
<i>3248</i>&nbsp;
<i>3249</i>&nbsp;    /**
<i>3250</i>&nbsp;     * Returns true if this shards is search idle
<i>3251</i>&nbsp;     */
<i>3252</i>&nbsp;    final boolean isSearchIdle() {
<b class="nc"><i>3253</i>&nbsp;        return (threadPool.relativeTimeInMillis() - lastSearcherAccess.get()) &gt;= indexSettings.getSearchIdleAfter().getMillis();</b>
<i>3254</i>&nbsp;    }
<i>3255</i>&nbsp;
<i>3256</i>&nbsp;    /**
<i>3257</i>&nbsp;     * Returns the last timestamp the searcher was accessed. This is a relative timestamp in milliseconds.
<i>3258</i>&nbsp;     */
<i>3259</i>&nbsp;    final long getLastSearcherAccess() {
<b class="nc"><i>3260</i>&nbsp;        return lastSearcherAccess.get();</b>
<i>3261</i>&nbsp;    }
<i>3262</i>&nbsp;
<i>3263</i>&nbsp;    private void setRefreshPending(Engine engine) {
<b class="nc"><i>3264</i>&nbsp;        Translog.Location lastWriteLocation = engine.getTranslogLastWriteLocation();</b>
<i>3265</i>&nbsp;        Translog.Location location;
<i>3266</i>&nbsp;        do {
<b class="nc"><i>3267</i>&nbsp;            location = this.pendingRefreshLocation.get();</b>
<b class="nc"><i>3268</i>&nbsp;            if (location != null &amp;&amp; lastWriteLocation.compareTo(location) &lt;= 0) {</b>
<b class="nc"><i>3269</i>&nbsp;                break;</b>
<i>3270</i>&nbsp;            }
<b class="nc"><i>3271</i>&nbsp;        } while (pendingRefreshLocation.compareAndSet(location, lastWriteLocation) == false);</b>
<b class="nc"><i>3272</i>&nbsp;    }</b>
<i>3273</i>&nbsp;
<i>3274</i>&nbsp;    /**
<i>3275</i>&nbsp;     * Registers the given listener and invokes it once the shard is active again and all
<i>3276</i>&nbsp;     * pending refresh translog location has been refreshed. If there is no pending refresh location registered the listener will be
<i>3277</i>&nbsp;     * invoked immediately.
<i>3278</i>&nbsp;     * @param listener the listener to invoke once the pending refresh location is visible. The listener will be called with
<i>3279</i>&nbsp;     *                 &lt;code&gt;true&lt;/code&gt; if the listener was registered to wait for a refresh.
<i>3280</i>&nbsp;     */
<i>3281</i>&nbsp;    public final void awaitShardSearchActive(Consumer&lt;Boolean&gt; listener) {
<b class="nc"><i>3282</i>&nbsp;        markSearcherAccessed(); // move the shard into non-search idle</b>
<b class="nc"><i>3283</i>&nbsp;        final Translog.Location location = pendingRefreshLocation.get();</b>
<b class="nc"><i>3284</i>&nbsp;        if (location != null) {</b>
<b class="nc"><i>3285</i>&nbsp;            addRefreshListener(location, (b) -&gt; {</b>
<b class="nc"><i>3286</i>&nbsp;                pendingRefreshLocation.compareAndSet(location, null);</b>
<b class="nc"><i>3287</i>&nbsp;                listener.accept(true);</b>
<b class="nc"><i>3288</i>&nbsp;            });</b>
<i>3289</i>&nbsp;        } else {
<b class="nc"><i>3290</i>&nbsp;            listener.accept(false);</b>
<i>3291</i>&nbsp;        }
<b class="nc"><i>3292</i>&nbsp;    }</b>
<i>3293</i>&nbsp;
<i>3294</i>&nbsp;    /**
<i>3295</i>&nbsp;     * Add a listener for refreshes.
<i>3296</i>&nbsp;     *
<i>3297</i>&nbsp;     * @param location the location to listen for
<i>3298</i>&nbsp;     * @param listener for the refresh. Called with true if registering the listener ran it out of slots and forced a refresh. Called with
<i>3299</i>&nbsp;     *        false otherwise.
<i>3300</i>&nbsp;     */
<i>3301</i>&nbsp;    public void addRefreshListener(Translog.Location location, Consumer&lt;Boolean&gt; listener) {
<i>3302</i>&nbsp;        final boolean readAllowed;
<b class="nc"><i>3303</i>&nbsp;        if (isReadAllowed()) {</b>
<b class="nc"><i>3304</i>&nbsp;            readAllowed = true;</b>
<i>3305</i>&nbsp;        } else {
<i>3306</i>&nbsp;            // check again under postRecoveryMutex. this is important to create a happens before relationship
<i>3307</i>&nbsp;            // between the switch to POST_RECOVERY + associated refresh. Otherwise we may respond
<i>3308</i>&nbsp;            // to a listener before a refresh actually happened that contained that operation.
<b class="nc"><i>3309</i>&nbsp;            synchronized (postRecoveryMutex) {</b>
<b class="nc"><i>3310</i>&nbsp;                readAllowed = isReadAllowed();</b>
<b class="nc"><i>3311</i>&nbsp;            }</b>
<i>3312</i>&nbsp;        }
<b class="nc"><i>3313</i>&nbsp;        if (readAllowed) {</b>
<b class="nc"><i>3314</i>&nbsp;            refreshListeners.addOrNotify(location, listener);</b>
<i>3315</i>&nbsp;        } else {
<i>3316</i>&nbsp;            // we&#39;re not yet ready fo ready for reads, just ignore refresh cycles
<b class="nc"><i>3317</i>&nbsp;            listener.accept(false);</b>
<i>3318</i>&nbsp;        }
<b class="nc"><i>3319</i>&nbsp;    }</b>
<i>3320</i>&nbsp;
<b class="fc"><i>3321</i>&nbsp;    private static class RefreshMetricUpdater implements ReferenceManager.RefreshListener {</b>
<i>3322</i>&nbsp;
<i>3323</i>&nbsp;        private final MeanMetric refreshMetric;
<i>3324</i>&nbsp;        private long currentRefreshStartTime;
<b class="fc"><i>3325</i>&nbsp;        private Thread callingThread = null;</b>
<i>3326</i>&nbsp;
<b class="fc"><i>3327</i>&nbsp;        private RefreshMetricUpdater(MeanMetric refreshMetric) {</b>
<b class="fc"><i>3328</i>&nbsp;            this.refreshMetric = refreshMetric;</b>
<b class="fc"><i>3329</i>&nbsp;        }</b>
<i>3330</i>&nbsp;
<i>3331</i>&nbsp;        @Override
<i>3332</i>&nbsp;        public void beforeRefresh() throws IOException {
<b class="fc"><i>3333</i>&nbsp;            if (Assertions.ENABLED) {</b>
<b class="fc"><i>3334</i>&nbsp;                assert callingThread == null : &quot;beforeRefresh was called by &quot; + callingThread.getName() +</b>
<i>3335</i>&nbsp;                    &quot; without a corresponding call to afterRefresh&quot;;
<b class="fc"><i>3336</i>&nbsp;                callingThread = Thread.currentThread();</b>
<i>3337</i>&nbsp;            }
<b class="fc"><i>3338</i>&nbsp;            currentRefreshStartTime = System.nanoTime();</b>
<b class="fc"><i>3339</i>&nbsp;        }</b>
<i>3340</i>&nbsp;
<i>3341</i>&nbsp;        @Override
<i>3342</i>&nbsp;        public void afterRefresh(boolean didRefresh) throws IOException {
<b class="fc"><i>3343</i>&nbsp;            if (Assertions.ENABLED) {</b>
<b class="fc"><i>3344</i>&nbsp;                assert callingThread != null : &quot;afterRefresh called but not beforeRefresh&quot;;</b>
<b class="fc"><i>3345</i>&nbsp;                assert callingThread == Thread.currentThread() : &quot;beforeRefreshed called by a different thread. current [&quot;</b>
<b class="nc"><i>3346</i>&nbsp;                    + Thread.currentThread().getName() + &quot;], thread that called beforeRefresh [&quot; + callingThread.getName() + &quot;]&quot;;</b>
<b class="fc"><i>3347</i>&nbsp;                callingThread = null;</b>
<i>3348</i>&nbsp;            }
<b class="fc"><i>3349</i>&nbsp;            refreshMetric.inc(System.nanoTime() - currentRefreshStartTime);</b>
<b class="fc"><i>3350</i>&nbsp;        }</b>
<i>3351</i>&nbsp;    }
<i>3352</i>&nbsp;
<i>3353</i>&nbsp;    private EngineConfig.TombstoneDocSupplier tombstoneDocSupplier() {
<b class="fc"><i>3354</i>&nbsp;        final RootObjectMapper.Builder noopRootMapper = new RootObjectMapper.Builder(&quot;__noop&quot;);</b>
<b class="fc"><i>3355</i>&nbsp;        final DocumentMapper noopDocumentMapper = mapperService != null ?</b>
<b class="fc"><i>3356</i>&nbsp;            new DocumentMapper.Builder(noopRootMapper, mapperService).build(mapperService) :</b>
<b class="nc"><i>3357</i>&nbsp;            null;</b>
<b class="fc"><i>3358</i>&nbsp;        return new EngineConfig.TombstoneDocSupplier() {</b>
<i>3359</i>&nbsp;            @Override
<i>3360</i>&nbsp;            public ParsedDocument newDeleteTombstoneDoc(String type, String id) {
<b class="nc"><i>3361</i>&nbsp;                return docMapper(type).getDocumentMapper().createDeleteTombstoneDoc(shardId.getIndexName(), type, id);</b>
<i>3362</i>&nbsp;            }
<i>3363</i>&nbsp;            @Override
<i>3364</i>&nbsp;            public ParsedDocument newNoopTombstoneDoc(String reason) {
<b class="nc"><i>3365</i>&nbsp;                return noopDocumentMapper.createNoopTombstoneDoc(shardId.getIndexName(), reason);</b>
<i>3366</i>&nbsp;            }
<i>3367</i>&nbsp;        };
<i>3368</i>&nbsp;    }
<i>3369</i>&nbsp;
<i>3370</i>&nbsp;    /**
<i>3371</i>&nbsp;     * Rollback the current engine to the safe commit, then replay local translog up to the global checkpoint.
<i>3372</i>&nbsp;     */
<i>3373</i>&nbsp;    void resetEngineToGlobalCheckpoint() throws IOException {
<b class="nc"><i>3374</i>&nbsp;        assert Thread.holdsLock(mutex) == false : &quot;resetting engine under mutex&quot;;</b>
<b class="nc"><i>3375</i>&nbsp;        assert getActiveOperationsCount() == OPERATIONS_BLOCKED</b>
<b class="nc"><i>3376</i>&nbsp;            : &quot;resetting engine without blocking operations; active operations are [&quot; + getActiveOperations() + &#39;]&#39;;</b>
<b class="nc"><i>3377</i>&nbsp;        sync(); // persist the global checkpoint to disk</b>
<b class="nc"><i>3378</i>&nbsp;        final SeqNoStats seqNoStats = seqNoStats();</b>
<b class="nc"><i>3379</i>&nbsp;        final TranslogStats translogStats = translogStats();</b>
<i>3380</i>&nbsp;        // flush to make sure the latest commit, which will be opened by the read-only engine, includes all operations.
<b class="nc"><i>3381</i>&nbsp;        flush(new FlushRequest().waitIfOngoing(true));</b>
<i>3382</i>&nbsp;
<b class="nc"><i>3383</i>&nbsp;        SetOnce&lt;Engine&gt; newEngineReference = new SetOnce&lt;&gt;();</b>
<b class="nc"><i>3384</i>&nbsp;        final long globalCheckpoint = getLastKnownGlobalCheckpoint();</b>
<b class="nc"><i>3385</i>&nbsp;        assert globalCheckpoint == getLastSyncedGlobalCheckpoint();</b>
<b class="nc"><i>3386</i>&nbsp;        synchronized (engineMutex) {</b>
<b class="nc"><i>3387</i>&nbsp;            verifyNotClosed();</b>
<i>3388</i>&nbsp;            // we must create both new read-only engine and new read-write engine under engineMutex to ensure snapshotStoreMetadata,
<i>3389</i>&nbsp;            // acquireXXXCommit and close works.
<b class="nc"><i>3390</i>&nbsp;            final Engine readOnlyEngine =</b>
<b class="nc"><i>3391</i>&nbsp;                new ReadOnlyEngine(newEngineConfig(replicationTracker), seqNoStats, translogStats, false, Function.identity()) {</b>
<i>3392</i>&nbsp;                    @Override
<i>3393</i>&nbsp;                    public IndexCommitRef acquireLastIndexCommit(boolean flushFirst) {
<i>3394</i>&nbsp;                        synchronized (engineMutex) {
<i>3395</i>&nbsp;                            if (newEngineReference.get() == null) {
<i>3396</i>&nbsp;                                throw new AlreadyClosedException(&quot;engine was closed&quot;);
<i>3397</i>&nbsp;                            }
<i>3398</i>&nbsp;                            // ignore flushFirst since we flushed above and we do not want to interfere with ongoing translog replay
<i>3399</i>&nbsp;                            return newEngineReference.get().acquireLastIndexCommit(false);
<i>3400</i>&nbsp;                        }
<i>3401</i>&nbsp;                    }
<i>3402</i>&nbsp;
<i>3403</i>&nbsp;                    @Override
<i>3404</i>&nbsp;                    public IndexCommitRef acquireSafeIndexCommit() {
<i>3405</i>&nbsp;                        synchronized (engineMutex) {
<i>3406</i>&nbsp;                            if (newEngineReference.get() == null) {
<i>3407</i>&nbsp;                                throw new AlreadyClosedException(&quot;engine was closed&quot;);
<i>3408</i>&nbsp;                            }
<i>3409</i>&nbsp;                            return newEngineReference.get().acquireSafeIndexCommit();
<i>3410</i>&nbsp;                        }
<i>3411</i>&nbsp;                    }
<i>3412</i>&nbsp;
<i>3413</i>&nbsp;                    @Override
<i>3414</i>&nbsp;                    public void close() throws IOException {
<i>3415</i>&nbsp;                        assert Thread.holdsLock(engineMutex);
<i>3416</i>&nbsp;
<i>3417</i>&nbsp;                        Engine newEngine = newEngineReference.get();
<i>3418</i>&nbsp;                        if (newEngine == currentEngineReference.get()) {
<i>3419</i>&nbsp;                            // we successfully installed the new engine so do not close it.
<i>3420</i>&nbsp;                            newEngine = null;
<i>3421</i>&nbsp;                        }
<i>3422</i>&nbsp;                        IOUtils.close(super::close, newEngine);
<i>3423</i>&nbsp;                    }
<i>3424</i>&nbsp;                };
<b class="nc"><i>3425</i>&nbsp;            IOUtils.close(currentEngineReference.getAndSet(readOnlyEngine));</b>
<b class="nc"><i>3426</i>&nbsp;            newEngineReference.set(engineFactory.newReadWriteEngine(newEngineConfig(replicationTracker)));</b>
<b class="nc"><i>3427</i>&nbsp;            onNewEngine(newEngineReference.get());</b>
<b class="nc"><i>3428</i>&nbsp;        }</b>
<b class="nc"><i>3429</i>&nbsp;        final Engine.TranslogRecoveryRunner translogRunner = (engine, snapshot) -&gt; runTranslogRecovery(</b>
<i>3430</i>&nbsp;            engine, snapshot, Engine.Operation.Origin.LOCAL_RESET, () -&gt; {
<i>3431</i>&nbsp;                // TODO: add a dedicate recovery stats for the reset translog
<b class="nc"><i>3432</i>&nbsp;            });</b>
<b class="nc"><i>3433</i>&nbsp;        newEngineReference.get().recoverFromTranslog(translogRunner, globalCheckpoint);</b>
<b class="nc"><i>3434</i>&nbsp;        newEngineReference.get().refresh(&quot;reset_engine&quot;);</b>
<b class="nc"><i>3435</i>&nbsp;        synchronized (engineMutex) {</b>
<b class="nc"><i>3436</i>&nbsp;            verifyNotClosed();</b>
<b class="nc"><i>3437</i>&nbsp;            IOUtils.close(currentEngineReference.getAndSet(newEngineReference.get()));</b>
<i>3438</i>&nbsp;            // We set active because we are now writing operations to the engine; this way,
<i>3439</i>&nbsp;            // if we go idle after some time and become inactive, we still give sync&#39;d flush a chance to run.
<b class="nc"><i>3440</i>&nbsp;            active.set(true);</b>
<b class="nc"><i>3441</i>&nbsp;        }</b>
<i>3442</i>&nbsp;        // time elapses after the engine is created above (pulling the config settings) until we set the engine reference, during
<i>3443</i>&nbsp;        // which settings changes could possibly have happened, so here we forcefully push any config changes to the new engine.
<b class="nc"><i>3444</i>&nbsp;        onSettingsChanged();</b>
<b class="nc"><i>3445</i>&nbsp;    }</b>
<i>3446</i>&nbsp;
<i>3447</i>&nbsp;    /**
<i>3448</i>&nbsp;     * Returns the maximum sequence number of either update or delete operations have been processed in this shard
<i>3449</i>&nbsp;     * or the sequence number from {@link #advanceMaxSeqNoOfUpdatesOrDeletes(long)}. An index request is considered
<i>3450</i>&nbsp;     * as an update operation if it overwrites the existing documents in Lucene index with the same document id.
<i>3451</i>&nbsp;     * &lt;p&gt;
<i>3452</i>&nbsp;     * The primary captures this value after executes a replication request, then transfers it to a replica before
<i>3453</i>&nbsp;     * executing that replication request on a replica.
<i>3454</i>&nbsp;     */
<i>3455</i>&nbsp;    public long getMaxSeqNoOfUpdatesOrDeletes() {
<b class="nc"><i>3456</i>&nbsp;        return getEngine().getMaxSeqNoOfUpdatesOrDeletes();</b>
<i>3457</i>&nbsp;    }
<i>3458</i>&nbsp;
<i>3459</i>&nbsp;    /**
<i>3460</i>&nbsp;     * A replica calls this method to advance the max_seq_no_of_updates marker of its engine to at least the max_seq_no_of_updates
<i>3461</i>&nbsp;     * value (piggybacked in a replication request) that it receives from its primary before executing that replication request.
<i>3462</i>&nbsp;     * The receiving value is at least as high as the max_seq_no_of_updates on the primary was when any of the operations of that
<i>3463</i>&nbsp;     * replication request were processed on it.
<i>3464</i>&nbsp;     * &lt;p&gt;
<i>3465</i>&nbsp;     * A replica shard also calls this method to bootstrap the max_seq_no_of_updates marker with the value that it received from
<i>3466</i>&nbsp;     * the primary in peer-recovery, before it replays remote translog operations from the primary. The receiving value is at least
<i>3467</i>&nbsp;     * as high as the max_seq_no_of_updates on the primary was when any of these operations were processed on it.
<i>3468</i>&nbsp;     * &lt;p&gt;
<i>3469</i>&nbsp;     * These transfers guarantee that every index/delete operation when executing on a replica engine will observe this marker a value
<i>3470</i>&nbsp;     * which is at least the value of the max_seq_no_of_updates marker on the primary after that operation was executed on the primary.
<i>3471</i>&nbsp;     *
<i>3472</i>&nbsp;     * @see #acquireReplicaOperationPermit(long, long, long, ActionListener, String, Object)
<i>3473</i>&nbsp;     * @see RecoveryTarget#indexTranslogOperations(List, int, long, long, RetentionLeases, long, ActionListener)
<i>3474</i>&nbsp;     */
<i>3475</i>&nbsp;    public void advanceMaxSeqNoOfUpdatesOrDeletes(long seqNo) {
<b class="nc"><i>3476</i>&nbsp;        getEngine().advanceMaxSeqNoOfUpdatesOrDeletes(seqNo);</b>
<b class="nc"><i>3477</i>&nbsp;    }</b>
<i>3478</i>&nbsp;
<i>3479</i>&nbsp;    /**
<i>3480</i>&nbsp;     * Performs the pre-closing checks on the {@link IndexShard}.
<i>3481</i>&nbsp;     *
<i>3482</i>&nbsp;     * @throws IllegalStateException if the sanity checks failed
<i>3483</i>&nbsp;     */
<i>3484</i>&nbsp;    public void verifyShardBeforeIndexClosing() throws IllegalStateException {
<b class="nc"><i>3485</i>&nbsp;        getEngine().verifyEngineBeforeIndexClosing();</b>
<b class="nc"><i>3486</i>&nbsp;    }</b>
<i>3487</i>&nbsp;
<i>3488</i>&nbsp;    RetentionLeaseSyncer getRetentionLeaseSyncer() {
<b class="nc"><i>3489</i>&nbsp;        return retentionLeaseSyncer;</b>
<i>3490</i>&nbsp;    }
<i>3491</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-02-09 18:46</div>
</div>
</body>
</html>
