


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: BlobStoreRepository</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.elasticsearch.repositories.blobstore</a> ]
</div>

<h1>Coverage Summary for Class: BlobStoreRepository (org.elasticsearch.repositories.blobstore)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">BlobStoreRepository</td>
<td class="coverageStat">
  <span class="percent">
    2.4%
  </span>
  <span class="absValue">
    (2/ 82)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0.3%
  </span>
  <span class="absValue">
    (2/ 598)
  </span>
</td>
</tr>
  <tr>
    <td class="name">BlobStoreRepository$4</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 4)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 10)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>total</strong></td>
<td class="coverageStat">
  <span class="percent">
    2.3%
  </span>
  <span class="absValue">
    (2/ 86)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0.3%
  </span>
  <span class="absValue">
    (2/ 608)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to Elasticsearch under one or more contributor
<i>3</i>&nbsp; * license agreements. See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright
<i>5</i>&nbsp; * ownership. Elasticsearch licenses this file to you under
<i>6</i>&nbsp; * the Apache License, Version 2.0 (the &quot;License&quot;); you may
<i>7</i>&nbsp; * not use this file except in compliance with the License.
<i>8</i>&nbsp; * You may obtain a copy of the License at
<i>9</i>&nbsp; *
<i>10</i>&nbsp; *    http://www.apache.org/licenses/LICENSE-2.0
<i>11</i>&nbsp; *
<i>12</i>&nbsp; * Unless required by applicable law or agreed to in writing,
<i>13</i>&nbsp; * software distributed under the License is distributed on an
<i>14</i>&nbsp; * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
<i>15</i>&nbsp; * KIND, either express or implied.  See the License for the
<i>16</i>&nbsp; * specific language governing permissions and limitations
<i>17</i>&nbsp; * under the License.
<i>18</i>&nbsp; */
<i>19</i>&nbsp;
<i>20</i>&nbsp;package org.elasticsearch.repositories.blobstore;
<i>21</i>&nbsp;
<i>22</i>&nbsp;import org.apache.logging.log4j.LogManager;
<i>23</i>&nbsp;import org.apache.logging.log4j.Logger;
<i>24</i>&nbsp;import org.apache.logging.log4j.message.ParameterizedMessage;
<i>25</i>&nbsp;import org.apache.lucene.index.IndexCommit;
<i>26</i>&nbsp;import org.apache.lucene.store.IOContext;
<i>27</i>&nbsp;import org.apache.lucene.store.IndexInput;
<i>28</i>&nbsp;import org.apache.lucene.store.RateLimiter;
<i>29</i>&nbsp;import org.apache.lucene.util.SetOnce;
<i>30</i>&nbsp;import org.elasticsearch.Version;
<i>31</i>&nbsp;import org.elasticsearch.action.ActionListener;
<i>32</i>&nbsp;import org.elasticsearch.action.ActionRunnable;
<i>33</i>&nbsp;import org.elasticsearch.action.StepListener;
<i>34</i>&nbsp;import org.elasticsearch.action.support.GroupedActionListener;
<i>35</i>&nbsp;import org.elasticsearch.cluster.metadata.IndexMetaData;
<i>36</i>&nbsp;import org.elasticsearch.cluster.metadata.MetaData;
<i>37</i>&nbsp;import org.elasticsearch.cluster.metadata.RepositoryMetaData;
<i>38</i>&nbsp;import org.elasticsearch.cluster.node.DiscoveryNode;
<i>39</i>&nbsp;import org.elasticsearch.common.Numbers;
<i>40</i>&nbsp;import org.elasticsearch.common.Strings;
<i>41</i>&nbsp;import org.elasticsearch.common.UUIDs;
<i>42</i>&nbsp;import org.elasticsearch.common.blobstore.BlobContainer;
<i>43</i>&nbsp;import org.elasticsearch.common.blobstore.BlobMetaData;
<i>44</i>&nbsp;import org.elasticsearch.common.blobstore.BlobPath;
<i>45</i>&nbsp;import org.elasticsearch.common.blobstore.BlobStore;
<i>46</i>&nbsp;import org.elasticsearch.common.blobstore.DeleteResult;
<i>47</i>&nbsp;import org.elasticsearch.common.blobstore.fs.FsBlobContainer;
<i>48</i>&nbsp;import org.elasticsearch.common.bytes.BytesArray;
<i>49</i>&nbsp;import org.elasticsearch.common.bytes.BytesReference;
<i>50</i>&nbsp;import org.elasticsearch.common.collect.Tuple;
<i>51</i>&nbsp;import org.elasticsearch.common.component.AbstractLifecycleComponent;
<i>52</i>&nbsp;import org.elasticsearch.common.compress.NotXContentException;
<i>53</i>&nbsp;import org.elasticsearch.common.io.Streams;
<i>54</i>&nbsp;import org.elasticsearch.common.io.stream.BytesStreamOutput;
<i>55</i>&nbsp;import org.elasticsearch.common.lucene.Lucene;
<i>56</i>&nbsp;import org.elasticsearch.common.lucene.store.InputStreamIndexInput;
<i>57</i>&nbsp;import org.elasticsearch.common.metrics.CounterMetric;
<i>58</i>&nbsp;import org.elasticsearch.common.settings.Settings;
<i>59</i>&nbsp;import org.elasticsearch.common.unit.ByteSizeUnit;
<i>60</i>&nbsp;import org.elasticsearch.common.unit.ByteSizeValue;
<i>61</i>&nbsp;import org.elasticsearch.common.util.concurrent.AbstractRunnable;
<i>62</i>&nbsp;import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;
<i>63</i>&nbsp;import org.elasticsearch.common.xcontent.NamedXContentRegistry;
<i>64</i>&nbsp;import org.elasticsearch.common.xcontent.XContentFactory;
<i>65</i>&nbsp;import org.elasticsearch.common.xcontent.XContentParser;
<i>66</i>&nbsp;import org.elasticsearch.common.xcontent.XContentType;
<i>67</i>&nbsp;import org.elasticsearch.index.Index;
<i>68</i>&nbsp;import org.elasticsearch.index.mapper.MapperService;
<i>69</i>&nbsp;import org.elasticsearch.index.shard.ShardId;
<i>70</i>&nbsp;import org.elasticsearch.index.snapshots.IndexShardRestoreFailedException;
<i>71</i>&nbsp;import org.elasticsearch.index.snapshots.IndexShardSnapshotException;
<i>72</i>&nbsp;import org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException;
<i>73</i>&nbsp;import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;
<i>74</i>&nbsp;import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot;
<i>75</i>&nbsp;import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshots;
<i>76</i>&nbsp;import org.elasticsearch.index.snapshots.blobstore.RateLimitingInputStream;
<i>77</i>&nbsp;import org.elasticsearch.index.snapshots.blobstore.SlicedInputStream;
<i>78</i>&nbsp;import org.elasticsearch.index.snapshots.blobstore.SnapshotFiles;
<i>79</i>&nbsp;import org.elasticsearch.index.store.Store;
<i>80</i>&nbsp;import org.elasticsearch.index.store.StoreFileMetaData;
<i>81</i>&nbsp;import org.elasticsearch.indices.recovery.RecoveryState;
<i>82</i>&nbsp;import org.elasticsearch.repositories.IndexId;
<i>83</i>&nbsp;import org.elasticsearch.repositories.Repository;
<i>84</i>&nbsp;import org.elasticsearch.repositories.RepositoryCleanupResult;
<i>85</i>&nbsp;import org.elasticsearch.repositories.RepositoryData;
<i>86</i>&nbsp;import org.elasticsearch.repositories.RepositoryException;
<i>87</i>&nbsp;import org.elasticsearch.repositories.RepositoryVerificationException;
<i>88</i>&nbsp;import org.elasticsearch.snapshots.SnapshotCreationException;
<i>89</i>&nbsp;import org.elasticsearch.snapshots.SnapshotException;
<i>90</i>&nbsp;import org.elasticsearch.snapshots.SnapshotId;
<i>91</i>&nbsp;import org.elasticsearch.snapshots.SnapshotInfo;
<i>92</i>&nbsp;import org.elasticsearch.snapshots.SnapshotMissingException;
<i>93</i>&nbsp;import org.elasticsearch.snapshots.SnapshotShardFailure;
<i>94</i>&nbsp;import org.elasticsearch.threadpool.ThreadPool;
<i>95</i>&nbsp;
<i>96</i>&nbsp;import java.io.FilterInputStream;
<i>97</i>&nbsp;import java.io.IOException;
<i>98</i>&nbsp;import java.io.InputStream;
<i>99</i>&nbsp;import java.nio.file.NoSuchFileException;
<i>100</i>&nbsp;import java.util.ArrayList;
<i>101</i>&nbsp;import java.util.Collection;
<i>102</i>&nbsp;import java.util.Collections;
<i>103</i>&nbsp;import java.util.List;
<i>104</i>&nbsp;import java.util.Map;
<i>105</i>&nbsp;import java.util.Set;
<i>106</i>&nbsp;import java.util.concurrent.Executor;
<i>107</i>&nbsp;import java.util.concurrent.atomic.AtomicBoolean;
<i>108</i>&nbsp;import java.util.concurrent.atomic.AtomicLong;
<i>109</i>&nbsp;import java.util.stream.Collectors;
<i>110</i>&nbsp;import java.util.stream.Stream;
<i>111</i>&nbsp;
<i>112</i>&nbsp;import static org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo.canonicalName;
<i>113</i>&nbsp;
<i>114</i>&nbsp;/**
<i>115</i>&nbsp; * BlobStore - based implementation of Snapshot Repository
<i>116</i>&nbsp; * &lt;p&gt;
<i>117</i>&nbsp; * This repository works with any {@link BlobStore} implementation. The blobStore could be (and preferred) lazy initialized in
<i>118</i>&nbsp; * {@link #createBlobStore()}.
<i>119</i>&nbsp; * &lt;p&gt;
<i>120</i>&nbsp; * BlobStoreRepository maintains the following structure in the blob store
<i>121</i>&nbsp; * &lt;pre&gt;
<i>122</i>&nbsp; * {@code
<i>123</i>&nbsp; *   STORE_ROOT
<i>124</i>&nbsp; *   |- index-N           - JSON serialized {@link RepositoryData} containing a list of all snapshot ids and the indices belonging to
<i>125</i>&nbsp; *   |                      each snapshot, N is the generation of the file
<i>126</i>&nbsp; *   |- index.latest      - contains the numeric value of the latest generation of the index file (i.e. N from above)
<i>127</i>&nbsp; *   |- incompatible-snapshots - list of all snapshot ids that are no longer compatible with the current version of the cluster
<i>128</i>&nbsp; *   |- snap-20131010.dat - SMILE serialized {@link SnapshotInfo} for snapshot &quot;20131010&quot;
<i>129</i>&nbsp; *   |- meta-20131010.dat - SMILE serialized {@link MetaData} for snapshot &quot;20131010&quot; (includes only global metadata)
<i>130</i>&nbsp; *   |- snap-20131011.dat - SMILE serialized {@link SnapshotInfo} for snapshot &quot;20131011&quot;
<i>131</i>&nbsp; *   |- meta-20131011.dat - SMILE serialized {@link MetaData} for snapshot &quot;20131011&quot;
<i>132</i>&nbsp; *   .....
<i>133</i>&nbsp; *   |- indices/ - data for all indices
<i>134</i>&nbsp; *      |- Ac1342-B_x/ - data for index &quot;foo&quot; which was assigned the unique id of Ac1342-B_x in the repository
<i>135</i>&nbsp; *      |  |- meta-20131010.dat - JSON Serialized {@link IndexMetaData} for index &quot;foo&quot;
<i>136</i>&nbsp; *      |  |- 0/ - data for shard &quot;0&quot; of index &quot;foo&quot;
<i>137</i>&nbsp; *      |  |  |- __1                      \  (files with numeric names were created by older ES versions)
<i>138</i>&nbsp; *      |  |  |- __2                      |
<i>139</i>&nbsp; *      |  |  |- __VPO5oDMVT5y4Akv8T_AO_A |- files from different segments see snap-* for their mappings to real segment files
<i>140</i>&nbsp; *      |  |  |- __1gbJy18wS_2kv1qI7FgKuQ |
<i>141</i>&nbsp; *      |  |  |- __R8JvZAHlSMyMXyZc2SS8Zg /
<i>142</i>&nbsp; *      |  |  .....
<i>143</i>&nbsp; *      |  |  |- snap-20131010.dat - SMILE serialized {@link BlobStoreIndexShardSnapshot} for snapshot &quot;20131010&quot;
<i>144</i>&nbsp; *      |  |  |- snap-20131011.dat - SMILE serialized {@link BlobStoreIndexShardSnapshot} for snapshot &quot;20131011&quot;
<i>145</i>&nbsp; *      |  |  |- index-123 - SMILE serialized {@link BlobStoreIndexShardSnapshots} for the shard
<i>146</i>&nbsp; *      |  |
<i>147</i>&nbsp; *      |  |- 1/ - data for shard &quot;1&quot; of index &quot;foo&quot;
<i>148</i>&nbsp; *      |  |  |- __1
<i>149</i>&nbsp; *      |  |  .....
<i>150</i>&nbsp; *      |  |
<i>151</i>&nbsp; *      |  |-2/
<i>152</i>&nbsp; *      |  ......
<i>153</i>&nbsp; *      |
<i>154</i>&nbsp; *      |- 1xB0D8_B3y/ - data for index &quot;bar&quot; which was assigned the unique id of 1xB0D8_B3y in the repository
<i>155</i>&nbsp; *      ......
<i>156</i>&nbsp; * }
<i>157</i>&nbsp; * &lt;/pre&gt;
<i>158</i>&nbsp; */
<b class="fc"><i>159</i>&nbsp;public abstract class BlobStoreRepository extends AbstractLifecycleComponent implements Repository {</b>
<b class="fc"><i>160</i>&nbsp;    private static final Logger logger = LogManager.getLogger(BlobStoreRepository.class);</b>
<i>161</i>&nbsp;
<i>162</i>&nbsp;    protected final RepositoryMetaData metadata;
<i>163</i>&nbsp;
<i>164</i>&nbsp;    protected final NamedXContentRegistry namedXContentRegistry;
<i>165</i>&nbsp;
<i>166</i>&nbsp;    protected final ThreadPool threadPool;
<i>167</i>&nbsp;
<i>168</i>&nbsp;    private static final int BUFFER_SIZE = 4096;
<i>169</i>&nbsp;
<i>170</i>&nbsp;    public static final String SNAPSHOT_PREFIX = &quot;snap-&quot;;
<i>171</i>&nbsp;
<i>172</i>&nbsp;    public static final String SNAPSHOT_CODEC = &quot;snapshot&quot;;
<i>173</i>&nbsp;
<i>174</i>&nbsp;    public static final String INDEX_FILE_PREFIX = &quot;index-&quot;;
<i>175</i>&nbsp;
<i>176</i>&nbsp;    public static final String INDEX_LATEST_BLOB = &quot;index.latest&quot;;
<i>177</i>&nbsp;
<i>178</i>&nbsp;    private static final String TESTS_FILE = &quot;tests-&quot;;
<i>179</i>&nbsp;
<i>180</i>&nbsp;    public static final String METADATA_PREFIX = &quot;meta-&quot;;
<i>181</i>&nbsp;
<i>182</i>&nbsp;    public static final String METADATA_NAME_FORMAT = METADATA_PREFIX + &quot;%s.dat&quot;;
<i>183</i>&nbsp;
<i>184</i>&nbsp;    private static final String METADATA_CODEC = &quot;metadata&quot;;
<i>185</i>&nbsp;
<i>186</i>&nbsp;    private static final String INDEX_METADATA_CODEC = &quot;index-metadata&quot;;
<i>187</i>&nbsp;
<i>188</i>&nbsp;    public static final String SNAPSHOT_NAME_FORMAT = SNAPSHOT_PREFIX + &quot;%s.dat&quot;;
<i>189</i>&nbsp;
<i>190</i>&nbsp;    private static final String SNAPSHOT_INDEX_PREFIX = &quot;index-&quot;;
<i>191</i>&nbsp;
<i>192</i>&nbsp;    private static final String SNAPSHOT_INDEX_NAME_FORMAT = SNAPSHOT_INDEX_PREFIX + &quot;%s&quot;;
<i>193</i>&nbsp;
<i>194</i>&nbsp;    private static final String SNAPSHOT_INDEX_CODEC = &quot;snapshots&quot;;
<i>195</i>&nbsp;
<i>196</i>&nbsp;    private static final String DATA_BLOB_PREFIX = &quot;__&quot;;
<i>197</i>&nbsp;
<i>198</i>&nbsp;    private final boolean compress;
<i>199</i>&nbsp;
<i>200</i>&nbsp;    private final RateLimiter snapshotRateLimiter;
<i>201</i>&nbsp;
<i>202</i>&nbsp;    private final RateLimiter restoreRateLimiter;
<i>203</i>&nbsp;
<b class="nc"><i>204</i>&nbsp;    private final CounterMetric snapshotRateLimitingTimeInNanos = new CounterMetric();</b>
<i>205</i>&nbsp;
<b class="nc"><i>206</i>&nbsp;    private final CounterMetric restoreRateLimitingTimeInNanos = new CounterMetric();</b>
<i>207</i>&nbsp;
<i>208</i>&nbsp;    private ChecksumBlobStoreFormat&lt;MetaData&gt; globalMetaDataFormat;
<i>209</i>&nbsp;
<i>210</i>&nbsp;    private ChecksumBlobStoreFormat&lt;IndexMetaData&gt; indexMetaDataFormat;
<i>211</i>&nbsp;
<i>212</i>&nbsp;    protected ChecksumBlobStoreFormat&lt;SnapshotInfo&gt; snapshotFormat;
<i>213</i>&nbsp;
<i>214</i>&nbsp;    private final boolean readOnly;
<i>215</i>&nbsp;
<i>216</i>&nbsp;    private final ChecksumBlobStoreFormat&lt;BlobStoreIndexShardSnapshot&gt; indexShardSnapshotFormat;
<i>217</i>&nbsp;
<i>218</i>&nbsp;    private final ChecksumBlobStoreFormat&lt;BlobStoreIndexShardSnapshots&gt; indexShardSnapshotsFormat;
<i>219</i>&nbsp;
<b class="nc"><i>220</i>&nbsp;    private final Object lock = new Object();</b>
<i>221</i>&nbsp;
<b class="nc"><i>222</i>&nbsp;    private final SetOnce&lt;BlobContainer&gt; blobContainer = new SetOnce&lt;&gt;();</b>
<i>223</i>&nbsp;
<b class="nc"><i>224</i>&nbsp;    private final SetOnce&lt;BlobStore&gt; blobStore = new SetOnce&lt;&gt;();</b>
<i>225</i>&nbsp;
<i>226</i>&nbsp;    /**
<i>227</i>&nbsp;     * Constructs new BlobStoreRepository
<i>228</i>&nbsp;     * @param metadata   The metadata for this repository including name and settings
<i>229</i>&nbsp;     * @param threadPool Threadpool to run long running repository manipulations on asynchronously
<i>230</i>&nbsp;     */
<i>231</i>&nbsp;    protected BlobStoreRepository(
<i>232</i>&nbsp;        final RepositoryMetaData metadata,
<i>233</i>&nbsp;        final boolean compress,
<i>234</i>&nbsp;        final NamedXContentRegistry namedXContentRegistry,
<b class="nc"><i>235</i>&nbsp;        final ThreadPool threadPool) {</b>
<b class="nc"><i>236</i>&nbsp;        this.compress = compress;</b>
<b class="nc"><i>237</i>&nbsp;        this.metadata = metadata;</b>
<b class="nc"><i>238</i>&nbsp;        this.namedXContentRegistry = namedXContentRegistry;</b>
<b class="nc"><i>239</i>&nbsp;        this.threadPool = threadPool;</b>
<b class="nc"><i>240</i>&nbsp;        snapshotRateLimiter = getRateLimiter(metadata.settings(), &quot;max_snapshot_bytes_per_sec&quot;, new ByteSizeValue(40, ByteSizeUnit.MB));</b>
<b class="nc"><i>241</i>&nbsp;        restoreRateLimiter = getRateLimiter(metadata.settings(), &quot;max_restore_bytes_per_sec&quot;, new ByteSizeValue(40, ByteSizeUnit.MB));</b>
<b class="nc"><i>242</i>&nbsp;        readOnly = metadata.settings().getAsBoolean(&quot;readonly&quot;, false);</b>
<i>243</i>&nbsp;
<i>244</i>&nbsp;
<b class="nc"><i>245</i>&nbsp;        indexShardSnapshotFormat = new ChecksumBlobStoreFormat&lt;&gt;(SNAPSHOT_CODEC, SNAPSHOT_NAME_FORMAT,</b>
<i>246</i>&nbsp;            BlobStoreIndexShardSnapshot::fromXContent, namedXContentRegistry, compress);
<b class="nc"><i>247</i>&nbsp;        indexShardSnapshotsFormat = new ChecksumBlobStoreFormat&lt;&gt;(SNAPSHOT_INDEX_CODEC, SNAPSHOT_INDEX_NAME_FORMAT,</b>
<i>248</i>&nbsp;            BlobStoreIndexShardSnapshots::fromXContent, namedXContentRegistry, compress);
<b class="nc"><i>249</i>&nbsp;    }</b>
<i>250</i>&nbsp;
<i>251</i>&nbsp;    @Override
<i>252</i>&nbsp;    protected void doStart() {
<b class="nc"><i>253</i>&nbsp;        ByteSizeValue chunkSize = chunkSize();</b>
<b class="nc"><i>254</i>&nbsp;        if (chunkSize != null &amp;&amp; chunkSize.getBytes() &lt;= 0) {</b>
<b class="nc"><i>255</i>&nbsp;            throw new IllegalArgumentException(&quot;the chunk size cannot be negative: [&quot; + chunkSize + &quot;]&quot;);</b>
<i>256</i>&nbsp;        }
<b class="nc"><i>257</i>&nbsp;        globalMetaDataFormat = new ChecksumBlobStoreFormat&lt;&gt;(METADATA_CODEC, METADATA_NAME_FORMAT,</b>
<i>258</i>&nbsp;            MetaData::fromXContent, namedXContentRegistry, compress);
<b class="nc"><i>259</i>&nbsp;        indexMetaDataFormat = new ChecksumBlobStoreFormat&lt;&gt;(INDEX_METADATA_CODEC, METADATA_NAME_FORMAT,</b>
<i>260</i>&nbsp;            IndexMetaData::fromXContent, namedXContentRegistry, compress);
<b class="nc"><i>261</i>&nbsp;        snapshotFormat = new ChecksumBlobStoreFormat&lt;&gt;(SNAPSHOT_CODEC, SNAPSHOT_NAME_FORMAT,</b>
<i>262</i>&nbsp;            SnapshotInfo::fromXContentInternal, namedXContentRegistry, compress);
<b class="nc"><i>263</i>&nbsp;    }</b>
<i>264</i>&nbsp;
<i>265</i>&nbsp;    @Override
<b class="nc"><i>266</i>&nbsp;    protected void doStop() {}</b>
<i>267</i>&nbsp;
<i>268</i>&nbsp;    @Override
<i>269</i>&nbsp;    protected void doClose() {
<i>270</i>&nbsp;        BlobStore store;
<i>271</i>&nbsp;        // to close blobStore if blobStore initialization is started during close
<b class="nc"><i>272</i>&nbsp;        synchronized (lock) {</b>
<b class="nc"><i>273</i>&nbsp;            store = blobStore.get();</b>
<b class="nc"><i>274</i>&nbsp;        }</b>
<b class="nc"><i>275</i>&nbsp;        if (store != null) {</b>
<i>276</i>&nbsp;            try {
<b class="nc"><i>277</i>&nbsp;                store.close();</b>
<b class="nc"><i>278</i>&nbsp;            } catch (Exception t) {</b>
<b class="nc"><i>279</i>&nbsp;                logger.warn(&quot;cannot close blob store&quot;, t);</b>
<b class="nc"><i>280</i>&nbsp;            }</b>
<i>281</i>&nbsp;        }
<b class="nc"><i>282</i>&nbsp;    }</b>
<i>283</i>&nbsp;
<i>284</i>&nbsp;    public ThreadPool threadPool() {
<b class="nc"><i>285</i>&nbsp;        return threadPool;</b>
<i>286</i>&nbsp;    }
<i>287</i>&nbsp;
<i>288</i>&nbsp;    // package private, only use for testing
<i>289</i>&nbsp;    BlobContainer getBlobContainer() {
<b class="nc"><i>290</i>&nbsp;        return blobContainer.get();</b>
<i>291</i>&nbsp;    }
<i>292</i>&nbsp;
<i>293</i>&nbsp;    // for test purposes only
<i>294</i>&nbsp;    protected BlobStore getBlobStore() {
<b class="nc"><i>295</i>&nbsp;        return blobStore.get();</b>
<i>296</i>&nbsp;    }
<i>297</i>&nbsp;
<i>298</i>&nbsp;    /**
<i>299</i>&nbsp;     * maintains single lazy instance of {@link BlobContainer}
<i>300</i>&nbsp;     */
<i>301</i>&nbsp;    protected BlobContainer blobContainer() {
<b class="nc"><i>302</i>&nbsp;        assertSnapshotOrGenericThread();</b>
<i>303</i>&nbsp;
<b class="nc"><i>304</i>&nbsp;        BlobContainer blobContainer = this.blobContainer.get();</b>
<b class="nc"><i>305</i>&nbsp;        if (blobContainer == null) {</b>
<b class="nc"><i>306</i>&nbsp;           synchronized (lock) {</b>
<b class="nc"><i>307</i>&nbsp;               blobContainer = this.blobContainer.get();</b>
<b class="nc"><i>308</i>&nbsp;               if (blobContainer == null) {</b>
<b class="nc"><i>309</i>&nbsp;                   blobContainer = blobStore().blobContainer(basePath());</b>
<b class="nc"><i>310</i>&nbsp;                   this.blobContainer.set(blobContainer);</b>
<i>311</i>&nbsp;               }
<b class="nc"><i>312</i>&nbsp;           }</b>
<i>313</i>&nbsp;        }
<i>314</i>&nbsp;
<b class="nc"><i>315</i>&nbsp;        return blobContainer;</b>
<i>316</i>&nbsp;    }
<i>317</i>&nbsp;
<i>318</i>&nbsp;    /**
<i>319</i>&nbsp;     * Maintains single lazy instance of {@link BlobStore}.
<i>320</i>&nbsp;     * Public for testing.
<i>321</i>&nbsp;     */
<i>322</i>&nbsp;    public BlobStore blobStore() {
<b class="nc"><i>323</i>&nbsp;        assertSnapshotOrGenericThread();</b>
<i>324</i>&nbsp;
<b class="nc"><i>325</i>&nbsp;        BlobStore store = blobStore.get();</b>
<b class="nc"><i>326</i>&nbsp;        if (store == null) {</b>
<b class="nc"><i>327</i>&nbsp;            synchronized (lock) {</b>
<b class="nc"><i>328</i>&nbsp;                store = blobStore.get();</b>
<b class="nc"><i>329</i>&nbsp;                if (store == null) {</b>
<b class="nc"><i>330</i>&nbsp;                    if (lifecycle.started() == false) {</b>
<b class="nc"><i>331</i>&nbsp;                        throw new RepositoryException(metadata.name(), &quot;repository is not in started state&quot;);</b>
<i>332</i>&nbsp;                    }
<i>333</i>&nbsp;                    try {
<b class="nc"><i>334</i>&nbsp;                        store = createBlobStore();</b>
<b class="nc"><i>335</i>&nbsp;                    } catch (RepositoryException e) {</b>
<b class="nc"><i>336</i>&nbsp;                        throw e;</b>
<b class="nc"><i>337</i>&nbsp;                    } catch (Exception e) {</b>
<b class="nc"><i>338</i>&nbsp;                        throw new RepositoryException(metadata.name(), &quot;cannot create blob store&quot; , e);</b>
<b class="nc"><i>339</i>&nbsp;                    }</b>
<b class="nc"><i>340</i>&nbsp;                    blobStore.set(store);</b>
<i>341</i>&nbsp;                }
<b class="nc"><i>342</i>&nbsp;            }</b>
<i>343</i>&nbsp;        }
<b class="nc"><i>344</i>&nbsp;        return store;</b>
<i>345</i>&nbsp;    }
<i>346</i>&nbsp;
<i>347</i>&nbsp;    /**
<i>348</i>&nbsp;     * Creates new BlobStore to read and write data.
<i>349</i>&nbsp;     */
<i>350</i>&nbsp;    protected abstract BlobStore createBlobStore() throws Exception;
<i>351</i>&nbsp;
<i>352</i>&nbsp;    /**
<i>353</i>&nbsp;     * Returns base path of the repository
<i>354</i>&nbsp;     */
<i>355</i>&nbsp;    public abstract BlobPath basePath();
<i>356</i>&nbsp;
<i>357</i>&nbsp;    /**
<i>358</i>&nbsp;     * Returns true if metadata and snapshot files should be compressed
<i>359</i>&nbsp;     *
<i>360</i>&nbsp;     * @return true if compression is needed
<i>361</i>&nbsp;     */
<i>362</i>&nbsp;    protected final boolean isCompress() {
<b class="nc"><i>363</i>&nbsp;        return compress;</b>
<i>364</i>&nbsp;    }
<i>365</i>&nbsp;
<i>366</i>&nbsp;    /**
<i>367</i>&nbsp;     * Returns data file chunk size.
<i>368</i>&nbsp;     * &lt;p&gt;
<i>369</i>&nbsp;     * This method should return null if no chunking is needed.
<i>370</i>&nbsp;     *
<i>371</i>&nbsp;     * @return chunk size
<i>372</i>&nbsp;     */
<i>373</i>&nbsp;    protected ByteSizeValue chunkSize() {
<b class="nc"><i>374</i>&nbsp;        return null;</b>
<i>375</i>&nbsp;    }
<i>376</i>&nbsp;
<i>377</i>&nbsp;    @Override
<i>378</i>&nbsp;    public RepositoryMetaData getMetadata() {
<b class="nc"><i>379</i>&nbsp;        return metadata;</b>
<i>380</i>&nbsp;    }
<i>381</i>&nbsp;
<i>382</i>&nbsp;    @Override
<i>383</i>&nbsp;    public void initializeSnapshot(SnapshotId snapshotId, List&lt;IndexId&gt; indices, MetaData clusterMetaData) {
<i>384</i>&nbsp;        try {
<i>385</i>&nbsp;            // Write Global MetaData
<b class="nc"><i>386</i>&nbsp;            globalMetaDataFormat.write(clusterMetaData, blobContainer(), snapshotId.getUUID(), true);</b>
<i>387</i>&nbsp;
<i>388</i>&nbsp;            // write the index metadata for each index in the snapshot
<b class="nc"><i>389</i>&nbsp;            for (IndexId index : indices) {</b>
<b class="nc"><i>390</i>&nbsp;                indexMetaDataFormat.write(clusterMetaData.index(index.getName()), indexContainer(index), snapshotId.getUUID(), true);</b>
<b class="nc"><i>391</i>&nbsp;            }</b>
<b class="nc"><i>392</i>&nbsp;        } catch (IOException ex) {</b>
<b class="nc"><i>393</i>&nbsp;            throw new SnapshotCreationException(metadata.name(), snapshotId, ex);</b>
<b class="nc"><i>394</i>&nbsp;        }</b>
<b class="nc"><i>395</i>&nbsp;    }</b>
<i>396</i>&nbsp;
<i>397</i>&nbsp;    @Override
<i>398</i>&nbsp;    public void deleteSnapshot(SnapshotId snapshotId, long repositoryStateId, ActionListener&lt;Void&gt; listener) {
<b class="nc"><i>399</i>&nbsp;        if (isReadOnly()) {</b>
<b class="nc"><i>400</i>&nbsp;            listener.onFailure(new RepositoryException(metadata.name(), &quot;cannot delete snapshot from a readonly repository&quot;));</b>
<i>401</i>&nbsp;        } else {
<i>402</i>&nbsp;            try {
<b class="nc"><i>403</i>&nbsp;                final Map&lt;String, BlobMetaData&gt; rootBlobs = blobContainer().listBlobs();</b>
<b class="nc"><i>404</i>&nbsp;                final RepositoryData repositoryData = safeRepositoryData(repositoryStateId, rootBlobs);</b>
<i>405</i>&nbsp;                // Cache the indices that were found before writing out the new index-N blob so that a stuck master will never
<i>406</i>&nbsp;                // delete an index that was created by another master node after writing this index-N blob.
<b class="nc"><i>407</i>&nbsp;                final Map&lt;String, BlobContainer&gt; foundIndices = blobStore().blobContainer(indicesPath()).children();</b>
<b class="nc"><i>408</i>&nbsp;                doDeleteShardSnapshots(snapshotId, repositoryStateId, foundIndices, rootBlobs, repositoryData, listener);</b>
<b class="nc"><i>409</i>&nbsp;            } catch (Exception ex) {</b>
<b class="nc"><i>410</i>&nbsp;                listener.onFailure(new RepositoryException(metadata.name(), &quot;failed to delete snapshot [&quot; + snapshotId + &quot;]&quot;, ex));</b>
<b class="nc"><i>411</i>&nbsp;            }</b>
<i>412</i>&nbsp;        }
<b class="nc"><i>413</i>&nbsp;    }</b>
<i>414</i>&nbsp;
<i>415</i>&nbsp;    /**
<i>416</i>&nbsp;     * Loads {@link RepositoryData} ensuring that it is consistent with the given {@code rootBlobs} as well of the assumed generation.
<i>417</i>&nbsp;     *
<i>418</i>&nbsp;     * @param repositoryStateId Expected repository generation
<i>419</i>&nbsp;     * @param rootBlobs         Blobs at the repository root
<i>420</i>&nbsp;     * @return RepositoryData
<i>421</i>&nbsp;     */
<i>422</i>&nbsp;    private RepositoryData safeRepositoryData(long repositoryStateId, Map&lt;String, BlobMetaData&gt; rootBlobs) {
<b class="nc"><i>423</i>&nbsp;        final long generation = latestGeneration(rootBlobs.keySet());</b>
<b class="nc"><i>424</i>&nbsp;        final long genToLoad = latestKnownRepoGen.updateAndGet(known -&gt; Math.max(known, repositoryStateId));</b>
<b class="nc"><i>425</i>&nbsp;        if (genToLoad &gt; generation) {</b>
<i>426</i>&nbsp;            // It&#39;s always a possibility to not see the latest index-N in the listing here on an eventually consistent blob store, just
<i>427</i>&nbsp;            // debug log it. Any blobs leaked as a result of an inconsistent listing here will be cleaned up in a subsequent cleanup or
<i>428</i>&nbsp;            // snapshot delete run anyway.
<b class="nc"><i>429</i>&nbsp;            logger.debug(&quot;Determined repository&#39;s generation from its contents to [&quot; + generation + &quot;] but &quot; +</b>
<i>430</i>&nbsp;                &quot;current generation is at least [&quot; + genToLoad + &quot;]&quot;);
<i>431</i>&nbsp;        }
<b class="nc"><i>432</i>&nbsp;        if (genToLoad != repositoryStateId) {</b>
<b class="nc"><i>433</i>&nbsp;            throw new RepositoryException(metadata.name(), &quot;concurrent modification of the index-N file, expected current generation [&quot; +</b>
<i>434</i>&nbsp;                repositoryStateId + &quot;], actual current generation [&quot; + genToLoad + &quot;]&quot;);
<i>435</i>&nbsp;        }
<b class="nc"><i>436</i>&nbsp;        return getRepositoryData(genToLoad);</b>
<i>437</i>&nbsp;    }
<i>438</i>&nbsp;
<i>439</i>&nbsp;    /**
<i>440</i>&nbsp;     * After updating the {@link RepositoryData} each of the shards directories is individually first moved to the next shard generation
<i>441</i>&nbsp;     * and then has all now unreferenced blobs in it deleted.
<i>442</i>&nbsp;     *
<i>443</i>&nbsp;     * @param snapshotId        SnapshotId to delete
<i>444</i>&nbsp;     * @param repositoryStateId Expected repository state id
<i>445</i>&nbsp;     * @param foundIndices      All indices folders found in the repository before executing any writes to the repository during this
<i>446</i>&nbsp;     *                          delete operation
<i>447</i>&nbsp;     * @param rootBlobs         All blobs found at the root of the repository before executing any writes to the repository during this
<i>448</i>&nbsp;     *                          delete operation
<i>449</i>&nbsp;     * @param repositoryData    RepositoryData found the in the repository before executing this delete
<i>450</i>&nbsp;     * @param listener          Listener to invoke once finished
<i>451</i>&nbsp;     */
<i>452</i>&nbsp;    private void doDeleteShardSnapshots(SnapshotId snapshotId, long repositoryStateId, Map&lt;String, BlobContainer&gt; foundIndices,
<i>453</i>&nbsp;                                        Map&lt;String, BlobMetaData&gt; rootBlobs, RepositoryData repositoryData,
<i>454</i>&nbsp;                                        ActionListener&lt;Void&gt; listener) throws IOException {
<b class="nc"><i>455</i>&nbsp;        final RepositoryData updatedRepositoryData = repositoryData.removeSnapshot(snapshotId);</b>
<b class="nc"><i>456</i>&nbsp;        writeIndexGen(updatedRepositoryData, repositoryStateId);</b>
<b class="nc"><i>457</i>&nbsp;        final ActionListener&lt;Void&gt; afterCleanupsListener =</b>
<b class="nc"><i>458</i>&nbsp;            new GroupedActionListener&lt;&gt;(ActionListener.wrap(() -&gt; listener.onResponse(null)), 2);</b>
<i>459</i>&nbsp;
<i>460</i>&nbsp;        // Run unreferenced blobs cleanup in parallel to snapshot deletion
<b class="nc"><i>461</i>&nbsp;        threadPool.executor(ThreadPool.Names.SNAPSHOT).execute(ActionRunnable.wrap(afterCleanupsListener,</b>
<b class="nc"><i>462</i>&nbsp;            l -&gt; cleanupStaleBlobs(foundIndices, rootBlobs, updatedRepositoryData, ActionListener.map(l, ignored -&gt; null))));</b>
<i>463</i>&nbsp;
<b class="nc"><i>464</i>&nbsp;        deleteIndices(</b>
<i>465</i>&nbsp;            updatedRepositoryData,
<b class="nc"><i>466</i>&nbsp;            repositoryData.indicesToUpdateAfterRemovingSnapshot(snapshotId),</b>
<i>467</i>&nbsp;            snapshotId,
<b class="nc"><i>468</i>&nbsp;            ActionListener.runAfter(</b>
<b class="nc"><i>469</i>&nbsp;                ActionListener.wrap(</b>
<i>470</i>&nbsp;                    deleteResults -&gt; {
<i>471</i>&nbsp;                        // Now that all metadata (RepositoryData at the repo root as well as index-N blobs in all shard paths)
<i>472</i>&nbsp;                        // has been updated we can execute the delete operations for all blobs that have become unreferenced as a result
<b class="nc"><i>473</i>&nbsp;                        final String basePath = basePath().buildAsString();</b>
<b class="nc"><i>474</i>&nbsp;                        final int basePathLen = basePath.length();</b>
<b class="nc"><i>475</i>&nbsp;                        blobContainer().deleteBlobsIgnoringIfNotExists(</b>
<b class="nc"><i>476</i>&nbsp;                            Stream.concat(</b>
<b class="nc"><i>477</i>&nbsp;                                deleteResults.stream().flatMap(shardResult -&gt; {</b>
<b class="nc"><i>478</i>&nbsp;                                    final String shardPath =</b>
<b class="nc"><i>479</i>&nbsp;                                        shardContainer(shardResult.indexId, shardResult.shardId).path().buildAsString();</b>
<b class="nc"><i>480</i>&nbsp;                                    return shardResult.blobsToDelete.stream().map(blob -&gt; shardPath + blob);</b>
<i>481</i>&nbsp;                                }),
<b class="nc"><i>482</i>&nbsp;                                deleteResults.stream().map(shardResult -&gt; shardResult.indexId).distinct().map(indexId -&gt;</b>
<b class="nc"><i>483</i>&nbsp;                                    indexContainer(indexId).path().buildAsString() + globalMetaDataFormat.blobName(snapshotId.getUUID()))</b>
<b class="nc"><i>484</i>&nbsp;                            ).map(absolutePath -&gt; {</b>
<b class="nc"><i>485</i>&nbsp;                                assert absolutePath.startsWith(basePath);</b>
<b class="nc"><i>486</i>&nbsp;                                return absolutePath.substring(basePathLen);</b>
<b class="nc"><i>487</i>&nbsp;                            }).collect(Collectors.toList()));</b>
<b class="nc"><i>488</i>&nbsp;                    },</b>
<i>489</i>&nbsp;                    // Any exceptions after we have updated the root level RepositoryData are only logged but won&#39;t fail the delete request
<b class="nc"><i>490</i>&nbsp;                    e -&gt; logger.warn(</b>
<b class="nc"><i>491</i>&nbsp;                        () -&gt; new ParameterizedMessage(&quot;[{}] Failed to delete some blobs during snapshot delete&quot;, snapshotId), e)),</b>
<b class="nc"><i>492</i>&nbsp;                () -&gt; afterCleanupsListener.onResponse(null))</b>
<i>493</i>&nbsp;        );
<b class="nc"><i>494</i>&nbsp;    }</b>
<i>495</i>&nbsp;
<i>496</i>&nbsp;    /**
<i>497</i>&nbsp;     * Cleans up stale blobs directly under the repository root as well as all indices paths that aren&#39;t referenced by any existing
<i>498</i>&nbsp;     * snapshots. This method is only to be called directly after a new {@link RepositoryData} was written to the repository and with
<i>499</i>&nbsp;     * parameters {@code foundIndices}, {@code rootBlobs}
<i>500</i>&nbsp;     *
<i>501</i>&nbsp;     * @param foundIndices all indices blob containers found in the repository before {@code newRepoData} was written
<i>502</i>&nbsp;     * @param rootBlobs    all blobs found directly under the repository root
<i>503</i>&nbsp;     * @param newRepoData  new repository data that was just written
<i>504</i>&nbsp;     * @param listener     listener to invoke with the combined {@link DeleteResult} of all blobs removed in this operation
<i>505</i>&nbsp;     */
<i>506</i>&nbsp;    private void cleanupStaleBlobs(Map&lt;String, BlobContainer&gt; foundIndices, Map&lt;String, BlobMetaData&gt; rootBlobs,
<i>507</i>&nbsp;                                   RepositoryData newRepoData, ActionListener&lt;DeleteResult&gt; listener) {
<b class="nc"><i>508</i>&nbsp;        final GroupedActionListener&lt;DeleteResult&gt; groupedListener = new GroupedActionListener&lt;&gt;(ActionListener.wrap(deleteResults -&gt; {</b>
<b class="nc"><i>509</i>&nbsp;            DeleteResult deleteResult = DeleteResult.ZERO;</b>
<b class="nc"><i>510</i>&nbsp;            for (DeleteResult result : deleteResults) {</b>
<b class="nc"><i>511</i>&nbsp;                deleteResult = deleteResult.add(result);</b>
<b class="nc"><i>512</i>&nbsp;            }</b>
<b class="nc"><i>513</i>&nbsp;            listener.onResponse(deleteResult);</b>
<b class="nc"><i>514</i>&nbsp;        }, listener::onFailure), 2);</b>
<i>515</i>&nbsp;
<b class="nc"><i>516</i>&nbsp;        final Executor executor = threadPool.executor(ThreadPool.Names.SNAPSHOT);</b>
<b class="nc"><i>517</i>&nbsp;        executor.execute(ActionRunnable.supply(groupedListener, () -&gt; {</b>
<b class="nc"><i>518</i>&nbsp;            List&lt;String&gt; deletedBlobs = cleanupStaleRootFiles(staleRootBlobs(newRepoData, rootBlobs.keySet()));</b>
<b class="nc"><i>519</i>&nbsp;            return new DeleteResult(deletedBlobs.size(), deletedBlobs.stream().mapToLong(name -&gt; rootBlobs.get(name).length()).sum());</b>
<i>520</i>&nbsp;        }));
<i>521</i>&nbsp;
<b class="nc"><i>522</i>&nbsp;        final Set&lt;String&gt; survivingIndexIds = newRepoData.getIndices().values().stream().map(IndexId::getId).collect(Collectors.toSet());</b>
<b class="nc"><i>523</i>&nbsp;        executor.execute(ActionRunnable.supply(groupedListener, () -&gt; cleanupStaleIndices(foundIndices, survivingIndexIds)));</b>
<b class="nc"><i>524</i>&nbsp;    }</b>
<i>525</i>&nbsp;
<i>526</i>&nbsp;    /**
<i>527</i>&nbsp;     * Runs cleanup actions on the repository. Increments the repository state id by one before executing any modifications on the
<i>528</i>&nbsp;     * repository.
<i>529</i>&nbsp;     * TODO: Add shard level cleanups
<i>530</i>&nbsp;     * &lt;ul&gt;
<i>531</i>&nbsp;     *     &lt;li&gt;Deleting stale indices {@link #cleanupStaleIndices}&lt;/li&gt;
<i>532</i>&nbsp;     *     &lt;li&gt;Deleting unreferenced root level blobs {@link #cleanupStaleRootFiles}&lt;/li&gt;
<i>533</i>&nbsp;     * &lt;/ul&gt;
<i>534</i>&nbsp;     * @param repositoryStateId Current repository state id
<i>535</i>&nbsp;     * @param listener Lister to complete when done
<i>536</i>&nbsp;     */
<i>537</i>&nbsp;    public void cleanup(long repositoryStateId, ActionListener&lt;RepositoryCleanupResult&gt; listener) {
<i>538</i>&nbsp;        try {
<b class="nc"><i>539</i>&nbsp;            if (isReadOnly()) {</b>
<b class="nc"><i>540</i>&nbsp;                throw new RepositoryException(metadata.name(), &quot;cannot run cleanup on readonly repository&quot;);</b>
<i>541</i>&nbsp;            }
<b class="nc"><i>542</i>&nbsp;            Map&lt;String, BlobMetaData&gt; rootBlobs = blobContainer().listBlobs();</b>
<b class="nc"><i>543</i>&nbsp;            final RepositoryData repositoryData = safeRepositoryData(repositoryStateId, rootBlobs);</b>
<b class="nc"><i>544</i>&nbsp;            final Map&lt;String, BlobContainer&gt; foundIndices = blobStore().blobContainer(indicesPath()).children();</b>
<b class="nc"><i>545</i>&nbsp;            final Set&lt;String&gt; survivingIndexIds =</b>
<b class="nc"><i>546</i>&nbsp;                repositoryData.getIndices().values().stream().map(IndexId::getId).collect(Collectors.toSet());</b>
<b class="nc"><i>547</i>&nbsp;            final List&lt;String&gt; staleRootBlobs = staleRootBlobs(repositoryData, rootBlobs.keySet());</b>
<b class="nc"><i>548</i>&nbsp;            if (survivingIndexIds.equals(foundIndices.keySet()) &amp;&amp; staleRootBlobs.isEmpty()) {</b>
<i>549</i>&nbsp;                // Nothing to clean up we return
<b class="nc"><i>550</i>&nbsp;                listener.onResponse(new RepositoryCleanupResult(DeleteResult.ZERO));</b>
<i>551</i>&nbsp;            } else {
<i>552</i>&nbsp;                // write new index-N blob to ensure concurrent operations will fail
<b class="nc"><i>553</i>&nbsp;                writeIndexGen(repositoryData, repositoryStateId);</b>
<b class="nc"><i>554</i>&nbsp;                cleanupStaleBlobs(foundIndices, rootBlobs, repositoryData, ActionListener.map(listener, RepositoryCleanupResult::new));</b>
<i>555</i>&nbsp;            }
<b class="nc"><i>556</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>557</i>&nbsp;            listener.onFailure(e);</b>
<b class="nc"><i>558</i>&nbsp;        }</b>
<b class="nc"><i>559</i>&nbsp;    }</b>
<i>560</i>&nbsp;
<i>561</i>&nbsp;    // Finds all blobs directly under the repository root path that are not referenced by the current RepositoryData
<i>562</i>&nbsp;    private List&lt;String&gt; staleRootBlobs(RepositoryData repositoryData, Set&lt;String&gt; rootBlobNames) {
<b class="nc"><i>563</i>&nbsp;        final Set&lt;String&gt; allSnapshotIds =</b>
<b class="nc"><i>564</i>&nbsp;            repositoryData.getSnapshotIds().stream().map(SnapshotId::getUUID).collect(Collectors.toSet());</b>
<b class="nc"><i>565</i>&nbsp;        return rootBlobNames.stream().filter(</b>
<i>566</i>&nbsp;            blob -&gt; {
<b class="nc"><i>567</i>&nbsp;                if (FsBlobContainer.isTempBlobName(blob)) {</b>
<b class="nc"><i>568</i>&nbsp;                    return true;</b>
<i>569</i>&nbsp;                }
<b class="nc"><i>570</i>&nbsp;                if (blob.endsWith(&quot;.dat&quot;)) {</b>
<i>571</i>&nbsp;                    final String foundUUID;
<b class="nc"><i>572</i>&nbsp;                    if (blob.startsWith(SNAPSHOT_PREFIX)) {</b>
<b class="nc"><i>573</i>&nbsp;                        foundUUID = blob.substring(SNAPSHOT_PREFIX.length(), blob.length() - &quot;.dat&quot;.length());</b>
<b class="nc"><i>574</i>&nbsp;                        assert snapshotFormat.blobName(foundUUID).equals(blob);</b>
<b class="nc"><i>575</i>&nbsp;                    } else if (blob.startsWith(METADATA_PREFIX)) {</b>
<b class="nc"><i>576</i>&nbsp;                        foundUUID = blob.substring(METADATA_PREFIX.length(), blob.length() - &quot;.dat&quot;.length());</b>
<b class="nc"><i>577</i>&nbsp;                        assert globalMetaDataFormat.blobName(foundUUID).equals(blob);</b>
<i>578</i>&nbsp;                    } else {
<b class="nc"><i>579</i>&nbsp;                        return false;</b>
<i>580</i>&nbsp;                    }
<b class="nc"><i>581</i>&nbsp;                    return allSnapshotIds.contains(foundUUID) == false;</b>
<i>582</i>&nbsp;                }
<b class="nc"><i>583</i>&nbsp;                return false;</b>
<i>584</i>&nbsp;            }
<b class="nc"><i>585</i>&nbsp;        ).collect(Collectors.toList());</b>
<i>586</i>&nbsp;    }
<i>587</i>&nbsp;
<i>588</i>&nbsp;    private List&lt;String&gt; cleanupStaleRootFiles(List&lt;String&gt; blobsToDelete) {
<b class="nc"><i>589</i>&nbsp;        if (blobsToDelete.isEmpty()) {</b>
<b class="nc"><i>590</i>&nbsp;            return blobsToDelete;</b>
<i>591</i>&nbsp;        }
<i>592</i>&nbsp;        try {
<b class="nc"><i>593</i>&nbsp;            logger.info(&quot;[{}] Found stale root level blobs {}. Cleaning them up&quot;, metadata.name(), blobsToDelete);</b>
<b class="nc"><i>594</i>&nbsp;            blobContainer().deleteBlobsIgnoringIfNotExists(blobsToDelete);</b>
<b class="nc"><i>595</i>&nbsp;            return blobsToDelete;</b>
<b class="nc"><i>596</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i>597</i>&nbsp;            logger.warn(() -&gt; new ParameterizedMessage(</b>
<i>598</i>&nbsp;                &quot;[{}] The following blobs are no longer part of any snapshot [{}] but failed to remove them&quot;,
<b class="nc"><i>599</i>&nbsp;                metadata.name(), blobsToDelete), e);</b>
<b class="nc"><i>600</i>&nbsp;        } catch (Exception e) {</b>
<i>601</i>&nbsp;            // TODO: We shouldn&#39;t be blanket catching and suppressing all exceptions here and instead handle them safely upstream.
<i>602</i>&nbsp;            //       Currently this catch exists as a stop gap solution to tackle unexpected runtime exceptions from implementations
<i>603</i>&nbsp;            //       bubbling up and breaking the snapshot functionality.
<b class="nc"><i>604</i>&nbsp;            assert false : e;</b>
<b class="nc"><i>605</i>&nbsp;            logger.warn(new ParameterizedMessage(&quot;[{}] Exception during cleanup of root level blobs&quot;, metadata.name()), e);</b>
<b class="nc"><i>606</i>&nbsp;        }</b>
<b class="nc"><i>607</i>&nbsp;        return Collections.emptyList();</b>
<i>608</i>&nbsp;    }
<i>609</i>&nbsp;
<i>610</i>&nbsp;    private DeleteResult cleanupStaleIndices(Map&lt;String, BlobContainer&gt; foundIndices, Set&lt;String&gt; survivingIndexIds) {
<b class="nc"><i>611</i>&nbsp;        DeleteResult deleteResult = DeleteResult.ZERO;</b>
<i>612</i>&nbsp;        try {
<b class="nc"><i>613</i>&nbsp;            for (Map.Entry&lt;String, BlobContainer&gt; indexEntry : foundIndices.entrySet()) {</b>
<b class="nc"><i>614</i>&nbsp;                final String indexSnId = indexEntry.getKey();</b>
<i>615</i>&nbsp;                try {
<b class="nc"><i>616</i>&nbsp;                    if (survivingIndexIds.contains(indexSnId) == false) {</b>
<b class="nc"><i>617</i>&nbsp;                        logger.debug(&quot;[{}] Found stale index [{}]. Cleaning it up&quot;, metadata.name(), indexSnId);</b>
<b class="nc"><i>618</i>&nbsp;                        deleteResult = deleteResult.add(indexEntry.getValue().delete());</b>
<b class="nc"><i>619</i>&nbsp;                        logger.debug(&quot;[{}] Cleaned up stale index [{}]&quot;, metadata.name(), indexSnId);</b>
<i>620</i>&nbsp;                    }
<b class="nc"><i>621</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>622</i>&nbsp;                    logger.warn(() -&gt; new ParameterizedMessage(</b>
<i>623</i>&nbsp;                        &quot;[{}] index {} is no longer part of any snapshots in the repository, &quot; +
<b class="nc"><i>624</i>&nbsp;                            &quot;but failed to clean up their index folders&quot;, metadata.name(), indexSnId), e);</b>
<b class="nc"><i>625</i>&nbsp;                }</b>
<b class="nc"><i>626</i>&nbsp;            }</b>
<b class="nc"><i>627</i>&nbsp;        } catch (Exception e) {</b>
<i>628</i>&nbsp;            // TODO: We shouldn&#39;t be blanket catching and suppressing all exceptions here and instead handle them safely upstream.
<i>629</i>&nbsp;            //       Currently this catch exists as a stop gap solution to tackle unexpected runtime exceptions from implementations
<i>630</i>&nbsp;            //       bubbling up and breaking the snapshot functionality.
<b class="nc"><i>631</i>&nbsp;            assert false : e;</b>
<b class="nc"><i>632</i>&nbsp;            logger.warn(new ParameterizedMessage(&quot;[{}] Exception during cleanup of stale indices&quot;, metadata.name()), e);</b>
<b class="nc"><i>633</i>&nbsp;        }</b>
<b class="nc"><i>634</i>&nbsp;        return deleteResult;</b>
<i>635</i>&nbsp;    }
<i>636</i>&nbsp;
<i>637</i>&nbsp;    /**
<i>638</i>&nbsp;     * @param repositoryData RepositoryData with the snapshot removed
<i>639</i>&nbsp;     * @param indices        Indices to remove the snapshot from (should not contain indices that become completely unreferenced with the
<i>640</i>&nbsp;     *                       removal of this snapshot as those are cleaned up afterwards by {@link #cleanupStaleBlobs})
<i>641</i>&nbsp;     * @param snapshotId     SnapshotId to remove from all the given indices
<i>642</i>&nbsp;     * @param listener       Listener to invoke when finished
<i>643</i>&nbsp;     */
<i>644</i>&nbsp;    private void deleteIndices(RepositoryData repositoryData, List&lt;IndexId&gt; indices, SnapshotId snapshotId,
<i>645</i>&nbsp;                               ActionListener&lt;Collection&lt;ShardSnapshotMetaDeleteResult&gt;&gt; listener) {
<i>646</i>&nbsp;
<b class="nc"><i>647</i>&nbsp;        if (indices.isEmpty()) {</b>
<b class="nc"><i>648</i>&nbsp;            listener.onResponse(Collections.emptyList());</b>
<b class="nc"><i>649</i>&nbsp;            return;</b>
<i>650</i>&nbsp;        }
<i>651</i>&nbsp;
<i>652</i>&nbsp;        // Listener that flattens out the delete results for each index
<b class="nc"><i>653</i>&nbsp;        final ActionListener&lt;Collection&lt;ShardSnapshotMetaDeleteResult&gt;&gt; deleteIndexMetaDataListener = new GroupedActionListener&lt;&gt;(</b>
<b class="nc"><i>654</i>&nbsp;            ActionListener.map(listener, res -&gt; res.stream().flatMap(Collection::stream).collect(Collectors.toList())), indices.size());</b>
<b class="nc"><i>655</i>&nbsp;        final Executor executor = threadPool.executor(ThreadPool.Names.SNAPSHOT);</b>
<b class="nc"><i>656</i>&nbsp;        for (IndexId indexId : indices) {</b>
<b class="nc"><i>657</i>&nbsp;            executor.execute(ActionRunnable.wrap(deleteIndexMetaDataListener,</b>
<i>658</i>&nbsp;                deleteIdxMetaListener -&gt; {
<i>659</i>&nbsp;                    final IndexMetaData indexMetaData;
<i>660</i>&nbsp;                    try {
<b class="nc"><i>661</i>&nbsp;                        indexMetaData = getSnapshotIndexMetaData(snapshotId, indexId);</b>
<b class="nc"><i>662</i>&nbsp;                    } catch (Exception ex) {</b>
<b class="nc"><i>663</i>&nbsp;                        logger.warn(() -&gt;</b>
<b class="nc"><i>664</i>&nbsp;                            new ParameterizedMessage(&quot;[{}] [{}] failed to read metadata for index&quot;, snapshotId, indexId.getName()), ex);</b>
<i>665</i>&nbsp;                        // Just invoke the listener without any shard generations to count it down, this index will be cleaned up
<i>666</i>&nbsp;                        // by the stale data cleanup in the end.
<b class="nc"><i>667</i>&nbsp;                        deleteIdxMetaListener.onResponse(null);</b>
<b class="nc"><i>668</i>&nbsp;                        return;</b>
<b class="nc"><i>669</i>&nbsp;                    }</b>
<b class="nc"><i>670</i>&nbsp;                    final int shardCount = indexMetaData.getNumberOfShards();</b>
<b class="nc"><i>671</i>&nbsp;                    assert shardCount &gt; 0 : &quot;index did not have positive shard count, get [&quot; + shardCount + &quot;]&quot;;</b>
<i>672</i>&nbsp;                    // Listener for collecting the results of removing the snapshot from each shard&#39;s metadata in the current index
<b class="nc"><i>673</i>&nbsp;                    final ActionListener&lt;ShardSnapshotMetaDeleteResult&gt; allShardsListener =</b>
<i>674</i>&nbsp;                        new GroupedActionListener&lt;&gt;(deleteIdxMetaListener, shardCount);
<b class="nc"><i>675</i>&nbsp;                    final Index index = indexMetaData.getIndex();</b>
<b class="nc"><i>676</i>&nbsp;                    for (int shardId = 0; shardId &lt; indexMetaData.getNumberOfShards(); shardId++) {</b>
<b class="nc"><i>677</i>&nbsp;                        final ShardId shard = new ShardId(index, shardId);</b>
<b class="nc"><i>678</i>&nbsp;                        executor.execute(new AbstractRunnable() {</b>
<i>679</i>&nbsp;                            @Override
<i>680</i>&nbsp;                            protected void doRun() throws Exception {
<i>681</i>&nbsp;                                allShardsListener.onResponse(
<i>682</i>&nbsp;                                    deleteShardSnapshot(repositoryData, indexId, shard, snapshotId));
<i>683</i>&nbsp;                            }
<i>684</i>&nbsp;
<i>685</i>&nbsp;                            @Override
<i>686</i>&nbsp;                            public void onFailure(Exception ex) {
<i>687</i>&nbsp;                                logger.warn(() -&gt; new ParameterizedMessage(&quot;[{}] failed to delete shard data for shard [{}][{}]&quot;,
<i>688</i>&nbsp;                                    snapshotId, indexId.getName(), shard.id()), ex);
<i>689</i>&nbsp;                                // Just passing null here to count down the listener instead of failing it, the stale data left behind
<i>690</i>&nbsp;                                // here will be retried in the next delete or repository cleanup
<i>691</i>&nbsp;                                allShardsListener.onResponse(null);
<i>692</i>&nbsp;                            }
<i>693</i>&nbsp;                        });
<i>694</i>&nbsp;                    }
<b class="nc"><i>695</i>&nbsp;                }));</b>
<b class="nc"><i>696</i>&nbsp;        }</b>
<b class="nc"><i>697</i>&nbsp;    }</b>
<i>698</i>&nbsp;
<i>699</i>&nbsp;    @Override
<i>700</i>&nbsp;    public void finalizeSnapshot(final SnapshotId snapshotId,
<i>701</i>&nbsp;                                 final List&lt;IndexId&gt; indices,
<i>702</i>&nbsp;                                 final long startTime,
<i>703</i>&nbsp;                                 final String failure,
<i>704</i>&nbsp;                                 final int totalShards,
<i>705</i>&nbsp;                                 final List&lt;SnapshotShardFailure&gt; shardFailures,
<i>706</i>&nbsp;                                 final long repositoryStateId,
<i>707</i>&nbsp;                                 final boolean includeGlobalState,
<i>708</i>&nbsp;                                 final MetaData clusterMetaData,
<i>709</i>&nbsp;                                 final Map&lt;String, Object&gt; userMetadata,
<i>710</i>&nbsp;                                 final ActionListener&lt;SnapshotInfo&gt; listener) {
<i>711</i>&nbsp;
<i>712</i>&nbsp;        // We upload one meta blob for each index, one for the cluster-state and one snap-${uuid}.dat blob
<i>713</i>&nbsp;        // Once we&#39;re done writing all metadata, we update the index-N blob to finalize the snapshot
<b class="nc"><i>714</i>&nbsp;        final ActionListener&lt;SnapshotInfo&gt; allMetaListener = new GroupedActionListener&lt;&gt;(</b>
<b class="nc"><i>715</i>&nbsp;            ActionListener.wrap(snapshotInfos -&gt; {</b>
<b class="nc"><i>716</i>&nbsp;                    assert snapshotInfos.size() == 1 : &quot;Should have only received a single SnapshotInfo but received &quot; + snapshotInfos;</b>
<b class="nc"><i>717</i>&nbsp;                    final SnapshotInfo snapshotInfo = snapshotInfos.iterator().next();</b>
<b class="nc"><i>718</i>&nbsp;                    writeIndexGen(getRepositoryData().addSnapshot(snapshotId, snapshotInfo.state(), indices), repositoryStateId);</b>
<b class="nc"><i>719</i>&nbsp;                    listener.onResponse(snapshotInfo);</b>
<b class="nc"><i>720</i>&nbsp;                },</b>
<b class="nc"><i>721</i>&nbsp;                e -&gt; listener.onFailure(new SnapshotException(metadata.name(), snapshotId, &quot;failed to update snapshot in repository&quot;, e))),</b>
<b class="nc"><i>722</i>&nbsp;            2 + indices.size());</b>
<b class="nc"><i>723</i>&nbsp;        final Executor executor = threadPool.executor(ThreadPool.Names.SNAPSHOT);</b>
<i>724</i>&nbsp;
<i>725</i>&nbsp;        // We ignore all FileAlreadyExistsException when writing metadata since otherwise a master failover while in this method will
<i>726</i>&nbsp;        // mean that no snap-${uuid}.dat blob is ever written for this snapshot. This is safe because any updated version of the
<i>727</i>&nbsp;        // index or global metadata will be compatible with the segments written in this snapshot as well.
<i>728</i>&nbsp;        // Failing on an already existing index-${repoGeneration} below ensures that the index.latest blob is not updated in a way
<i>729</i>&nbsp;        // that decrements the generation it points at
<i>730</i>&nbsp;
<i>731</i>&nbsp;        // Write Global MetaData
<b class="nc"><i>732</i>&nbsp;        executor.execute(ActionRunnable.run(allMetaListener,</b>
<b class="nc"><i>733</i>&nbsp;            () -&gt; globalMetaDataFormat.write(clusterMetaData, blobContainer(), snapshotId.getUUID(), false)));</b>
<i>734</i>&nbsp;
<i>735</i>&nbsp;        // write the index metadata for each index in the snapshot
<b class="nc"><i>736</i>&nbsp;        for (IndexId index : indices) {</b>
<b class="nc"><i>737</i>&nbsp;            executor.execute(ActionRunnable.run(allMetaListener, () -&gt;</b>
<b class="nc"><i>738</i>&nbsp;                indexMetaDataFormat.write(clusterMetaData.index(index.getName()), indexContainer(index), snapshotId.getUUID(), false)));</b>
<b class="nc"><i>739</i>&nbsp;        }</b>
<i>740</i>&nbsp;
<b class="nc"><i>741</i>&nbsp;        executor.execute(ActionRunnable.supply(allMetaListener, () -&gt; {</b>
<b class="nc"><i>742</i>&nbsp;            final SnapshotInfo snapshotInfo = new SnapshotInfo(snapshotId,</b>
<b class="nc"><i>743</i>&nbsp;                indices.stream().map(IndexId::getName).collect(Collectors.toList()),</b>
<b class="nc"><i>744</i>&nbsp;                startTime, failure, threadPool.absoluteTimeInMillis(), totalShards, shardFailures,</b>
<b class="nc"><i>745</i>&nbsp;                includeGlobalState, userMetadata);</b>
<b class="nc"><i>746</i>&nbsp;            snapshotFormat.write(snapshotInfo, blobContainer(), snapshotId.getUUID(), false);</b>
<b class="nc"><i>747</i>&nbsp;            return snapshotInfo;</b>
<i>748</i>&nbsp;        }));
<b class="nc"><i>749</i>&nbsp;    }</b>
<i>750</i>&nbsp;
<i>751</i>&nbsp;    @Override
<i>752</i>&nbsp;    public SnapshotInfo getSnapshotInfo(final SnapshotId snapshotId) {
<i>753</i>&nbsp;        try {
<b class="nc"><i>754</i>&nbsp;            return snapshotFormat.read(blobContainer(), snapshotId.getUUID());</b>
<b class="nc"><i>755</i>&nbsp;        } catch (NoSuchFileException ex) {</b>
<b class="nc"><i>756</i>&nbsp;            throw new SnapshotMissingException(metadata.name(), snapshotId, ex);</b>
<b class="nc"><i>757</i>&nbsp;        } catch (IOException | NotXContentException ex) {</b>
<b class="nc"><i>758</i>&nbsp;            throw new SnapshotException(metadata.name(), snapshotId, &quot;failed to get snapshots&quot;, ex);</b>
<i>759</i>&nbsp;        }
<i>760</i>&nbsp;    }
<i>761</i>&nbsp;
<i>762</i>&nbsp;    @Override
<i>763</i>&nbsp;    public MetaData getSnapshotGlobalMetaData(final SnapshotId snapshotId) {
<i>764</i>&nbsp;        try {
<b class="nc"><i>765</i>&nbsp;            return globalMetaDataFormat.read(blobContainer(), snapshotId.getUUID());</b>
<b class="nc"><i>766</i>&nbsp;        } catch (NoSuchFileException ex) {</b>
<b class="nc"><i>767</i>&nbsp;            throw new SnapshotMissingException(metadata.name(), snapshotId, ex);</b>
<b class="nc"><i>768</i>&nbsp;        } catch (IOException ex) {</b>
<b class="nc"><i>769</i>&nbsp;            throw new SnapshotException(metadata.name(), snapshotId, &quot;failed to read global metadata&quot;, ex);</b>
<i>770</i>&nbsp;        }
<i>771</i>&nbsp;    }
<i>772</i>&nbsp;
<i>773</i>&nbsp;    @Override
<i>774</i>&nbsp;    public IndexMetaData getSnapshotIndexMetaData(final SnapshotId snapshotId, final IndexId index) throws IOException {
<i>775</i>&nbsp;        try {
<b class="nc"><i>776</i>&nbsp;            return indexMetaDataFormat.read(indexContainer(index), snapshotId.getUUID());</b>
<b class="nc"><i>777</i>&nbsp;        } catch (NoSuchFileException e) {</b>
<b class="nc"><i>778</i>&nbsp;            throw new SnapshotMissingException(metadata.name(), snapshotId, e);</b>
<i>779</i>&nbsp;        }
<i>780</i>&nbsp;    }
<i>781</i>&nbsp;
<i>782</i>&nbsp;    private BlobPath indicesPath() {
<b class="nc"><i>783</i>&nbsp;        return basePath().add(&quot;indices&quot;);</b>
<i>784</i>&nbsp;    }
<i>785</i>&nbsp;
<i>786</i>&nbsp;    private BlobContainer indexContainer(IndexId indexId) {
<b class="nc"><i>787</i>&nbsp;        return blobStore().blobContainer(indicesPath().add(indexId.getId()));</b>
<i>788</i>&nbsp;    }
<i>789</i>&nbsp;
<i>790</i>&nbsp;    private BlobContainer shardContainer(IndexId indexId, ShardId shardId) {
<b class="nc"><i>791</i>&nbsp;        return shardContainer(indexId, shardId.getId());</b>
<i>792</i>&nbsp;    }
<i>793</i>&nbsp;
<i>794</i>&nbsp;    private BlobContainer shardContainer(IndexId indexId, int shardId) {
<b class="nc"><i>795</i>&nbsp;        return blobStore().blobContainer(indicesPath().add(indexId.getId()).add(Integer.toString(shardId)));</b>
<i>796</i>&nbsp;    }
<i>797</i>&nbsp;
<i>798</i>&nbsp;    /**
<i>799</i>&nbsp;     * Configures RateLimiter based on repository and global settings
<i>800</i>&nbsp;     *
<i>801</i>&nbsp;     * @param repositorySettings repository settings
<i>802</i>&nbsp;     * @param setting            setting to use to configure rate limiter
<i>803</i>&nbsp;     * @param defaultRate        default limiting rate
<i>804</i>&nbsp;     * @return rate limiter or null of no throttling is needed
<i>805</i>&nbsp;     */
<i>806</i>&nbsp;    private RateLimiter getRateLimiter(Settings repositorySettings, String setting, ByteSizeValue defaultRate) {
<b class="nc"><i>807</i>&nbsp;        ByteSizeValue maxSnapshotBytesPerSec = repositorySettings.getAsBytesSize(setting, defaultRate);</b>
<b class="nc"><i>808</i>&nbsp;        if (maxSnapshotBytesPerSec.getBytes() &lt;= 0) {</b>
<b class="nc"><i>809</i>&nbsp;            return null;</b>
<i>810</i>&nbsp;        } else {
<b class="nc"><i>811</i>&nbsp;            return new RateLimiter.SimpleRateLimiter(maxSnapshotBytesPerSec.getMbFrac());</b>
<i>812</i>&nbsp;        }
<i>813</i>&nbsp;    }
<i>814</i>&nbsp;
<i>815</i>&nbsp;    @Override
<i>816</i>&nbsp;    public long getSnapshotThrottleTimeInNanos() {
<b class="nc"><i>817</i>&nbsp;        return snapshotRateLimitingTimeInNanos.count();</b>
<i>818</i>&nbsp;    }
<i>819</i>&nbsp;
<i>820</i>&nbsp;    @Override
<i>821</i>&nbsp;    public long getRestoreThrottleTimeInNanos() {
<b class="nc"><i>822</i>&nbsp;        return restoreRateLimitingTimeInNanos.count();</b>
<i>823</i>&nbsp;    }
<i>824</i>&nbsp;
<i>825</i>&nbsp;    protected void assertSnapshotOrGenericThread() {
<b class="nc"><i>826</i>&nbsp;        assert Thread.currentThread().getName().contains(ThreadPool.Names.SNAPSHOT)</b>
<b class="nc"><i>827</i>&nbsp;            || Thread.currentThread().getName().contains(ThreadPool.Names.GENERIC) :</b>
<b class="nc"><i>828</i>&nbsp;            &quot;Expected current thread [&quot; + Thread.currentThread() + &quot;] to be the snapshot or generic thread.&quot;;</b>
<b class="nc"><i>829</i>&nbsp;    }</b>
<i>830</i>&nbsp;
<i>831</i>&nbsp;    @Override
<i>832</i>&nbsp;    public String startVerification() {
<i>833</i>&nbsp;        try {
<b class="nc"><i>834</i>&nbsp;            if (isReadOnly()) {</b>
<i>835</i>&nbsp;                // It&#39;s readonly - so there is not much we can do here to verify it apart from reading the blob store metadata
<b class="nc"><i>836</i>&nbsp;                latestIndexBlobId();</b>
<b class="nc"><i>837</i>&nbsp;                return &quot;read-only&quot;;</b>
<i>838</i>&nbsp;            } else {
<b class="nc"><i>839</i>&nbsp;                String seed = UUIDs.randomBase64UUID();</b>
<b class="nc"><i>840</i>&nbsp;                byte[] testBytes = Strings.toUTF8Bytes(seed);</b>
<b class="nc"><i>841</i>&nbsp;                BlobContainer testContainer = blobStore().blobContainer(basePath().add(testBlobPrefix(seed)));</b>
<b class="nc"><i>842</i>&nbsp;                BytesArray bytes = new BytesArray(testBytes);</b>
<b class="nc"><i>843</i>&nbsp;                try (InputStream stream = bytes.streamInput()) {</b>
<b class="nc"><i>844</i>&nbsp;                    testContainer.writeBlobAtomic(&quot;master.dat&quot;, stream, bytes.length(), true);</b>
<b class="nc"><i>845</i>&nbsp;                }</b>
<b class="nc"><i>846</i>&nbsp;                return seed;</b>
<i>847</i>&nbsp;            }
<b class="nc"><i>848</i>&nbsp;        } catch (IOException exp) {</b>
<b class="nc"><i>849</i>&nbsp;            throw new RepositoryVerificationException(metadata.name(), &quot;path &quot; + basePath() + &quot; is not accessible on master node&quot;, exp);</b>
<i>850</i>&nbsp;        }
<i>851</i>&nbsp;    }
<i>852</i>&nbsp;
<i>853</i>&nbsp;    @Override
<i>854</i>&nbsp;    public void endVerification(String seed) {
<b class="nc"><i>855</i>&nbsp;        if (isReadOnly() == false) {</b>
<i>856</i>&nbsp;            try {
<b class="nc"><i>857</i>&nbsp;                final String testPrefix = testBlobPrefix(seed);</b>
<b class="nc"><i>858</i>&nbsp;                final BlobContainer container = blobStore().blobContainer(basePath().add(testPrefix));</b>
<b class="nc"><i>859</i>&nbsp;                container.deleteBlobsIgnoringIfNotExists(new ArrayList&lt;&gt;(container.listBlobs().keySet()));</b>
<b class="nc"><i>860</i>&nbsp;                blobStore().blobContainer(basePath()).deleteBlobIgnoringIfNotExists(testPrefix);</b>
<b class="nc"><i>861</i>&nbsp;            } catch (IOException exp) {</b>
<b class="nc"><i>862</i>&nbsp;                throw new RepositoryVerificationException(metadata.name(), &quot;cannot delete test data at &quot; + basePath(), exp);</b>
<b class="nc"><i>863</i>&nbsp;            }</b>
<i>864</i>&nbsp;        }
<b class="nc"><i>865</i>&nbsp;    }</b>
<i>866</i>&nbsp;
<i>867</i>&nbsp;    // Tracks the latest known repository generation in a best-effort way to detect inconsistent listing of root level index-N blobs
<i>868</i>&nbsp;    // and concurrent modifications.
<i>869</i>&nbsp;    // Protected for use in MockEventuallyConsistentRepository
<b class="nc"><i>870</i>&nbsp;    protected final AtomicLong latestKnownRepoGen = new AtomicLong(RepositoryData.EMPTY_REPO_GEN);</b>
<i>871</i>&nbsp;
<i>872</i>&nbsp;    @Override
<i>873</i>&nbsp;    public RepositoryData getRepositoryData() {
<i>874</i>&nbsp;        // Retry loading RepositoryData in a loop in case we run into concurrent modifications of the repository.
<i>875</i>&nbsp;        while (true) {
<i>876</i>&nbsp;            final long generation;
<i>877</i>&nbsp;            try {
<b class="nc"><i>878</i>&nbsp;                generation = latestIndexBlobId();</b>
<b class="nc"><i>879</i>&nbsp;            } catch (IOException ioe) {</b>
<b class="nc"><i>880</i>&nbsp;                throw new RepositoryException(metadata.name(), &quot;Could not determine repository generation from root blobs&quot;, ioe);</b>
<b class="nc"><i>881</i>&nbsp;            }</b>
<b class="nc"><i>882</i>&nbsp;            final long genToLoad = latestKnownRepoGen.updateAndGet(known -&gt; Math.max(known, generation));</b>
<b class="nc"><i>883</i>&nbsp;            if (genToLoad &gt; generation) {</b>
<b class="nc"><i>884</i>&nbsp;                logger.info(&quot;Determined repository generation [&quot; + generation</b>
<i>885</i>&nbsp;                    + &quot;] from repository contents but correct generation must be at least [&quot; + genToLoad + &quot;]&quot;);
<i>886</i>&nbsp;            }
<i>887</i>&nbsp;            try {
<b class="nc"><i>888</i>&nbsp;                return getRepositoryData(genToLoad);</b>
<b class="nc"><i>889</i>&nbsp;            } catch (RepositoryException e) {</b>
<b class="nc"><i>890</i>&nbsp;                if (genToLoad != latestKnownRepoGen.get()) {</b>
<b class="nc"><i>891</i>&nbsp;                    logger.warn(&quot;Failed to load repository data generation [&quot; + genToLoad +</b>
<b class="nc"><i>892</i>&nbsp;                        &quot;] because a concurrent operation moved the current generation to [&quot; + latestKnownRepoGen.get() + &quot;]&quot;, e);</b>
<b class="nc"><i>893</i>&nbsp;                    continue;</b>
<i>894</i>&nbsp;                }
<b class="nc"><i>895</i>&nbsp;                throw e;</b>
<i>896</i>&nbsp;            }
<i>897</i>&nbsp;        }
<i>898</i>&nbsp;    }
<i>899</i>&nbsp;
<i>900</i>&nbsp;    private RepositoryData getRepositoryData(long indexGen) {
<b class="nc"><i>901</i>&nbsp;        if (indexGen == RepositoryData.EMPTY_REPO_GEN) {</b>
<b class="nc"><i>902</i>&nbsp;            return RepositoryData.EMPTY;</b>
<i>903</i>&nbsp;        }
<i>904</i>&nbsp;        try {
<b class="nc"><i>905</i>&nbsp;            final String snapshotsIndexBlobName = INDEX_FILE_PREFIX + Long.toString(indexGen);</b>
<i>906</i>&nbsp;
<i>907</i>&nbsp;            // EMPTY is safe here because RepositoryData#fromXContent calls namedObject
<b class="nc"><i>908</i>&nbsp;            try (InputStream blob = blobContainer().readBlob(snapshotsIndexBlobName);</b>
<b class="nc"><i>909</i>&nbsp;                 XContentParser parser = XContentType.JSON.xContent().createParser(NamedXContentRegistry.EMPTY,</b>
<i>910</i>&nbsp;                     LoggingDeprecationHandler.INSTANCE, blob)) {
<b class="nc"><i>911</i>&nbsp;                return RepositoryData.snapshotsFromXContent(parser, indexGen);</b>
<b class="nc"><i>912</i>&nbsp;            }</b>
<b class="nc"><i>913</i>&nbsp;        } catch (IOException ioe) {</b>
<i>914</i>&nbsp;            // If we fail to load the generation we tracked in latestKnownRepoGen we reset it.
<i>915</i>&nbsp;            // This is done as a fail-safe in case a user manually deletes the contents of the repository in which case subsequent
<i>916</i>&nbsp;            // operations must start from the EMPTY_REPO_GEN again
<b class="nc"><i>917</i>&nbsp;            if (latestKnownRepoGen.compareAndSet(indexGen, RepositoryData.EMPTY_REPO_GEN)) {</b>
<b class="nc"><i>918</i>&nbsp;                logger.warn(&quot;Resetting repository generation tracker because we failed to read generation [&quot; + indexGen + &quot;]&quot;, ioe);</b>
<i>919</i>&nbsp;            }
<b class="nc"><i>920</i>&nbsp;            throw new RepositoryException(metadata.name(), &quot;could not read repository data from index blob&quot;, ioe);</b>
<i>921</i>&nbsp;        }
<i>922</i>&nbsp;    }
<i>923</i>&nbsp;
<i>924</i>&nbsp;    private static String testBlobPrefix(String seed) {
<b class="nc"><i>925</i>&nbsp;        return TESTS_FILE + seed;</b>
<i>926</i>&nbsp;    }
<i>927</i>&nbsp;
<i>928</i>&nbsp;    @Override
<i>929</i>&nbsp;    public boolean isReadOnly() {
<b class="nc"><i>930</i>&nbsp;        return readOnly;</b>
<i>931</i>&nbsp;    }
<i>932</i>&nbsp;
<i>933</i>&nbsp;    protected void writeIndexGen(final RepositoryData repositoryData, final long expectedGen) throws IOException {
<b class="nc"><i>934</i>&nbsp;        assert isReadOnly() == false; // can not write to a read only repository</b>
<b class="nc"><i>935</i>&nbsp;        final long currentGen = repositoryData.getGenId();</b>
<b class="nc"><i>936</i>&nbsp;        if (currentGen != expectedGen) {</b>
<i>937</i>&nbsp;            // the index file was updated by a concurrent operation, so we were operating on stale
<i>938</i>&nbsp;            // repository data
<b class="nc"><i>939</i>&nbsp;            throw new RepositoryException(metadata.name(), &quot;concurrent modification of the index-N file, expected current generation [&quot; +</b>
<i>940</i>&nbsp;                                              expectedGen + &quot;], actual current generation [&quot; + currentGen +
<i>941</i>&nbsp;                                              &quot;] - possibly due to simultaneous snapshot deletion requests&quot;);
<i>942</i>&nbsp;        }
<b class="nc"><i>943</i>&nbsp;        final long newGen = currentGen + 1;</b>
<b class="nc"><i>944</i>&nbsp;        if (latestKnownRepoGen.get() &gt;= newGen) {</b>
<b class="nc"><i>945</i>&nbsp;            throw new IllegalArgumentException(</b>
<i>946</i>&nbsp;                &quot;Tried writing generation [&quot; + newGen + &quot;] but repository is at least at generation [&quot; + newGen + &quot;] already&quot;);
<i>947</i>&nbsp;        }
<i>948</i>&nbsp;        // write the index file
<b class="nc"><i>949</i>&nbsp;        final String indexBlob = INDEX_FILE_PREFIX + Long.toString(newGen);</b>
<b class="nc"><i>950</i>&nbsp;        logger.debug(&quot;Repository [{}] writing new index generational blob [{}]&quot;, metadata.name(), indexBlob);</b>
<b class="nc"><i>951</i>&nbsp;        writeAtomic(indexBlob,</b>
<b class="nc"><i>952</i>&nbsp;            BytesReference.bytes(repositoryData.snapshotsToXContent(XContentFactory.jsonBuilder())), true);</b>
<b class="nc"><i>953</i>&nbsp;        final long latestKnownGen = latestKnownRepoGen.updateAndGet(known -&gt; Math.max(known, newGen));</b>
<b class="nc"><i>954</i>&nbsp;        if (newGen &lt; latestKnownGen) {</b>
<i>955</i>&nbsp;            // Don&#39;t mess up the index.latest blob
<b class="nc"><i>956</i>&nbsp;            throw new IllegalStateException(</b>
<i>957</i>&nbsp;                &quot;Wrote generation [&quot; + newGen + &quot;] but latest known repo gen concurrently changed to [&quot; + latestKnownGen + &quot;]&quot;);
<i>958</i>&nbsp;        }
<i>959</i>&nbsp;        // write the current generation to the index-latest file
<i>960</i>&nbsp;        final BytesReference genBytes;
<b class="nc"><i>961</i>&nbsp;        try (BytesStreamOutput bStream = new BytesStreamOutput()) {</b>
<b class="nc"><i>962</i>&nbsp;            bStream.writeLong(newGen);</b>
<b class="nc"><i>963</i>&nbsp;            genBytes = bStream.bytes();</b>
<b class="nc"><i>964</i>&nbsp;        }</b>
<b class="nc"><i>965</i>&nbsp;        logger.debug(&quot;Repository [{}] updating index.latest with generation [{}]&quot;, metadata.name(), newGen);</b>
<b class="nc"><i>966</i>&nbsp;        writeAtomic(INDEX_LATEST_BLOB, genBytes, false);</b>
<i>967</i>&nbsp;        // delete the N-2 index file if it exists, keep the previous one around as a backup
<b class="nc"><i>968</i>&nbsp;        if (newGen - 2 &gt;= 0) {</b>
<b class="nc"><i>969</i>&nbsp;            final String oldSnapshotIndexFile = INDEX_FILE_PREFIX + Long.toString(newGen - 2);</b>
<i>970</i>&nbsp;            try {
<b class="nc"><i>971</i>&nbsp;                blobContainer().deleteBlobIgnoringIfNotExists(oldSnapshotIndexFile);</b>
<b class="nc"><i>972</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i>973</i>&nbsp;                logger.warn(&quot;Failed to clean up old index blob [{}]&quot;, oldSnapshotIndexFile);</b>
<b class="nc"><i>974</i>&nbsp;            }</b>
<i>975</i>&nbsp;        }
<b class="nc"><i>976</i>&nbsp;    }</b>
<i>977</i>&nbsp;
<i>978</i>&nbsp;    /**
<i>979</i>&nbsp;     * Get the latest snapshot index blob id.  Snapshot index blobs are named index-N, where N is
<i>980</i>&nbsp;     * the next version number from when the index blob was written.  Each individual index-N blob is
<i>981</i>&nbsp;     * only written once and never overwritten.  The highest numbered index-N blob is the latest one
<i>982</i>&nbsp;     * that contains the current snapshots in the repository.
<i>983</i>&nbsp;     *
<i>984</i>&nbsp;     * Package private for testing
<i>985</i>&nbsp;     */
<i>986</i>&nbsp;    long latestIndexBlobId() throws IOException {
<i>987</i>&nbsp;        try {
<i>988</i>&nbsp;            // First, try listing all index-N blobs (there should only be two index-N blobs at any given
<i>989</i>&nbsp;            // time in a repository if cleanup is happening properly) and pick the index-N blob with the
<i>990</i>&nbsp;            // highest N value - this will be the latest index blob for the repository.  Note, we do this
<i>991</i>&nbsp;            // instead of directly reading the index.latest blob to get the current index-N blob because
<i>992</i>&nbsp;            // index.latest is not written atomically and is not immutable - on every index-N change,
<i>993</i>&nbsp;            // we first delete the old index.latest and then write the new one.  If the repository is not
<i>994</i>&nbsp;            // read-only, it is possible that we try deleting the index.latest blob while it is being read
<i>995</i>&nbsp;            // by some other operation (such as the get snapshots operation).  In some file systems, it is
<i>996</i>&nbsp;            // illegal to delete a file while it is being read elsewhere (e.g. Windows).  For read-only
<i>997</i>&nbsp;            // repositories, we read for index.latest, both because listing blob prefixes is often unsupported
<i>998</i>&nbsp;            // and because the index.latest blob will never be deleted and re-written.
<b class="nc"><i>999</i>&nbsp;            return listBlobsToGetLatestIndexId();</b>
<b class="nc"><i>1000</i>&nbsp;        } catch (UnsupportedOperationException e) {</b>
<i>1001</i>&nbsp;            // If its a read-only repository, listing blobs by prefix may not be supported (e.g. a URL repository),
<i>1002</i>&nbsp;            // in this case, try reading the latest index generation from the index.latest blob
<i>1003</i>&nbsp;            try {
<b class="nc"><i>1004</i>&nbsp;                return readSnapshotIndexLatestBlob();</b>
<b class="nc"><i>1005</i>&nbsp;            } catch (NoSuchFileException nsfe) {</b>
<b class="nc"><i>1006</i>&nbsp;                return RepositoryData.EMPTY_REPO_GEN;</b>
<i>1007</i>&nbsp;            }
<i>1008</i>&nbsp;        }
<i>1009</i>&nbsp;    }
<i>1010</i>&nbsp;
<i>1011</i>&nbsp;    // package private for testing
<i>1012</i>&nbsp;    long readSnapshotIndexLatestBlob() throws IOException {
<b class="nc"><i>1013</i>&nbsp;        return Numbers.bytesToLong(Streams.readFully(blobContainer().readBlob(INDEX_LATEST_BLOB)).toBytesRef());</b>
<i>1014</i>&nbsp;    }
<i>1015</i>&nbsp;
<i>1016</i>&nbsp;    private long listBlobsToGetLatestIndexId() throws IOException {
<b class="nc"><i>1017</i>&nbsp;        return latestGeneration(blobContainer().listBlobsByPrefix(INDEX_FILE_PREFIX).keySet());</b>
<i>1018</i>&nbsp;    }
<i>1019</i>&nbsp;
<i>1020</i>&nbsp;    private long latestGeneration(Collection&lt;String&gt; rootBlobs) {
<b class="nc"><i>1021</i>&nbsp;        long latest = RepositoryData.EMPTY_REPO_GEN;</b>
<b class="nc"><i>1022</i>&nbsp;        for (String blobName : rootBlobs) {</b>
<b class="nc"><i>1023</i>&nbsp;            if (blobName.startsWith(INDEX_FILE_PREFIX) == false) {</b>
<b class="nc"><i>1024</i>&nbsp;                continue;</b>
<i>1025</i>&nbsp;            }
<i>1026</i>&nbsp;            try {
<b class="nc"><i>1027</i>&nbsp;                final long curr = Long.parseLong(blobName.substring(INDEX_FILE_PREFIX.length()));</b>
<b class="nc"><i>1028</i>&nbsp;                latest = Math.max(latest, curr);</b>
<b class="nc"><i>1029</i>&nbsp;            } catch (NumberFormatException nfe) {</b>
<i>1030</i>&nbsp;                // the index- blob wasn&#39;t of the format index-N where N is a number,
<i>1031</i>&nbsp;                // no idea what this blob is but it doesn&#39;t belong in the repository!
<b class="nc"><i>1032</i>&nbsp;                logger.warn(&quot;[{}] Unknown blob in the repository: {}&quot;, metadata.name(), blobName);</b>
<b class="nc"><i>1033</i>&nbsp;            }</b>
<b class="nc"><i>1034</i>&nbsp;        }</b>
<b class="nc"><i>1035</i>&nbsp;        return latest;</b>
<i>1036</i>&nbsp;    }
<i>1037</i>&nbsp;
<i>1038</i>&nbsp;    private void writeAtomic(final String blobName, final BytesReference bytesRef, boolean failIfAlreadyExists) throws IOException {
<b class="nc"><i>1039</i>&nbsp;        try (InputStream stream = bytesRef.streamInput()) {</b>
<b class="nc"><i>1040</i>&nbsp;            blobContainer().writeBlobAtomic(blobName, stream, bytesRef.length(), failIfAlreadyExists);</b>
<b class="nc"><i>1041</i>&nbsp;        }</b>
<b class="nc"><i>1042</i>&nbsp;    }</b>
<i>1043</i>&nbsp;
<i>1044</i>&nbsp;    @Override
<i>1045</i>&nbsp;    public void snapshotShard(Store store, MapperService mapperService, SnapshotId snapshotId, IndexId indexId,
<i>1046</i>&nbsp;                              IndexCommit snapshotIndexCommit, IndexShardSnapshotStatus snapshotStatus, ActionListener&lt;Void&gt; listener) {
<b class="nc"><i>1047</i>&nbsp;        final ShardId shardId = store.shardId();</b>
<b class="nc"><i>1048</i>&nbsp;        final long startTime = threadPool.absoluteTimeInMillis();</b>
<i>1049</i>&nbsp;        try {
<b class="nc"><i>1050</i>&nbsp;            logger.debug(&quot;[{}] [{}] snapshot to [{}] ...&quot;, shardId, snapshotId, metadata.name());</b>
<i>1051</i>&nbsp;
<b class="nc"><i>1052</i>&nbsp;            final BlobContainer shardContainer = shardContainer(indexId, shardId);</b>
<i>1053</i>&nbsp;            final Map&lt;String, BlobMetaData&gt; blobs;
<i>1054</i>&nbsp;            try {
<b class="nc"><i>1055</i>&nbsp;                blobs = shardContainer.listBlobsByPrefix(INDEX_FILE_PREFIX);</b>
<b class="nc"><i>1056</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i>1057</i>&nbsp;                throw new IndexShardSnapshotFailedException(shardId, &quot;failed to list blobs&quot;, e);</b>
<b class="nc"><i>1058</i>&nbsp;            }</b>
<i>1059</i>&nbsp;
<b class="nc"><i>1060</i>&nbsp;            Tuple&lt;BlobStoreIndexShardSnapshots, Long&gt; tuple = buildBlobStoreIndexShardSnapshots(blobs.keySet(), shardContainer);</b>
<b class="nc"><i>1061</i>&nbsp;            BlobStoreIndexShardSnapshots snapshots = tuple.v1();</b>
<b class="nc"><i>1062</i>&nbsp;            long fileListGeneration = tuple.v2();</b>
<i>1063</i>&nbsp;
<b class="nc"><i>1064</i>&nbsp;            if (snapshots.snapshots().stream().anyMatch(sf -&gt; sf.snapshot().equals(snapshotId.getName()))) {</b>
<b class="nc"><i>1065</i>&nbsp;                throw new IndexShardSnapshotFailedException(shardId,</b>
<b class="nc"><i>1066</i>&nbsp;                    &quot;Duplicate snapshot name [&quot; + snapshotId.getName() + &quot;] detected, aborting&quot;);</b>
<i>1067</i>&nbsp;            }
<i>1068</i>&nbsp;
<b class="nc"><i>1069</i>&nbsp;            final List&lt;BlobStoreIndexShardSnapshot.FileInfo&gt; indexCommitPointFiles = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>1070</i>&nbsp;            ArrayList&lt;BlobStoreIndexShardSnapshot.FileInfo&gt; filesToSnapshot = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>1071</i>&nbsp;            store.incRef();</b>
<i>1072</i>&nbsp;            final Collection&lt;String&gt; fileNames;
<i>1073</i>&nbsp;            final Store.MetadataSnapshot metadataFromStore;
<i>1074</i>&nbsp;            try {
<i>1075</i>&nbsp;                // TODO apparently we don&#39;t use the MetadataSnapshot#.recoveryDiff(...) here but we should
<i>1076</i>&nbsp;                try {
<b class="nc"><i>1077</i>&nbsp;                    logger.trace(</b>
<i>1078</i>&nbsp;                        &quot;[{}] [{}] Loading store metadata using index commit [{}]&quot;, shardId, snapshotId, snapshotIndexCommit);
<b class="nc"><i>1079</i>&nbsp;                    metadataFromStore = store.getMetadata(snapshotIndexCommit);</b>
<b class="nc"><i>1080</i>&nbsp;                    fileNames = snapshotIndexCommit.getFileNames();</b>
<b class="nc"><i>1081</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>1082</i>&nbsp;                    throw new IndexShardSnapshotFailedException(shardId, &quot;Failed to get store file metadata&quot;, e);</b>
<b class="nc"><i>1083</i>&nbsp;                }</b>
<i>1084</i>&nbsp;            } finally {
<b class="nc"><i>1085</i>&nbsp;                store.decRef();</b>
<b class="nc"><i>1086</i>&nbsp;            }</b>
<b class="nc"><i>1087</i>&nbsp;            int indexIncrementalFileCount = 0;</b>
<b class="nc"><i>1088</i>&nbsp;            int indexTotalNumberOfFiles = 0;</b>
<b class="nc"><i>1089</i>&nbsp;            long indexIncrementalSize = 0;</b>
<b class="nc"><i>1090</i>&nbsp;            long indexTotalFileCount = 0;</b>
<b class="nc"><i>1091</i>&nbsp;            for (String fileName : fileNames) {</b>
<b class="nc"><i>1092</i>&nbsp;                if (snapshotStatus.isAborted()) {</b>
<b class="nc"><i>1093</i>&nbsp;                    logger.debug(&quot;[{}] [{}] Aborted on the file [{}], exiting&quot;, shardId, snapshotId, fileName);</b>
<b class="nc"><i>1094</i>&nbsp;                    throw new IndexShardSnapshotFailedException(shardId, &quot;Aborted&quot;);</b>
<i>1095</i>&nbsp;                }
<i>1096</i>&nbsp;
<b class="nc"><i>1097</i>&nbsp;                logger.trace(&quot;[{}] [{}] Processing [{}]&quot;, shardId, snapshotId, fileName);</b>
<b class="nc"><i>1098</i>&nbsp;                final StoreFileMetaData md = metadataFromStore.get(fileName);</b>
<b class="nc"><i>1099</i>&nbsp;                BlobStoreIndexShardSnapshot.FileInfo existingFileInfo = null;</b>
<b class="nc"><i>1100</i>&nbsp;                List&lt;BlobStoreIndexShardSnapshot.FileInfo&gt; filesInfo = snapshots.findPhysicalIndexFiles(fileName);</b>
<b class="nc"><i>1101</i>&nbsp;                if (filesInfo != null) {</b>
<b class="nc"><i>1102</i>&nbsp;                    for (BlobStoreIndexShardSnapshot.FileInfo fileInfo : filesInfo) {</b>
<b class="nc"><i>1103</i>&nbsp;                        if (fileInfo.isSame(md)) {</b>
<i>1104</i>&nbsp;                            // a commit point file with the same name, size and checksum was already copied to repository
<i>1105</i>&nbsp;                            // we will reuse it for this snapshot
<b class="nc"><i>1106</i>&nbsp;                            existingFileInfo = fileInfo;</b>
<b class="nc"><i>1107</i>&nbsp;                            break;</b>
<i>1108</i>&nbsp;                        }
<b class="nc"><i>1109</i>&nbsp;                    }</b>
<i>1110</i>&nbsp;                }
<i>1111</i>&nbsp;
<b class="nc"><i>1112</i>&nbsp;                indexTotalFileCount += md.length();</b>
<b class="nc"><i>1113</i>&nbsp;                indexTotalNumberOfFiles++;</b>
<i>1114</i>&nbsp;
<b class="nc"><i>1115</i>&nbsp;                if (existingFileInfo == null) {</b>
<b class="nc"><i>1116</i>&nbsp;                    indexIncrementalFileCount++;</b>
<b class="nc"><i>1117</i>&nbsp;                    indexIncrementalSize += md.length();</b>
<i>1118</i>&nbsp;                    // create a new FileInfo
<b class="nc"><i>1119</i>&nbsp;                    BlobStoreIndexShardSnapshot.FileInfo snapshotFileInfo =</b>
<b class="nc"><i>1120</i>&nbsp;                        new BlobStoreIndexShardSnapshot.FileInfo(DATA_BLOB_PREFIX + UUIDs.randomBase64UUID(), md, chunkSize());</b>
<b class="nc"><i>1121</i>&nbsp;                    indexCommitPointFiles.add(snapshotFileInfo);</b>
<b class="nc"><i>1122</i>&nbsp;                    filesToSnapshot.add(snapshotFileInfo);</b>
<b class="nc"><i>1123</i>&nbsp;                } else {</b>
<b class="nc"><i>1124</i>&nbsp;                    indexCommitPointFiles.add(existingFileInfo);</b>
<i>1125</i>&nbsp;                }
<b class="nc"><i>1126</i>&nbsp;            }</b>
<i>1127</i>&nbsp;
<b class="nc"><i>1128</i>&nbsp;            snapshotStatus.moveToStarted(startTime, indexIncrementalFileCount,</b>
<i>1129</i>&nbsp;                indexTotalNumberOfFiles, indexIncrementalSize, indexTotalFileCount);
<i>1130</i>&nbsp;
<b class="nc"><i>1131</i>&nbsp;            assert indexIncrementalFileCount == filesToSnapshot.size();</b>
<i>1132</i>&nbsp;
<b class="nc"><i>1133</i>&nbsp;            final StepListener&lt;Collection&lt;Void&gt;&gt; allFilesUploadedListener = new StepListener&lt;&gt;();</b>
<b class="nc"><i>1134</i>&nbsp;            allFilesUploadedListener.whenComplete(v -&gt; {</b>
<b class="nc"><i>1135</i>&nbsp;                final IndexShardSnapshotStatus.Copy lastSnapshotStatus =</b>
<b class="nc"><i>1136</i>&nbsp;                    snapshotStatus.moveToFinalize(snapshotIndexCommit.getGeneration());</b>
<i>1137</i>&nbsp;
<i>1138</i>&nbsp;                // now create and write the commit point
<b class="nc"><i>1139</i>&nbsp;                final BlobStoreIndexShardSnapshot snapshot = new BlobStoreIndexShardSnapshot(snapshotId.getName(),</b>
<b class="nc"><i>1140</i>&nbsp;                    lastSnapshotStatus.getIndexVersion(),</b>
<i>1141</i>&nbsp;                    indexCommitPointFiles,
<b class="nc"><i>1142</i>&nbsp;                    lastSnapshotStatus.getStartTime(),</b>
<b class="nc"><i>1143</i>&nbsp;                    threadPool.absoluteTimeInMillis() - lastSnapshotStatus.getStartTime(),</b>
<b class="nc"><i>1144</i>&nbsp;                    lastSnapshotStatus.getIncrementalFileCount(),</b>
<b class="nc"><i>1145</i>&nbsp;                    lastSnapshotStatus.getIncrementalSize()</b>
<i>1146</i>&nbsp;                );
<i>1147</i>&nbsp;
<b class="nc"><i>1148</i>&nbsp;                logger.trace(&quot;[{}] [{}] writing shard snapshot file&quot;, shardId, snapshotId);</b>
<i>1149</i>&nbsp;                try {
<b class="nc"><i>1150</i>&nbsp;                    indexShardSnapshotFormat.write(snapshot, shardContainer, snapshotId.getUUID(), false);</b>
<b class="nc"><i>1151</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>1152</i>&nbsp;                    throw new IndexShardSnapshotFailedException(shardId, &quot;Failed to write commit point&quot;, e);</b>
<b class="nc"><i>1153</i>&nbsp;                }</b>
<i>1154</i>&nbsp;                // delete all files that are not referenced by any commit point
<i>1155</i>&nbsp;                // build a new BlobStoreIndexShardSnapshot, that includes this one and all the saved ones
<b class="nc"><i>1156</i>&nbsp;                List&lt;SnapshotFiles&gt; newSnapshotsList = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>1157</i>&nbsp;                newSnapshotsList.add(new SnapshotFiles(snapshot.snapshot(), snapshot.indexFiles()));</b>
<b class="nc"><i>1158</i>&nbsp;                for (SnapshotFiles point : snapshots) {</b>
<b class="nc"><i>1159</i>&nbsp;                    newSnapshotsList.add(point);</b>
<b class="nc"><i>1160</i>&nbsp;                }</b>
<b class="nc"><i>1161</i>&nbsp;                final String indexGeneration = Long.toString(fileListGeneration + 1);</b>
<i>1162</i>&nbsp;                final List&lt;String&gt; blobsToDelete;
<i>1163</i>&nbsp;                try {
<b class="nc"><i>1164</i>&nbsp;                    final BlobStoreIndexShardSnapshots updatedSnapshots = new BlobStoreIndexShardSnapshots(newSnapshotsList);</b>
<b class="nc"><i>1165</i>&nbsp;                    indexShardSnapshotsFormat.writeAtomic(updatedSnapshots, shardContainer, indexGeneration);</b>
<i>1166</i>&nbsp;                    // Delete all previous index-N blobs
<b class="nc"><i>1167</i>&nbsp;                    blobsToDelete =</b>
<b class="nc"><i>1168</i>&nbsp;                        blobs.keySet().stream().filter(blob -&gt; blob.startsWith(SNAPSHOT_INDEX_PREFIX)).collect(Collectors.toList());</b>
<b class="nc"><i>1169</i>&nbsp;                    assert blobsToDelete.stream().mapToLong(b -&gt; Long.parseLong(b.replaceFirst(SNAPSHOT_INDEX_PREFIX, &quot;&quot;)))</b>
<b class="nc"><i>1170</i>&nbsp;                        .max().orElse(-1L) &lt; Long.parseLong(indexGeneration)</b>
<i>1171</i>&nbsp;                        : &quot;Tried to delete an index-N blob newer than the current generation [&quot; + indexGeneration
<i>1172</i>&nbsp;                        + &quot;] when deleting index-N blobs &quot; + blobsToDelete;
<b class="nc"><i>1173</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>1174</i>&nbsp;                    throw new IndexShardSnapshotFailedException(shardId,</b>
<i>1175</i>&nbsp;                        &quot;Failed to finalize snapshot creation [&quot; + snapshotId + &quot;] with shard index [&quot;
<b class="nc"><i>1176</i>&nbsp;                            + indexShardSnapshotsFormat.blobName(indexGeneration) + &quot;]&quot;, e);</b>
<b class="nc"><i>1177</i>&nbsp;                }</b>
<i>1178</i>&nbsp;                try {
<b class="nc"><i>1179</i>&nbsp;                    shardContainer.deleteBlobsIgnoringIfNotExists(blobsToDelete);</b>
<b class="nc"><i>1180</i>&nbsp;                } catch (IOException e) {</b>
<b class="nc"><i>1181</i>&nbsp;                    logger.warn(() -&gt; new ParameterizedMessage(&quot;[{}][{}] failed to delete old index-N blobs during finalization&quot;,</b>
<i>1182</i>&nbsp;                        snapshotId, shardId), e);
<b class="nc"><i>1183</i>&nbsp;                }</b>
<b class="nc"><i>1184</i>&nbsp;                snapshotStatus.moveToDone(threadPool.absoluteTimeInMillis());</b>
<b class="nc"><i>1185</i>&nbsp;                listener.onResponse(null);</b>
<b class="nc"><i>1186</i>&nbsp;            }, listener::onFailure);</b>
<b class="nc"><i>1187</i>&nbsp;            if (indexIncrementalFileCount == 0) {</b>
<b class="nc"><i>1188</i>&nbsp;                allFilesUploadedListener.onResponse(Collections.emptyList());</b>
<b class="nc"><i>1189</i>&nbsp;                return;</b>
<i>1190</i>&nbsp;            }
<b class="nc"><i>1191</i>&nbsp;            final GroupedActionListener&lt;Void&gt; filesListener =</b>
<i>1192</i>&nbsp;                new GroupedActionListener&lt;&gt;(allFilesUploadedListener, indexIncrementalFileCount);
<b class="nc"><i>1193</i>&nbsp;            final Executor executor = threadPool.executor(ThreadPool.Names.SNAPSHOT);</b>
<i>1194</i>&nbsp;            // Flag to signal that the snapshot has been aborted/failed so we can stop any further blob uploads from starting
<b class="nc"><i>1195</i>&nbsp;            final AtomicBoolean alreadyFailed = new AtomicBoolean();</b>
<b class="nc"><i>1196</i>&nbsp;            for (BlobStoreIndexShardSnapshot.FileInfo snapshotFileInfo : filesToSnapshot) {</b>
<b class="nc"><i>1197</i>&nbsp;                executor.execute(new ActionRunnable&lt;Void&gt;(filesListener) {</b>
<i>1198</i>&nbsp;                    @Override
<i>1199</i>&nbsp;                    protected void doRun() {
<i>1200</i>&nbsp;                        try {
<i>1201</i>&nbsp;                            if (alreadyFailed.get() == false) {
<i>1202</i>&nbsp;                                if (store.tryIncRef()) {
<i>1203</i>&nbsp;                                    try {
<i>1204</i>&nbsp;                                        snapshotFile(snapshotFileInfo, indexId, shardId, snapshotId, snapshotStatus, store);
<i>1205</i>&nbsp;                                    } finally {
<i>1206</i>&nbsp;                                        store.decRef();
<i>1207</i>&nbsp;                                    }
<i>1208</i>&nbsp;                                } else if (snapshotStatus.isAborted()) {
<i>1209</i>&nbsp;                                    throw new IndexShardSnapshotFailedException(shardId, &quot;Aborted&quot;);
<i>1210</i>&nbsp;                                } else {
<i>1211</i>&nbsp;                                    assert false : &quot;Store was closed before aborting the snapshot&quot;;
<i>1212</i>&nbsp;                                    throw new IllegalStateException(&quot;Store is closed already&quot;);
<i>1213</i>&nbsp;                                }
<i>1214</i>&nbsp;                            }
<i>1215</i>&nbsp;                            filesListener.onResponse(null);
<i>1216</i>&nbsp;                        } catch (IOException e) {
<i>1217</i>&nbsp;                            throw new IndexShardSnapshotFailedException(shardId, &quot;Failed to perform snapshot (index files)&quot;, e);
<i>1218</i>&nbsp;                        }
<i>1219</i>&nbsp;                    }
<i>1220</i>&nbsp;
<i>1221</i>&nbsp;                    @Override
<i>1222</i>&nbsp;                    public void onFailure(Exception e) {
<i>1223</i>&nbsp;                        alreadyFailed.set(true);
<i>1224</i>&nbsp;                        super.onFailure(e);
<i>1225</i>&nbsp;                    }
<i>1226</i>&nbsp;                });
<b class="nc"><i>1227</i>&nbsp;            }</b>
<b class="nc"><i>1228</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>1229</i>&nbsp;            listener.onFailure(e);</b>
<b class="nc"><i>1230</i>&nbsp;        }</b>
<b class="nc"><i>1231</i>&nbsp;    }</b>
<i>1232</i>&nbsp;
<i>1233</i>&nbsp;    @Override
<i>1234</i>&nbsp;    public void restoreShard(Store store, SnapshotId snapshotId, Version version, IndexId indexId, ShardId snapshotShardId,
<i>1235</i>&nbsp;                             RecoveryState recoveryState) {
<b class="nc"><i>1236</i>&nbsp;        ShardId shardId = store.shardId();</b>
<i>1237</i>&nbsp;        try {
<b class="nc"><i>1238</i>&nbsp;            final BlobContainer container = shardContainer(indexId, snapshotShardId);</b>
<b class="nc"><i>1239</i>&nbsp;            BlobStoreIndexShardSnapshot snapshot = loadShardSnapshot(container, snapshotId);</b>
<b class="nc"><i>1240</i>&nbsp;            SnapshotFiles snapshotFiles = new SnapshotFiles(snapshot.snapshot(), snapshot.indexFiles());</b>
<b class="nc"><i>1241</i>&nbsp;            new FileRestoreContext(metadata.name(), shardId, snapshotId, recoveryState, BUFFER_SIZE) {</b>
<i>1242</i>&nbsp;                @Override
<i>1243</i>&nbsp;                protected InputStream fileInputStream(BlobStoreIndexShardSnapshot.FileInfo fileInfo) {
<i>1244</i>&nbsp;                    final InputStream dataBlobCompositeStream = new SlicedInputStream(fileInfo.numberOfParts()) {
<i>1245</i>&nbsp;                        @Override
<i>1246</i>&nbsp;                        protected InputStream openSlice(long slice) throws IOException {
<i>1247</i>&nbsp;                            return container.readBlob(fileInfo.partName(slice));
<i>1248</i>&nbsp;                        }
<i>1249</i>&nbsp;                    };
<i>1250</i>&nbsp;                    return restoreRateLimiter == null ? dataBlobCompositeStream
<i>1251</i>&nbsp;                        : new RateLimitingInputStream(dataBlobCompositeStream, restoreRateLimiter, restoreRateLimitingTimeInNanos::inc);
<i>1252</i>&nbsp;                }
<b class="nc"><i>1253</i>&nbsp;            }.restore(snapshotFiles, store);</b>
<b class="nc"><i>1254</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i>1255</i>&nbsp;            throw new IndexShardRestoreFailedException(shardId, &quot;failed to restore snapshot [&quot; + snapshotId + &quot;]&quot;, e);</b>
<b class="nc"><i>1256</i>&nbsp;        }</b>
<b class="nc"><i>1257</i>&nbsp;    }</b>
<i>1258</i>&nbsp;
<i>1259</i>&nbsp;    @Override
<i>1260</i>&nbsp;    public IndexShardSnapshotStatus getShardSnapshotStatus(SnapshotId snapshotId, Version version, IndexId indexId, ShardId shardId) {
<b class="nc"><i>1261</i>&nbsp;        BlobStoreIndexShardSnapshot snapshot = loadShardSnapshot(shardContainer(indexId, shardId), snapshotId);</b>
<b class="nc"><i>1262</i>&nbsp;        return IndexShardSnapshotStatus.newDone(snapshot.startTime(), snapshot.time(),</b>
<b class="nc"><i>1263</i>&nbsp;            snapshot.incrementalFileCount(), snapshot.totalFileCount(),</b>
<b class="nc"><i>1264</i>&nbsp;            snapshot.incrementalSize(), snapshot.totalSize());</b>
<i>1265</i>&nbsp;    }
<i>1266</i>&nbsp;
<i>1267</i>&nbsp;    @Override
<i>1268</i>&nbsp;    public void verify(String seed, DiscoveryNode localNode) {
<b class="nc"><i>1269</i>&nbsp;        assertSnapshotOrGenericThread();</b>
<b class="nc"><i>1270</i>&nbsp;        if (isReadOnly()) {</b>
<i>1271</i>&nbsp;            try {
<b class="nc"><i>1272</i>&nbsp;                latestIndexBlobId();</b>
<b class="nc"><i>1273</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i>1274</i>&nbsp;                throw new RepositoryVerificationException(metadata.name(), &quot;path &quot; + basePath() +</b>
<i>1275</i>&nbsp;                    &quot; is not accessible on node &quot; + localNode, e);
<b class="nc"><i>1276</i>&nbsp;            }</b>
<i>1277</i>&nbsp;        } else {
<b class="nc"><i>1278</i>&nbsp;            BlobContainer testBlobContainer = blobStore().blobContainer(basePath().add(testBlobPrefix(seed)));</b>
<i>1279</i>&nbsp;            try {
<b class="nc"><i>1280</i>&nbsp;                BytesArray bytes = new BytesArray(seed);</b>
<b class="nc"><i>1281</i>&nbsp;                try (InputStream stream = bytes.streamInput()) {</b>
<b class="nc"><i>1282</i>&nbsp;                    testBlobContainer.writeBlob(&quot;data-&quot; + localNode.getId() + &quot;.dat&quot;, stream, bytes.length(), true);</b>
<b class="nc"><i>1283</i>&nbsp;                }</b>
<b class="nc"><i>1284</i>&nbsp;            } catch (IOException exp) {</b>
<b class="nc"><i>1285</i>&nbsp;                throw new RepositoryVerificationException(metadata.name(), &quot;store location [&quot; + blobStore() +</b>
<i>1286</i>&nbsp;                    &quot;] is not accessible on the node [&quot; + localNode + &quot;]&quot;, exp);
<b class="nc"><i>1287</i>&nbsp;            }</b>
<b class="nc"><i>1288</i>&nbsp;            try (InputStream masterDat = testBlobContainer.readBlob(&quot;master.dat&quot;)) {</b>
<b class="nc"><i>1289</i>&nbsp;                final String seedRead = Streams.readFully(masterDat).utf8ToString();</b>
<b class="nc"><i>1290</i>&nbsp;                if (seedRead.equals(seed) == false) {</b>
<b class="nc"><i>1291</i>&nbsp;                    throw new RepositoryVerificationException(metadata.name(), &quot;Seed read from master.dat was [&quot; + seedRead +</b>
<i>1292</i>&nbsp;                        &quot;] but expected seed [&quot; + seed + &quot;]&quot;);
<i>1293</i>&nbsp;                }
<b class="nc"><i>1294</i>&nbsp;            } catch (NoSuchFileException e) {</b>
<b class="nc"><i>1295</i>&nbsp;                throw new RepositoryVerificationException(metadata.name(), &quot;a file written by master to the store [&quot; + blobStore() +</b>
<i>1296</i>&nbsp;                    &quot;] cannot be accessed on the node [&quot; + localNode + &quot;]. &quot; +
<b class="nc"><i>1297</i>&nbsp;                    &quot;This might indicate that the store [&quot; + blobStore() + &quot;] is not shared between this node and the master node or &quot; +</b>
<i>1298</i>&nbsp;                    &quot;that permissions on the store don&#39;t allow reading files written by the master node&quot;, e);
<b class="nc"><i>1299</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i>1300</i>&nbsp;                throw new RepositoryVerificationException(metadata.name(), &quot;Failed to verify repository&quot;, e);</b>
<b class="nc"><i>1301</i>&nbsp;            }</b>
<i>1302</i>&nbsp;        }
<b class="nc"><i>1303</i>&nbsp;    }</b>
<i>1304</i>&nbsp;
<i>1305</i>&nbsp;    @Override
<i>1306</i>&nbsp;    public String toString() {
<b class="nc"><i>1307</i>&nbsp;        return &quot;BlobStoreRepository[&quot; +</b>
<b class="nc"><i>1308</i>&nbsp;            &quot;[&quot; + metadata.name() +</b>
<b class="nc"><i>1309</i>&nbsp;            &quot;], [&quot; + blobStore() + &#39;]&#39; +</b>
<i>1310</i>&nbsp;            &#39;]&#39;;
<i>1311</i>&nbsp;    }
<i>1312</i>&nbsp;
<i>1313</i>&nbsp;    /**
<i>1314</i>&nbsp;     * Delete shard snapshot
<i>1315</i>&nbsp;     */
<i>1316</i>&nbsp;    private ShardSnapshotMetaDeleteResult deleteShardSnapshot(RepositoryData repositoryData, IndexId indexId, ShardId snapshotShardId,
<i>1317</i>&nbsp;                                                              SnapshotId snapshotId) throws IOException {
<b class="nc"><i>1318</i>&nbsp;        final BlobContainer shardContainer = shardContainer(indexId, snapshotShardId);</b>
<i>1319</i>&nbsp;        final Map&lt;String, BlobMetaData&gt; blobs;
<i>1320</i>&nbsp;        try {
<b class="nc"><i>1321</i>&nbsp;            blobs = shardContainer.listBlobs();</b>
<b class="nc"><i>1322</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i>1323</i>&nbsp;            throw new IndexShardSnapshotException(snapshotShardId, &quot;Failed to list content of shard directory&quot;, e);</b>
<b class="nc"><i>1324</i>&nbsp;        }</b>
<i>1325</i>&nbsp;
<b class="nc"><i>1326</i>&nbsp;        Tuple&lt;BlobStoreIndexShardSnapshots, Long&gt; tuple = buildBlobStoreIndexShardSnapshots(blobs.keySet(), shardContainer);</b>
<b class="nc"><i>1327</i>&nbsp;        BlobStoreIndexShardSnapshots snapshots = tuple.v1();</b>
<b class="nc"><i>1328</i>&nbsp;        long fileListGeneration = tuple.v2();</b>
<i>1329</i>&nbsp;
<i>1330</i>&nbsp;        // Build a list of snapshots that should be preserved
<b class="nc"><i>1331</i>&nbsp;        List&lt;SnapshotFiles&gt; newSnapshotsList = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>1332</i>&nbsp;        final Set&lt;String&gt; survivingSnapshotNames =</b>
<b class="nc"><i>1333</i>&nbsp;            repositoryData.getSnapshots(indexId).stream().map(SnapshotId::getName).collect(Collectors.toSet());</b>
<b class="nc"><i>1334</i>&nbsp;        for (SnapshotFiles point : snapshots) {</b>
<b class="nc"><i>1335</i>&nbsp;            if (survivingSnapshotNames.contains(point.snapshot())) {</b>
<b class="nc"><i>1336</i>&nbsp;                newSnapshotsList.add(point);</b>
<i>1337</i>&nbsp;            }
<b class="nc"><i>1338</i>&nbsp;        }</b>
<b class="nc"><i>1339</i>&nbsp;        final String indexGeneration = Long.toString(fileListGeneration + 1);</b>
<i>1340</i>&nbsp;        try {
<i>1341</i>&nbsp;            final List&lt;String&gt; blobsToDelete;
<b class="nc"><i>1342</i>&nbsp;            if (newSnapshotsList.isEmpty()) {</b>
<i>1343</i>&nbsp;                // If we deleted all snapshots, we don&#39;t need to create a new index file and simply delete all the blobs we found
<b class="nc"><i>1344</i>&nbsp;                blobsToDelete = new ArrayList&lt;&gt;(blobs.keySet());</b>
<i>1345</i>&nbsp;            } else {
<b class="nc"><i>1346</i>&nbsp;                final Set&lt;String&gt; survivingSnapshotUUIDs = repositoryData.getSnapshots(indexId).stream().map(SnapshotId::getUUID)</b>
<b class="nc"><i>1347</i>&nbsp;                    .collect(Collectors.toSet());</b>
<b class="nc"><i>1348</i>&nbsp;                final BlobStoreIndexShardSnapshots updatedSnapshots = new BlobStoreIndexShardSnapshots(newSnapshotsList);</b>
<b class="nc"><i>1349</i>&nbsp;                indexShardSnapshotsFormat.writeAtomic(updatedSnapshots, shardContainer, indexGeneration);</b>
<b class="nc"><i>1350</i>&nbsp;                blobsToDelete = unusedBlobs(blobs, survivingSnapshotUUIDs, updatedSnapshots);</b>
<i>1351</i>&nbsp;            }
<b class="nc"><i>1352</i>&nbsp;            return new ShardSnapshotMetaDeleteResult(indexId, snapshotShardId.id(), blobsToDelete);</b>
<b class="nc"><i>1353</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i>1354</i>&nbsp;            throw new IndexShardSnapshotFailedException(snapshotShardId,</b>
<i>1355</i>&nbsp;                &quot;Failed to finalize snapshot deletion [&quot; + snapshotId + &quot;] with shard index [&quot;
<b class="nc"><i>1356</i>&nbsp;                    + indexShardSnapshotsFormat.blobName(indexGeneration) + &quot;]&quot;, e);</b>
<i>1357</i>&nbsp;        }
<i>1358</i>&nbsp;    }
<i>1359</i>&nbsp;
<i>1360</i>&nbsp;    // Unused blobs are all previous index-, data- and meta-blobs and that are not referenced by the new index- as well as all
<i>1361</i>&nbsp;    // temporary blobs
<i>1362</i>&nbsp;    private static List&lt;String&gt; unusedBlobs(Map&lt;String, BlobMetaData&gt; blobs, Set&lt;String&gt; survivingSnapshotUUIDs,
<i>1363</i>&nbsp;                                            BlobStoreIndexShardSnapshots updatedSnapshots) {
<b class="nc"><i>1364</i>&nbsp;        return blobs.keySet().stream().filter(blob -&gt;</b>
<b class="nc"><i>1365</i>&nbsp;            blob.startsWith(SNAPSHOT_INDEX_PREFIX)</b>
<b class="nc"><i>1366</i>&nbsp;                || (blob.startsWith(SNAPSHOT_PREFIX) &amp;&amp; blob.endsWith(&quot;.dat&quot;)</b>
<b class="nc"><i>1367</i>&nbsp;                    &amp;&amp; survivingSnapshotUUIDs.contains(</b>
<b class="nc"><i>1368</i>&nbsp;                        blob.substring(SNAPSHOT_PREFIX.length(), blob.length() - &quot;.dat&quot;.length())) == false)</b>
<b class="nc"><i>1369</i>&nbsp;                || (blob.startsWith(DATA_BLOB_PREFIX) &amp;&amp; updatedSnapshots.findNameFile(canonicalName(blob)) == null)</b>
<b class="nc"><i>1370</i>&nbsp;                || FsBlobContainer.isTempBlobName(blob)).collect(Collectors.toList());</b>
<i>1371</i>&nbsp;    }
<i>1372</i>&nbsp;
<i>1373</i>&nbsp;
<i>1374</i>&nbsp;    /**
<i>1375</i>&nbsp;     * Loads information about shard snapshot
<i>1376</i>&nbsp;     */
<i>1377</i>&nbsp;    private BlobStoreIndexShardSnapshot loadShardSnapshot(BlobContainer shardContainer, SnapshotId snapshotId) {
<i>1378</i>&nbsp;        try {
<b class="nc"><i>1379</i>&nbsp;            return indexShardSnapshotFormat.read(shardContainer, snapshotId.getUUID());</b>
<b class="nc"><i>1380</i>&nbsp;        } catch (NoSuchFileException ex) {</b>
<b class="nc"><i>1381</i>&nbsp;            throw new SnapshotMissingException(metadata.name(), snapshotId, ex);</b>
<b class="nc"><i>1382</i>&nbsp;        } catch (IOException ex) {</b>
<b class="nc"><i>1383</i>&nbsp;            throw new SnapshotException(metadata.name(), snapshotId,</b>
<b class="nc"><i>1384</i>&nbsp;                &quot;failed to read shard snapshot file for [&quot; + shardContainer.path() + &#39;]&#39;, ex);</b>
<i>1385</i>&nbsp;        }
<i>1386</i>&nbsp;    }
<i>1387</i>&nbsp;
<i>1388</i>&nbsp;    /**
<i>1389</i>&nbsp;     * Loads all available snapshots in the repository
<i>1390</i>&nbsp;     *
<i>1391</i>&nbsp;     * @param blobs list of blobs in repository
<i>1392</i>&nbsp;     * @return tuple of BlobStoreIndexShardSnapshots and the last snapshot index generation
<i>1393</i>&nbsp;     */
<i>1394</i>&nbsp;    private Tuple&lt;BlobStoreIndexShardSnapshots, Long&gt; buildBlobStoreIndexShardSnapshots(Set&lt;String&gt; blobs, BlobContainer shardContainer)
<i>1395</i>&nbsp;            throws IOException {
<b class="nc"><i>1396</i>&nbsp;        long latest = latestGeneration(blobs);</b>
<b class="nc"><i>1397</i>&nbsp;        if (latest &gt;= 0) {</b>
<b class="nc"><i>1398</i>&nbsp;            final BlobStoreIndexShardSnapshots shardSnapshots = indexShardSnapshotsFormat.read(shardContainer, Long.toString(latest));</b>
<b class="nc"><i>1399</i>&nbsp;            return new Tuple&lt;&gt;(shardSnapshots, latest);</b>
<b class="nc"><i>1400</i>&nbsp;        } else if (blobs.stream().anyMatch(b -&gt; b.startsWith(SNAPSHOT_PREFIX) || b.startsWith(INDEX_FILE_PREFIX)</b>
<b class="nc"><i>1401</i>&nbsp;                                                                              || b.startsWith(DATA_BLOB_PREFIX))) {</b>
<b class="nc"><i>1402</i>&nbsp;            throw new IllegalStateException(</b>
<b class="nc"><i>1403</i>&nbsp;                &quot;Could not find a readable index-N file in a non-empty shard snapshot directory [&quot; + shardContainer.path() + &quot;]&quot;);</b>
<i>1404</i>&nbsp;        }
<b class="nc"><i>1405</i>&nbsp;        return new Tuple&lt;&gt;(BlobStoreIndexShardSnapshots.EMPTY, latest);</b>
<i>1406</i>&nbsp;    }
<i>1407</i>&nbsp;
<i>1408</i>&nbsp;    /**
<i>1409</i>&nbsp;     * Snapshot individual file
<i>1410</i>&nbsp;     * @param fileInfo file to be snapshotted
<i>1411</i>&nbsp;     */
<i>1412</i>&nbsp;    private void snapshotFile(BlobStoreIndexShardSnapshot.FileInfo fileInfo, IndexId indexId, ShardId shardId, SnapshotId snapshotId,
<i>1413</i>&nbsp;                              IndexShardSnapshotStatus snapshotStatus, Store store) throws IOException {
<b class="nc"><i>1414</i>&nbsp;        final BlobContainer shardContainer = shardContainer(indexId, shardId);</b>
<b class="nc"><i>1415</i>&nbsp;        final String file = fileInfo.physicalName();</b>
<b class="nc"><i>1416</i>&nbsp;        try (IndexInput indexInput = store.openVerifyingInput(file, IOContext.READONCE, fileInfo.metadata())) {</b>
<b class="nc"><i>1417</i>&nbsp;            for (int i = 0; i &lt; fileInfo.numberOfParts(); i++) {</b>
<b class="nc"><i>1418</i>&nbsp;                final long partBytes = fileInfo.partBytes(i);</b>
<i>1419</i>&nbsp;
<b class="nc"><i>1420</i>&nbsp;                InputStream inputStream = new InputStreamIndexInput(indexInput, partBytes);</b>
<b class="nc"><i>1421</i>&nbsp;                if (snapshotRateLimiter != null) {</b>
<b class="nc"><i>1422</i>&nbsp;                    inputStream = new RateLimitingInputStream(inputStream, snapshotRateLimiter,</b>
<b class="nc"><i>1423</i>&nbsp;                        snapshotRateLimitingTimeInNanos::inc);</b>
<i>1424</i>&nbsp;                }
<i>1425</i>&nbsp;                // Make reads abortable by mutating the snapshotStatus object
<b class="nc"><i>1426</i>&nbsp;                inputStream = new FilterInputStream(inputStream) {</b>
<i>1427</i>&nbsp;                    @Override
<i>1428</i>&nbsp;                    public int read() throws IOException {
<b class="nc"><i>1429</i>&nbsp;                        checkAborted();</b>
<b class="nc"><i>1430</i>&nbsp;                        return super.read();</b>
<i>1431</i>&nbsp;                    }
<i>1432</i>&nbsp;
<i>1433</i>&nbsp;                    @Override
<i>1434</i>&nbsp;                    public int read(byte[] b, int off, int len) throws IOException {
<b class="nc"><i>1435</i>&nbsp;                        checkAborted();</b>
<b class="nc"><i>1436</i>&nbsp;                        return super.read(b, off, len);</b>
<i>1437</i>&nbsp;                    }
<i>1438</i>&nbsp;
<i>1439</i>&nbsp;                    private void checkAborted() {
<b class="nc"><i>1440</i>&nbsp;                        if (snapshotStatus.isAborted()) {</b>
<b class="nc"><i>1441</i>&nbsp;                            logger.debug(&quot;[{}] [{}] Aborted on the file [{}], exiting&quot;, shardId,</b>
<b class="nc"><i>1442</i>&nbsp;                                snapshotId, fileInfo.physicalName());</b>
<b class="nc"><i>1443</i>&nbsp;                            throw new IndexShardSnapshotFailedException(shardId, &quot;Aborted&quot;);</b>
<i>1444</i>&nbsp;                        }
<b class="nc"><i>1445</i>&nbsp;                    }</b>
<i>1446</i>&nbsp;                };
<b class="nc"><i>1447</i>&nbsp;                shardContainer.writeBlob(fileInfo.partName(i), inputStream, partBytes, true);</b>
<i>1448</i>&nbsp;            }
<b class="nc"><i>1449</i>&nbsp;            Store.verify(indexInput);</b>
<b class="nc"><i>1450</i>&nbsp;            snapshotStatus.addProcessedFile(fileInfo.length());</b>
<b class="nc"><i>1451</i>&nbsp;        } catch (Exception t) {</b>
<b class="nc"><i>1452</i>&nbsp;            failStoreIfCorrupted(store, t);</b>
<b class="nc"><i>1453</i>&nbsp;            snapshotStatus.addProcessedFile(0);</b>
<b class="nc"><i>1454</i>&nbsp;            throw t;</b>
<b class="nc"><i>1455</i>&nbsp;        }</b>
<b class="nc"><i>1456</i>&nbsp;    }</b>
<i>1457</i>&nbsp;
<i>1458</i>&nbsp;    private static void failStoreIfCorrupted(Store store, Exception e) {
<b class="nc"><i>1459</i>&nbsp;        if (Lucene.isCorruptionException(e)) {</b>
<i>1460</i>&nbsp;            try {
<b class="nc"><i>1461</i>&nbsp;                store.markStoreCorrupted((IOException) e);</b>
<b class="nc"><i>1462</i>&nbsp;            } catch (IOException inner) {</b>
<b class="nc"><i>1463</i>&nbsp;                inner.addSuppressed(e);</b>
<b class="nc"><i>1464</i>&nbsp;                logger.warn(&quot;store cannot be marked as corrupted&quot;, inner);</b>
<b class="nc"><i>1465</i>&nbsp;            }</b>
<i>1466</i>&nbsp;        }
<b class="nc"><i>1467</i>&nbsp;    }</b>
<i>1468</i>&nbsp;
<i>1469</i>&nbsp;    /**
<i>1470</i>&nbsp;     * The result of removing a snapshot from a shard folder in the repository.
<i>1471</i>&nbsp;     */
<i>1472</i>&nbsp;    private static final class ShardSnapshotMetaDeleteResult {
<i>1473</i>&nbsp;
<i>1474</i>&nbsp;        // Index that the snapshot was removed from
<i>1475</i>&nbsp;        private final IndexId indexId;
<i>1476</i>&nbsp;
<i>1477</i>&nbsp;        // Shard id that the snapshot was removed from
<i>1478</i>&nbsp;        private final int shardId;
<i>1479</i>&nbsp;
<i>1480</i>&nbsp;        // Blob names in the shard directory that have become unreferenced in the new shard generation
<i>1481</i>&nbsp;        private final Collection&lt;String&gt; blobsToDelete;
<i>1482</i>&nbsp;
<i>1483</i>&nbsp;        ShardSnapshotMetaDeleteResult(IndexId indexId, int shardId, Collection&lt;String&gt; blobsToDelete) {
<i>1484</i>&nbsp;            this.indexId = indexId;
<i>1485</i>&nbsp;            this.shardId = shardId;
<i>1486</i>&nbsp;            this.blobsToDelete = blobsToDelete;
<i>1487</i>&nbsp;        }
<i>1488</i>&nbsp;    }
<i>1489</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-02-09 18:45</div>
</div>
</body>
</html>
