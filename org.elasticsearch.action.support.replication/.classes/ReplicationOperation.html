


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: ReplicationOperation</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.elasticsearch.action.support.replication</a> ]
</div>

<h1>Coverage Summary for Class: ReplicationOperation (org.elasticsearch.action.support.replication)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
  <tr>
    <td class="name">ReplicationOperation$PrimaryResult</td>
  </tr>
  <tr>
    <td class="name">ReplicationOperation$Replicas</td>
  </tr>
  <tr>
    <td class="name">ReplicationOperation$RetryOnPrimaryException</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 7)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>total</strong></td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/ 7)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to Elasticsearch under one or more contributor
<i>3</i>&nbsp; * license agreements. See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright
<i>5</i>&nbsp; * ownership. Elasticsearch licenses this file to you under
<i>6</i>&nbsp; * the Apache License, Version 2.0 (the &quot;License&quot;); you may
<i>7</i>&nbsp; * not use this file except in compliance with the License.
<i>8</i>&nbsp; * You may obtain a copy of the License at
<i>9</i>&nbsp; *
<i>10</i>&nbsp; *    http://www.apache.org/licenses/LICENSE-2.0
<i>11</i>&nbsp; *
<i>12</i>&nbsp; * Unless required by applicable law or agreed to in writing,
<i>13</i>&nbsp; * software distributed under the License is distributed on an
<i>14</i>&nbsp; * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
<i>15</i>&nbsp; * KIND, either express or implied.  See the License for the
<i>16</i>&nbsp; * specific language governing permissions and limitations
<i>17</i>&nbsp; * under the License.
<i>18</i>&nbsp; */
<i>19</i>&nbsp;package org.elasticsearch.action.support.replication;
<i>20</i>&nbsp;
<i>21</i>&nbsp;import org.apache.logging.log4j.Logger;
<i>22</i>&nbsp;import org.apache.logging.log4j.message.ParameterizedMessage;
<i>23</i>&nbsp;import org.apache.lucene.store.AlreadyClosedException;
<i>24</i>&nbsp;import org.elasticsearch.Assertions;
<i>25</i>&nbsp;import org.elasticsearch.ElasticsearchException;
<i>26</i>&nbsp;import org.elasticsearch.ExceptionsHelper;
<i>27</i>&nbsp;import org.elasticsearch.action.ActionListener;
<i>28</i>&nbsp;import org.elasticsearch.action.UnavailableShardsException;
<i>29</i>&nbsp;import org.elasticsearch.action.support.ActiveShardCount;
<i>30</i>&nbsp;import org.elasticsearch.action.support.TransportActions;
<i>31</i>&nbsp;import org.elasticsearch.cluster.action.shard.ShardStateAction;
<i>32</i>&nbsp;import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
<i>33</i>&nbsp;import org.elasticsearch.cluster.routing.ShardRouting;
<i>34</i>&nbsp;import org.elasticsearch.common.Nullable;
<i>35</i>&nbsp;import org.elasticsearch.common.io.stream.StreamInput;
<i>36</i>&nbsp;import org.elasticsearch.index.seqno.SequenceNumbers;
<i>37</i>&nbsp;import org.elasticsearch.index.shard.ReplicationGroup;
<i>38</i>&nbsp;import org.elasticsearch.index.shard.ShardId;
<i>39</i>&nbsp;import org.elasticsearch.node.NodeClosedException;
<i>40</i>&nbsp;import org.elasticsearch.rest.RestStatus;
<i>41</i>&nbsp;
<i>42</i>&nbsp;import java.io.IOException;
<i>43</i>&nbsp;import java.util.ArrayList;
<i>44</i>&nbsp;import java.util.Collections;
<i>45</i>&nbsp;import java.util.List;
<i>46</i>&nbsp;import java.util.Locale;
<i>47</i>&nbsp;import java.util.concurrent.atomic.AtomicBoolean;
<i>48</i>&nbsp;import java.util.concurrent.atomic.AtomicInteger;
<i>49</i>&nbsp;
<i>50</i>&nbsp;public class ReplicationOperation&lt;
<i>51</i>&nbsp;            Request extends ReplicationRequest&lt;Request&gt;,
<i>52</i>&nbsp;            ReplicaRequest extends ReplicationRequest&lt;ReplicaRequest&gt;,
<i>53</i>&nbsp;            PrimaryResultT extends ReplicationOperation.PrimaryResult&lt;ReplicaRequest&gt;
<i>54</i>&nbsp;        &gt; {
<i>55</i>&nbsp;    private final Logger logger;
<i>56</i>&nbsp;    private final Request request;
<i>57</i>&nbsp;    private final String opType;
<i>58</i>&nbsp;    private final AtomicInteger totalShards = new AtomicInteger();
<i>59</i>&nbsp;    /**
<i>60</i>&nbsp;     * The number of pending sub-operations in this operation. This is incremented when the following operations start and decremented when
<i>61</i>&nbsp;     * they complete:
<i>62</i>&nbsp;     * &lt;ul&gt;
<i>63</i>&nbsp;     * &lt;li&gt;The operation on the primary&lt;/li&gt;
<i>64</i>&nbsp;     * &lt;li&gt;The operation on each replica&lt;/li&gt;
<i>65</i>&nbsp;     * &lt;li&gt;Coordination of the operation as a whole. This prevents the operation from terminating early if we haven&#39;t started any replica
<i>66</i>&nbsp;     * operations and the primary finishes.&lt;/li&gt;
<i>67</i>&nbsp;     * &lt;/ul&gt;
<i>68</i>&nbsp;     */
<i>69</i>&nbsp;    private final AtomicInteger pendingActions = new AtomicInteger();
<i>70</i>&nbsp;    private final AtomicInteger successfulShards = new AtomicInteger();
<i>71</i>&nbsp;    private final Primary&lt;Request, ReplicaRequest, PrimaryResultT&gt; primary;
<i>72</i>&nbsp;    private final Replicas&lt;ReplicaRequest&gt; replicasProxy;
<i>73</i>&nbsp;    private final AtomicBoolean finished = new AtomicBoolean();
<i>74</i>&nbsp;    private final long primaryTerm;
<i>75</i>&nbsp;
<i>76</i>&nbsp;    // exposed for tests
<i>77</i>&nbsp;    private final ActionListener&lt;PrimaryResultT&gt; resultListener;
<i>78</i>&nbsp;
<i>79</i>&nbsp;    private volatile PrimaryResultT primaryResult = null;
<i>80</i>&nbsp;
<i>81</i>&nbsp;    private final List&lt;ReplicationResponse.ShardInfo.Failure&gt; shardReplicaFailures = Collections.synchronizedList(new ArrayList&lt;&gt;());
<i>82</i>&nbsp;
<i>83</i>&nbsp;    public ReplicationOperation(Request request, Primary&lt;Request, ReplicaRequest, PrimaryResultT&gt; primary,
<i>84</i>&nbsp;                                ActionListener&lt;PrimaryResultT&gt; listener,
<i>85</i>&nbsp;                                Replicas&lt;ReplicaRequest&gt; replicas,
<i>86</i>&nbsp;                                Logger logger, String opType, long primaryTerm) {
<i>87</i>&nbsp;        this.replicasProxy = replicas;
<i>88</i>&nbsp;        this.primary = primary;
<i>89</i>&nbsp;        this.resultListener = listener;
<i>90</i>&nbsp;        this.logger = logger;
<i>91</i>&nbsp;        this.request = request;
<i>92</i>&nbsp;        this.opType = opType;
<i>93</i>&nbsp;        this.primaryTerm = primaryTerm;
<i>94</i>&nbsp;    }
<i>95</i>&nbsp;
<i>96</i>&nbsp;    public void execute() throws Exception {
<i>97</i>&nbsp;        final String activeShardCountFailure = checkActiveShardCount();
<i>98</i>&nbsp;        final ShardRouting primaryRouting = primary.routingEntry();
<i>99</i>&nbsp;        final ShardId primaryId = primaryRouting.shardId();
<i>100</i>&nbsp;        if (activeShardCountFailure != null) {
<i>101</i>&nbsp;            finishAsFailed(new UnavailableShardsException(primaryId,
<i>102</i>&nbsp;                &quot;{} Timeout: [{}], request: [{}]&quot;, activeShardCountFailure, request.timeout(), request));
<i>103</i>&nbsp;            return;
<i>104</i>&nbsp;        }
<i>105</i>&nbsp;
<i>106</i>&nbsp;        totalShards.incrementAndGet();
<i>107</i>&nbsp;        pendingActions.incrementAndGet(); // increase by 1 until we finish all primary coordination
<i>108</i>&nbsp;        primary.perform(request, ActionListener.wrap(this::handlePrimaryResult, resultListener::onFailure));
<i>109</i>&nbsp;    }
<i>110</i>&nbsp;
<i>111</i>&nbsp;    private void handlePrimaryResult(final PrimaryResultT primaryResult) {
<i>112</i>&nbsp;        this.primaryResult = primaryResult;
<i>113</i>&nbsp;        primary.updateLocalCheckpointForShard(primary.routingEntry().allocationId().getId(), primary.localCheckpoint());
<i>114</i>&nbsp;        primary.updateGlobalCheckpointForShard(primary.routingEntry().allocationId().getId(), primary.globalCheckpoint());
<i>115</i>&nbsp;        final ReplicaRequest replicaRequest = primaryResult.replicaRequest();
<i>116</i>&nbsp;        if (replicaRequest != null) {
<i>117</i>&nbsp;            if (logger.isTraceEnabled()) {
<i>118</i>&nbsp;                logger.trace(&quot;[{}] op [{}] completed on primary for request [{}]&quot;, primary.routingEntry().shardId(), opType, request);
<i>119</i>&nbsp;            }
<i>120</i>&nbsp;            // we have to get the replication group after successfully indexing into the primary in order to honour recovery semantics.
<i>121</i>&nbsp;            // we have to make sure that every operation indexed into the primary after recovery start will also be replicated
<i>122</i>&nbsp;            // to the recovery target. If we used an old replication group, we may miss a recovery that has started since then.
<i>123</i>&nbsp;            // we also have to make sure to get the global checkpoint before the replication group, to ensure that the global checkpoint
<i>124</i>&nbsp;            // is valid for this replication group. If we would sample in the reverse, the global checkpoint might be based on a subset
<i>125</i>&nbsp;            // of the sampled replication group, and advanced further than what the given replication group would allow it to.
<i>126</i>&nbsp;            // This would entail that some shards could learn about a global checkpoint that would be higher than its local checkpoint.
<i>127</i>&nbsp;            final long globalCheckpoint = primary.computedGlobalCheckpoint();
<i>128</i>&nbsp;            // we have to capture the max_seq_no_of_updates after this request was completed on the primary to make sure the value of
<i>129</i>&nbsp;            // max_seq_no_of_updates on replica when this request is executed is at least the value on the primary when it was executed
<i>130</i>&nbsp;            // on.
<i>131</i>&nbsp;            final long maxSeqNoOfUpdatesOrDeletes = primary.maxSeqNoOfUpdatesOrDeletes();
<i>132</i>&nbsp;            assert maxSeqNoOfUpdatesOrDeletes != SequenceNumbers.UNASSIGNED_SEQ_NO : &quot;seqno_of_updates still uninitialized&quot;;
<i>133</i>&nbsp;            final ReplicationGroup replicationGroup = primary.getReplicationGroup();
<i>134</i>&nbsp;            markUnavailableShardsAsStale(replicaRequest, replicationGroup);
<i>135</i>&nbsp;            performOnReplicas(replicaRequest, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes, replicationGroup);
<i>136</i>&nbsp;        }
<i>137</i>&nbsp;        successfulShards.incrementAndGet();  // mark primary as successful
<i>138</i>&nbsp;        decPendingAndFinishIfNeeded();
<i>139</i>&nbsp;    }
<i>140</i>&nbsp;
<i>141</i>&nbsp;    private void markUnavailableShardsAsStale(ReplicaRequest replicaRequest, ReplicationGroup replicationGroup) {
<i>142</i>&nbsp;        // if inSyncAllocationIds contains allocation ids of shards that don&#39;t exist in RoutingTable, mark copies as stale
<i>143</i>&nbsp;        for (String allocationId : replicationGroup.getUnavailableInSyncShards()) {
<i>144</i>&nbsp;            pendingActions.incrementAndGet();
<i>145</i>&nbsp;            replicasProxy.markShardCopyAsStaleIfNeeded(replicaRequest.shardId(), allocationId, primaryTerm,
<i>146</i>&nbsp;                ActionListener.wrap(r -&gt; decPendingAndFinishIfNeeded(), ReplicationOperation.this::onNoLongerPrimary));
<i>147</i>&nbsp;        }
<i>148</i>&nbsp;    }
<i>149</i>&nbsp;
<i>150</i>&nbsp;    private void performOnReplicas(final ReplicaRequest replicaRequest, final long globalCheckpoint,
<i>151</i>&nbsp;                                   final long maxSeqNoOfUpdatesOrDeletes, final ReplicationGroup replicationGroup) {
<i>152</i>&nbsp;        // for total stats, add number of unassigned shards and
<i>153</i>&nbsp;        // number of initializing shards that are not ready yet to receive operations (recovery has not opened engine yet on the target)
<i>154</i>&nbsp;        totalShards.addAndGet(replicationGroup.getSkippedShards().size());
<i>155</i>&nbsp;
<i>156</i>&nbsp;        final ShardRouting primaryRouting = primary.routingEntry();
<i>157</i>&nbsp;
<i>158</i>&nbsp;        for (final ShardRouting shard : replicationGroup.getReplicationTargets()) {
<i>159</i>&nbsp;            if (shard.isSameAllocation(primaryRouting) == false) {
<i>160</i>&nbsp;                performOnReplica(shard, replicaRequest, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes);
<i>161</i>&nbsp;            }
<i>162</i>&nbsp;        }
<i>163</i>&nbsp;    }
<i>164</i>&nbsp;
<i>165</i>&nbsp;    private void performOnReplica(final ShardRouting shard, final ReplicaRequest replicaRequest,
<i>166</i>&nbsp;                                  final long globalCheckpoint, final long maxSeqNoOfUpdatesOrDeletes) {
<i>167</i>&nbsp;        if (logger.isTraceEnabled()) {
<i>168</i>&nbsp;            logger.trace(&quot;[{}] sending op [{}] to replica {} for request [{}]&quot;, shard.shardId(), opType, shard, replicaRequest);
<i>169</i>&nbsp;        }
<i>170</i>&nbsp;
<i>171</i>&nbsp;        totalShards.incrementAndGet();
<i>172</i>&nbsp;        pendingActions.incrementAndGet();
<i>173</i>&nbsp;        replicasProxy.performOn(shard, replicaRequest, primaryTerm, globalCheckpoint, maxSeqNoOfUpdatesOrDeletes,
<i>174</i>&nbsp;            new ActionListener&lt;ReplicaResponse&gt;() {
<i>175</i>&nbsp;                @Override
<i>176</i>&nbsp;                public void onResponse(ReplicaResponse response) {
<i>177</i>&nbsp;                    successfulShards.incrementAndGet();
<i>178</i>&nbsp;                    try {
<i>179</i>&nbsp;                        primary.updateLocalCheckpointForShard(shard.allocationId().getId(), response.localCheckpoint());
<i>180</i>&nbsp;                        primary.updateGlobalCheckpointForShard(shard.allocationId().getId(), response.globalCheckpoint());
<i>181</i>&nbsp;                    } catch (final AlreadyClosedException e) {
<i>182</i>&nbsp;                        // the index was deleted or this shard was never activated after a relocation; fall through and finish normally
<i>183</i>&nbsp;                    } catch (final Exception e) {
<i>184</i>&nbsp;                        // fail the primary but fall through and let the rest of operation processing complete
<i>185</i>&nbsp;                        final String message = String.format(Locale.ROOT, &quot;primary failed updating local checkpoint for replica %s&quot;, shard);
<i>186</i>&nbsp;                        primary.failShard(message, e);
<i>187</i>&nbsp;                    }
<i>188</i>&nbsp;                    decPendingAndFinishIfNeeded();
<i>189</i>&nbsp;                }
<i>190</i>&nbsp;
<i>191</i>&nbsp;                @Override
<i>192</i>&nbsp;                public void onFailure(Exception replicaException) {
<i>193</i>&nbsp;                    logger.trace(() -&gt; new ParameterizedMessage(
<i>194</i>&nbsp;                        &quot;[{}] failure while performing [{}] on replica {}, request [{}]&quot;,
<i>195</i>&nbsp;                        shard.shardId(), opType, shard, replicaRequest), replicaException);
<i>196</i>&nbsp;                    // Only report &quot;critical&quot; exceptions - TODO: Reach out to the master node to get the latest shard state then report.
<i>197</i>&nbsp;                    if (TransportActions.isShardNotAvailableException(replicaException) == false) {
<i>198</i>&nbsp;                        RestStatus restStatus = ExceptionsHelper.status(replicaException);
<i>199</i>&nbsp;                        shardReplicaFailures.add(new ReplicationResponse.ShardInfo.Failure(
<i>200</i>&nbsp;                            shard.shardId(), shard.currentNodeId(), replicaException, restStatus, false));
<i>201</i>&nbsp;                    }
<i>202</i>&nbsp;                    String message = String.format(Locale.ROOT, &quot;failed to perform %s on replica %s&quot;, opType, shard);
<i>203</i>&nbsp;                    replicasProxy.failShardIfNeeded(shard, primaryTerm, message, replicaException,
<i>204</i>&nbsp;                        ActionListener.wrap(r -&gt; decPendingAndFinishIfNeeded(), ReplicationOperation.this::onNoLongerPrimary));
<i>205</i>&nbsp;                }
<i>206</i>&nbsp;
<i>207</i>&nbsp;                @Override
<i>208</i>&nbsp;                public String toString() {
<i>209</i>&nbsp;                    return &quot;[&quot; + replicaRequest + &quot;][&quot; + shard + &quot;]&quot;;
<i>210</i>&nbsp;                }
<i>211</i>&nbsp;            });
<i>212</i>&nbsp;    }
<i>213</i>&nbsp;
<i>214</i>&nbsp;    private void onNoLongerPrimary(Exception failure) {
<i>215</i>&nbsp;        final Throwable cause = ExceptionsHelper.unwrapCause(failure);
<i>216</i>&nbsp;        final boolean nodeIsClosing =
<i>217</i>&nbsp;                cause instanceof NodeClosedException
<i>218</i>&nbsp;                        || ExceptionsHelper.isTransportStoppedForAction(cause, &quot;internal:cluster/shard/failure&quot;);
<i>219</i>&nbsp;        final String message;
<i>220</i>&nbsp;        if (nodeIsClosing) {
<i>221</i>&nbsp;            message = String.format(Locale.ROOT,
<i>222</i>&nbsp;                &quot;node with primary [%s] is shutting down while failing replica shard&quot;, primary.routingEntry());
<i>223</i>&nbsp;            // We prefer not to fail the primary to avoid unnecessary warning log
<i>224</i>&nbsp;            // when the node with the primary shard is gracefully shutting down.
<i>225</i>&nbsp;        } else {
<i>226</i>&nbsp;            if (Assertions.ENABLED) {
<i>227</i>&nbsp;                if (failure instanceof ShardStateAction.NoLongerPrimaryShardException == false) {
<i>228</i>&nbsp;                    throw new AssertionError(&quot;unexpected failure&quot;, failure);
<i>229</i>&nbsp;                }
<i>230</i>&nbsp;            }
<i>231</i>&nbsp;            // we are no longer the primary, fail ourselves and start over
<i>232</i>&nbsp;            message = String.format(Locale.ROOT, &quot;primary shard [%s] was demoted while failing replica shard&quot;, primary.routingEntry());
<i>233</i>&nbsp;            primary.failShard(message, failure);
<i>234</i>&nbsp;        }
<i>235</i>&nbsp;        finishAsFailed(new RetryOnPrimaryException(primary.routingEntry().shardId(), message, failure));
<i>236</i>&nbsp;    }
<i>237</i>&nbsp;
<i>238</i>&nbsp;    /**
<i>239</i>&nbsp;     * Checks whether we can perform a write based on the required active shard count setting.
<i>240</i>&nbsp;     * Returns **null* if OK to proceed, or a string describing the reason to stop
<i>241</i>&nbsp;     */
<i>242</i>&nbsp;    protected String checkActiveShardCount() {
<i>243</i>&nbsp;        final ShardId shardId = primary.routingEntry().shardId();
<i>244</i>&nbsp;        final ActiveShardCount waitForActiveShards = request.waitForActiveShards();
<i>245</i>&nbsp;        if (waitForActiveShards == ActiveShardCount.NONE) {
<i>246</i>&nbsp;            return null;  // not waiting for any shards
<i>247</i>&nbsp;        }
<i>248</i>&nbsp;        final IndexShardRoutingTable shardRoutingTable = primary.getReplicationGroup().getRoutingTable();
<i>249</i>&nbsp;        if (waitForActiveShards.enoughShardsActive(shardRoutingTable)) {
<i>250</i>&nbsp;            return null;
<i>251</i>&nbsp;        } else {
<i>252</i>&nbsp;            final String resolvedShards = waitForActiveShards == ActiveShardCount.ALL ? Integer.toString(shardRoutingTable.shards().size())
<i>253</i>&nbsp;                                              : waitForActiveShards.toString();
<i>254</i>&nbsp;            logger.trace(&quot;[{}] not enough active copies to meet shard count of [{}] (have {}, needed {}), scheduling a retry. op [{}], &quot; +
<i>255</i>&nbsp;                         &quot;request [{}]&quot;, shardId, waitForActiveShards, shardRoutingTable.activeShards().size(),
<i>256</i>&nbsp;                         resolvedShards, opType, request);
<i>257</i>&nbsp;            return &quot;Not enough active copies to meet shard count of [&quot; + waitForActiveShards + &quot;] (have &quot; +
<i>258</i>&nbsp;                       shardRoutingTable.activeShards().size() + &quot;, needed &quot; + resolvedShards + &quot;).&quot;;
<i>259</i>&nbsp;        }
<i>260</i>&nbsp;    }
<i>261</i>&nbsp;
<i>262</i>&nbsp;    private void decPendingAndFinishIfNeeded() {
<i>263</i>&nbsp;        assert pendingActions.get() &gt; 0 : &quot;pending action count goes below 0 for request [&quot; + request + &quot;]&quot;;
<i>264</i>&nbsp;        if (pendingActions.decrementAndGet() == 0) {
<i>265</i>&nbsp;            finish();
<i>266</i>&nbsp;        }
<i>267</i>&nbsp;    }
<i>268</i>&nbsp;
<i>269</i>&nbsp;    private void finish() {
<i>270</i>&nbsp;        if (finished.compareAndSet(false, true)) {
<i>271</i>&nbsp;            final ReplicationResponse.ShardInfo.Failure[] failuresArray;
<i>272</i>&nbsp;            if (shardReplicaFailures.isEmpty()) {
<i>273</i>&nbsp;                failuresArray = ReplicationResponse.EMPTY;
<i>274</i>&nbsp;            } else {
<i>275</i>&nbsp;                failuresArray = new ReplicationResponse.ShardInfo.Failure[shardReplicaFailures.size()];
<i>276</i>&nbsp;                shardReplicaFailures.toArray(failuresArray);
<i>277</i>&nbsp;            }
<i>278</i>&nbsp;            primaryResult.setShardInfo(new ReplicationResponse.ShardInfo(
<i>279</i>&nbsp;                    totalShards.get(),
<i>280</i>&nbsp;                    successfulShards.get(),
<i>281</i>&nbsp;                    failuresArray
<i>282</i>&nbsp;                )
<i>283</i>&nbsp;            );
<i>284</i>&nbsp;            resultListener.onResponse(primaryResult);
<i>285</i>&nbsp;        }
<i>286</i>&nbsp;    }
<i>287</i>&nbsp;
<i>288</i>&nbsp;    private void finishAsFailed(Exception exception) {
<i>289</i>&nbsp;        if (finished.compareAndSet(false, true)) {
<i>290</i>&nbsp;            resultListener.onFailure(exception);
<i>291</i>&nbsp;        }
<i>292</i>&nbsp;    }
<i>293</i>&nbsp;
<i>294</i>&nbsp;    /**
<i>295</i>&nbsp;     * An encapsulation of an operation that is to be performed on the primary shard
<i>296</i>&nbsp;     */
<i>297</i>&nbsp;    public interface Primary&lt;
<i>298</i>&nbsp;                RequestT extends ReplicationRequest&lt;RequestT&gt;,
<i>299</i>&nbsp;                ReplicaRequestT extends ReplicationRequest&lt;ReplicaRequestT&gt;,
<i>300</i>&nbsp;                PrimaryResultT extends PrimaryResult&lt;ReplicaRequestT&gt;
<i>301</i>&nbsp;            &gt; {
<i>302</i>&nbsp;
<i>303</i>&nbsp;        /**
<i>304</i>&nbsp;         * routing entry for this primary
<i>305</i>&nbsp;         */
<i>306</i>&nbsp;        ShardRouting routingEntry();
<i>307</i>&nbsp;
<i>308</i>&nbsp;        /**
<i>309</i>&nbsp;         * Fail the primary shard.
<i>310</i>&nbsp;         *
<i>311</i>&nbsp;         * @param message   the failure message
<i>312</i>&nbsp;         * @param exception the exception that triggered the failure
<i>313</i>&nbsp;         */
<i>314</i>&nbsp;        void failShard(String message, Exception exception);
<i>315</i>&nbsp;
<i>316</i>&nbsp;        /**
<i>317</i>&nbsp;         * Performs the given request on this primary. Yes, this returns as soon as it can with the request for the replicas and calls a
<i>318</i>&nbsp;         * listener when the primary request is completed. Yes, the primary request might complete before the method returns. Yes, it might
<i>319</i>&nbsp;         * also complete after. Deal with it.
<i>320</i>&nbsp;         *
<i>321</i>&nbsp;         * @param request the request to perform
<i>322</i>&nbsp;         * @param listener result listener
<i>323</i>&nbsp;         */
<i>324</i>&nbsp;        void perform(RequestT request, ActionListener&lt;PrimaryResultT&gt; listener);
<i>325</i>&nbsp;
<i>326</i>&nbsp;        /**
<i>327</i>&nbsp;         * Notifies the primary of a local checkpoint for the given allocation.
<i>328</i>&nbsp;         *
<i>329</i>&nbsp;         * Note: The primary will use this information to advance the global checkpoint if possible.
<i>330</i>&nbsp;         *
<i>331</i>&nbsp;         * @param allocationId allocation ID of the shard corresponding to the supplied local checkpoint
<i>332</i>&nbsp;         * @param checkpoint the *local* checkpoint for the shard
<i>333</i>&nbsp;         */
<i>334</i>&nbsp;        void updateLocalCheckpointForShard(String allocationId, long checkpoint);
<i>335</i>&nbsp;
<i>336</i>&nbsp;        /**
<i>337</i>&nbsp;         * Update the local knowledge of the global checkpoint for the specified allocation ID.
<i>338</i>&nbsp;         *
<i>339</i>&nbsp;         * @param allocationId     the allocation ID to update the global checkpoint for
<i>340</i>&nbsp;         * @param globalCheckpoint the global checkpoint
<i>341</i>&nbsp;         */
<i>342</i>&nbsp;        void updateGlobalCheckpointForShard(String allocationId, long globalCheckpoint);
<i>343</i>&nbsp;
<i>344</i>&nbsp;        /**
<i>345</i>&nbsp;         * Returns the persisted local checkpoint on the primary shard.
<i>346</i>&nbsp;         *
<i>347</i>&nbsp;         * @return the local checkpoint
<i>348</i>&nbsp;         */
<i>349</i>&nbsp;        long localCheckpoint();
<i>350</i>&nbsp;
<i>351</i>&nbsp;        /**
<i>352</i>&nbsp;         * Returns the global checkpoint computed on the primary shard.
<i>353</i>&nbsp;         *
<i>354</i>&nbsp;         * @return the computed global checkpoint
<i>355</i>&nbsp;         */
<i>356</i>&nbsp;        long computedGlobalCheckpoint();
<i>357</i>&nbsp;
<i>358</i>&nbsp;        /**
<i>359</i>&nbsp;         * Returns the persisted global checkpoint on the primary shard.
<i>360</i>&nbsp;         *
<i>361</i>&nbsp;         * @return the persisted global checkpoint
<i>362</i>&nbsp;         */
<i>363</i>&nbsp;        long globalCheckpoint();
<i>364</i>&nbsp;
<i>365</i>&nbsp;        /**
<i>366</i>&nbsp;         * Returns the maximum seq_no of updates (index operations overwrite Lucene) or deletes on the primary.
<i>367</i>&nbsp;         * This value must be captured after the execution of a replication request on the primary is completed.
<i>368</i>&nbsp;         */
<i>369</i>&nbsp;        long maxSeqNoOfUpdatesOrDeletes();
<i>370</i>&nbsp;
<i>371</i>&nbsp;        /**
<i>372</i>&nbsp;         * Returns the current replication group on the primary shard
<i>373</i>&nbsp;         *
<i>374</i>&nbsp;         * @return the replication group
<i>375</i>&nbsp;         */
<i>376</i>&nbsp;        ReplicationGroup getReplicationGroup();
<i>377</i>&nbsp;    }
<i>378</i>&nbsp;
<i>379</i>&nbsp;    /**
<i>380</i>&nbsp;     * An encapsulation of an operation that will be executed on the replica shards, if present.
<i>381</i>&nbsp;     */
<i>382</i>&nbsp;    public interface Replicas&lt;RequestT extends ReplicationRequest&lt;RequestT&gt;&gt; {
<i>383</i>&nbsp;
<i>384</i>&nbsp;        /**
<i>385</i>&nbsp;         * Performs the specified request on the specified replica.
<i>386</i>&nbsp;         *
<i>387</i>&nbsp;         * @param replica                    the shard this request should be executed on
<i>388</i>&nbsp;         * @param replicaRequest             the operation to perform
<i>389</i>&nbsp;         * @param primaryTerm                the primary term
<i>390</i>&nbsp;         * @param globalCheckpoint           the global checkpoint on the primary
<i>391</i>&nbsp;         * @param maxSeqNoOfUpdatesOrDeletes the max seq_no of updates (index operations overwriting Lucene) or deletes on primary
<i>392</i>&nbsp;         *                                   after this replication was executed on it.
<i>393</i>&nbsp;         * @param listener                   callback for handling the response or failure
<i>394</i>&nbsp;         */
<i>395</i>&nbsp;        void performOn(ShardRouting replica, RequestT replicaRequest,
<i>396</i>&nbsp;                       long primaryTerm, long globalCheckpoint, long maxSeqNoOfUpdatesOrDeletes, ActionListener&lt;ReplicaResponse&gt; listener);
<i>397</i>&nbsp;
<i>398</i>&nbsp;        /**
<i>399</i>&nbsp;         * Fail the specified shard if needed, removing it from the current set
<i>400</i>&nbsp;         * of active shards. Whether a failure is needed is left up to the
<i>401</i>&nbsp;         * implementation.
<i>402</i>&nbsp;         *
<i>403</i>&nbsp;         * @param replica      shard to fail
<i>404</i>&nbsp;         * @param primaryTerm  the primary term
<i>405</i>&nbsp;         * @param message      a (short) description of the reason
<i>406</i>&nbsp;         * @param exception    the original exception which caused the ReplicationOperation to request the shard to be failed
<i>407</i>&nbsp;         * @param listener     a listener that will be notified when the failing shard has been removed from the in-sync set
<i>408</i>&nbsp;         */
<i>409</i>&nbsp;        void failShardIfNeeded(ShardRouting replica, long primaryTerm, String message, Exception exception, ActionListener&lt;Void&gt; listener);
<i>410</i>&nbsp;
<i>411</i>&nbsp;        /**
<i>412</i>&nbsp;         * Marks shard copy as stale if needed, removing its allocation id from
<i>413</i>&nbsp;         * the set of in-sync allocation ids. Whether marking as stale is needed
<i>414</i>&nbsp;         * is left up to the implementation.
<i>415</i>&nbsp;         *
<i>416</i>&nbsp;         * @param shardId      shard id
<i>417</i>&nbsp;         * @param allocationId allocation id to remove from the set of in-sync allocation ids
<i>418</i>&nbsp;         * @param primaryTerm  the primary term
<i>419</i>&nbsp;         * @param listener     a listener that will be notified when the failing shard has been removed from the in-sync set
<i>420</i>&nbsp;         */
<i>421</i>&nbsp;        void markShardCopyAsStaleIfNeeded(ShardId shardId, String allocationId, long primaryTerm, ActionListener&lt;Void&gt; listener);
<i>422</i>&nbsp;    }
<i>423</i>&nbsp;
<i>424</i>&nbsp;    /**
<i>425</i>&nbsp;     * An interface to encapsulate the metadata needed from replica shards when they respond to operations performed on them.
<i>426</i>&nbsp;     */
<i>427</i>&nbsp;    public interface ReplicaResponse {
<i>428</i>&nbsp;
<i>429</i>&nbsp;        /**
<i>430</i>&nbsp;         * The persisted local checkpoint for the shard.
<i>431</i>&nbsp;         *
<i>432</i>&nbsp;         * @return the persisted local checkpoint
<i>433</i>&nbsp;         **/
<i>434</i>&nbsp;        long localCheckpoint();
<i>435</i>&nbsp;
<i>436</i>&nbsp;        /**
<i>437</i>&nbsp;         * The persisted global checkpoint for the shard.
<i>438</i>&nbsp;         *
<i>439</i>&nbsp;         * @return the persisted global checkpoint
<i>440</i>&nbsp;         **/
<i>441</i>&nbsp;        long globalCheckpoint();
<i>442</i>&nbsp;
<i>443</i>&nbsp;    }
<i>444</i>&nbsp;
<i>445</i>&nbsp;    public static class RetryOnPrimaryException extends ElasticsearchException {
<i>446</i>&nbsp;        RetryOnPrimaryException(ShardId shardId, String msg) {
<b class="nc"><i>447</i>&nbsp;            this(shardId, msg, null);</b>
<b class="nc"><i>448</i>&nbsp;        }</b>
<i>449</i>&nbsp;
<i>450</i>&nbsp;        RetryOnPrimaryException(ShardId shardId, String msg, Throwable cause) {
<b class="nc"><i>451</i>&nbsp;            super(msg, cause);</b>
<b class="nc"><i>452</i>&nbsp;            setShard(shardId);</b>
<b class="nc"><i>453</i>&nbsp;        }</b>
<i>454</i>&nbsp;
<i>455</i>&nbsp;        public RetryOnPrimaryException(StreamInput in) throws IOException {
<b class="nc"><i>456</i>&nbsp;            super(in);</b>
<b class="nc"><i>457</i>&nbsp;        }</b>
<i>458</i>&nbsp;    }
<i>459</i>&nbsp;
<i>460</i>&nbsp;    public interface PrimaryResult&lt;RequestT extends ReplicationRequest&lt;RequestT&gt;&gt; {
<i>461</i>&nbsp;
<i>462</i>&nbsp;        /**
<i>463</i>&nbsp;         * @return null if no operation needs to be sent to a replica
<i>464</i>&nbsp;         * (for example when the operation failed on the primary due to a parsing exception)
<i>465</i>&nbsp;         */
<i>466</i>&nbsp;        @Nullable RequestT replicaRequest();
<i>467</i>&nbsp;
<i>468</i>&nbsp;        void setShardInfo(ReplicationResponse.ShardInfo shardInfo);
<i>469</i>&nbsp;    }
<i>470</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-02-09 18:46</div>
</div>
</body>
</html>
