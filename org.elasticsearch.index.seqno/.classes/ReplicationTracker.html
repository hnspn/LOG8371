


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: ReplicationTracker</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">org.elasticsearch.index.seqno</a> ]
</div>

<h1>Coverage Summary for Class: ReplicationTracker (org.elasticsearch.index.seqno)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">ReplicationTracker</td>
<td class="coverageStat">
  <span class="percent">
    33.3%
  </span>
  <span class="absValue">
    (21/ 63)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    29%
  </span>
  <span class="absValue">
    (149/ 514)
  </span>
</td>
</tr>
  <tr>
    <td class="name">ReplicationTracker$CheckpointState</td>
<td class="coverageStat">
  <span class="percent">
    22.2%
  </span>
  <span class="absValue">
    (2/ 9)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    19.4%
  </span>
  <span class="absValue">
    (7/ 36)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>total</strong></td>
<td class="coverageStat">
  <span class="percent">
    31.9%
  </span>
  <span class="absValue">
    (23/ 72)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    28.4%
  </span>
  <span class="absValue">
    (156/ 550)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to Elasticsearch under one or more contributor
<i>3</i>&nbsp; * license agreements. See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright
<i>5</i>&nbsp; * ownership. Elasticsearch licenses this file to you under
<i>6</i>&nbsp; * the Apache License, Version 2.0 (the &quot;License&quot;); you may
<i>7</i>&nbsp; * not use this file except in compliance with the License.
<i>8</i>&nbsp; * You may obtain a copy of the License at
<i>9</i>&nbsp; *
<i>10</i>&nbsp; *    http://www.apache.org/licenses/LICENSE-2.0
<i>11</i>&nbsp; *
<i>12</i>&nbsp; * Unless required by applicable law or agreed to in writing,
<i>13</i>&nbsp; * software distributed under the License is distributed on an
<i>14</i>&nbsp; * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
<i>15</i>&nbsp; * KIND, either express or implied.  See the License for the
<i>16</i>&nbsp; * specific language governing permissions and limitations
<i>17</i>&nbsp; * under the License.
<i>18</i>&nbsp; */
<i>19</i>&nbsp;
<i>20</i>&nbsp;package org.elasticsearch.index.seqno;
<i>21</i>&nbsp;
<i>22</i>&nbsp;import com.carrotsearch.hppc.ObjectLongHashMap;
<i>23</i>&nbsp;import com.carrotsearch.hppc.ObjectLongMap;
<i>24</i>&nbsp;import org.elasticsearch.Version;
<i>25</i>&nbsp;import org.elasticsearch.action.ActionListener;
<i>26</i>&nbsp;import org.elasticsearch.action.support.GroupedActionListener;
<i>27</i>&nbsp;import org.elasticsearch.action.support.replication.ReplicationResponse;
<i>28</i>&nbsp;import org.elasticsearch.cluster.metadata.IndexMetaData;
<i>29</i>&nbsp;import org.elasticsearch.cluster.routing.AllocationId;
<i>30</i>&nbsp;import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
<i>31</i>&nbsp;import org.elasticsearch.cluster.routing.ShardRouting;
<i>32</i>&nbsp;import org.elasticsearch.common.SuppressForbidden;
<i>33</i>&nbsp;import org.elasticsearch.common.collect.Tuple;
<i>34</i>&nbsp;import org.elasticsearch.common.io.stream.StreamInput;
<i>35</i>&nbsp;import org.elasticsearch.common.io.stream.StreamOutput;
<i>36</i>&nbsp;import org.elasticsearch.common.io.stream.Writeable;
<i>37</i>&nbsp;import org.elasticsearch.common.xcontent.NamedXContentRegistry;
<i>38</i>&nbsp;import org.elasticsearch.gateway.WriteStateException;
<i>39</i>&nbsp;import org.elasticsearch.index.IndexSettings;
<i>40</i>&nbsp;import org.elasticsearch.index.engine.SafeCommitInfo;
<i>41</i>&nbsp;import org.elasticsearch.index.shard.AbstractIndexShardComponent;
<i>42</i>&nbsp;import org.elasticsearch.index.shard.IndexShard;
<i>43</i>&nbsp;import org.elasticsearch.index.shard.ReplicationGroup;
<i>44</i>&nbsp;import org.elasticsearch.index.shard.ShardId;
<i>45</i>&nbsp;
<i>46</i>&nbsp;import java.io.IOException;
<i>47</i>&nbsp;import java.nio.file.Path;
<i>48</i>&nbsp;import java.util.Collection;
<i>49</i>&nbsp;import java.util.Collections;
<i>50</i>&nbsp;import java.util.HashMap;
<i>51</i>&nbsp;import java.util.HashSet;
<i>52</i>&nbsp;import java.util.List;
<i>53</i>&nbsp;import java.util.Map;
<i>54</i>&nbsp;import java.util.Objects;
<i>55</i>&nbsp;import java.util.OptionalLong;
<i>56</i>&nbsp;import java.util.Set;
<i>57</i>&nbsp;import java.util.function.BiConsumer;
<i>58</i>&nbsp;import java.util.function.Function;
<i>59</i>&nbsp;import java.util.function.LongConsumer;
<i>60</i>&nbsp;import java.util.function.LongSupplier;
<i>61</i>&nbsp;import java.util.function.Supplier;
<i>62</i>&nbsp;import java.util.function.ToLongFunction;
<i>63</i>&nbsp;import java.util.stream.Collectors;
<i>64</i>&nbsp;import java.util.stream.LongStream;
<i>65</i>&nbsp;import java.util.stream.Stream;
<i>66</i>&nbsp;import java.util.stream.StreamSupport;
<i>67</i>&nbsp;
<i>68</i>&nbsp;/**
<i>69</i>&nbsp; * This class is responsible for tracking the replication group with its progress and safety markers (local and global checkpoints).
<i>70</i>&nbsp; *
<i>71</i>&nbsp; * The global checkpoint is the highest sequence number for which all lower (or equal) sequence number have been processed
<i>72</i>&nbsp; * on all shards that are currently active. Since shards count as &quot;active&quot; when the master starts
<i>73</i>&nbsp; * them, and before this primary shard has been notified of this fact, we also include shards that have completed recovery. These shards
<i>74</i>&nbsp; * have received all old operations via the recovery mechanism and are kept up to date by the various replications actions. The set of
<i>75</i>&nbsp; * shards that are taken into account for the global checkpoint calculation are called the &quot;in-sync shards&quot;.
<i>76</i>&nbsp; * &lt;p&gt;
<i>77</i>&nbsp; * The global checkpoint is maintained by the primary shard and is replicated to all the replicas (via {@link GlobalCheckpointSyncAction}).
<i>78</i>&nbsp; */
<b class="fc"><i>79</i>&nbsp;public class ReplicationTracker extends AbstractIndexShardComponent implements LongSupplier {</b>
<i>80</i>&nbsp;
<i>81</i>&nbsp;    /**
<i>82</i>&nbsp;     * The allocation ID for the shard to which this tracker is a component of.
<i>83</i>&nbsp;     */
<i>84</i>&nbsp;    final String shardAllocationId;
<i>85</i>&nbsp;
<i>86</i>&nbsp;    /**
<i>87</i>&nbsp;     * The global checkpoint tracker can operate in two modes:
<i>88</i>&nbsp;     * - primary: this shard is in charge of collecting local checkpoint information from all shard copies and computing the global
<i>89</i>&nbsp;     *            checkpoint based on the local checkpoints of all in-sync shard copies.
<i>90</i>&nbsp;     * - replica: this shard receives global checkpoint information from the primary (see
<i>91</i>&nbsp;     *   {@link #updateGlobalCheckpointOnReplica(long, String)}).
<i>92</i>&nbsp;     *
<i>93</i>&nbsp;     * When a shard is initialized (be it a primary or replica), it initially operates in replica mode. The global checkpoint tracker is
<i>94</i>&nbsp;     * then switched to primary mode in the following three scenarios:
<i>95</i>&nbsp;     *
<i>96</i>&nbsp;     * - An initializing primary shard that is not a relocation target is moved to primary mode (using {@link #activatePrimaryMode}) once
<i>97</i>&nbsp;     *   the shard becomes active.
<i>98</i>&nbsp;     * - An active replica shard is moved to primary mode (using {@link #activatePrimaryMode}) once it is promoted to primary.
<i>99</i>&nbsp;     * - A primary relocation target is moved to primary mode (using {@link #activateWithPrimaryContext}) during the primary relocation
<i>100</i>&nbsp;     *   handoff. If the target shard is successfully initialized in primary mode, the source shard of a primary relocation is then moved
<i>101</i>&nbsp;     *   to replica mode (using {@link #completeRelocationHandoff}), as the relocation target will be in charge of the global checkpoint
<i>102</i>&nbsp;     *   computation from that point on.
<i>103</i>&nbsp;     */
<i>104</i>&nbsp;    volatile boolean primaryMode;
<i>105</i>&nbsp;
<i>106</i>&nbsp;    /**
<i>107</i>&nbsp;     * The current operation primary term. Management of this value is done through {@link IndexShard} and must only be done when safe. See
<i>108</i>&nbsp;     * {@link #setOperationPrimaryTerm(long)}.
<i>109</i>&nbsp;     */
<i>110</i>&nbsp;    private volatile long operationPrimaryTerm;
<i>111</i>&nbsp;
<i>112</i>&nbsp;    /**
<i>113</i>&nbsp;     * Boolean flag that indicates if a relocation handoff is in progress. A handoff is started by calling
<i>114</i>&nbsp;     * {@link #startRelocationHandoff(String)} and is finished by either calling {@link #completeRelocationHandoff} or
<i>115</i>&nbsp;     * {@link #abortRelocationHandoff}, depending on whether the handoff was successful or not. During the handoff, which has as main
<i>116</i>&nbsp;     * objective to transfer the internal state of the global checkpoint tracker from the relocation source to the target, the list of
<i>117</i>&nbsp;     * in-sync shard copies cannot grow, otherwise the relocation target might miss this information and increase the global checkpoint
<i>118</i>&nbsp;     * to eagerly. As consequence, some of the methods in this class are not allowed to be called while a handoff is in progress,
<i>119</i>&nbsp;     * in particular {@link #markAllocationIdAsInSync}.
<i>120</i>&nbsp;     *
<i>121</i>&nbsp;     * A notable exception to this is the method {@link #updateFromMaster}, which is still allowed to be called during a relocation handoff.
<i>122</i>&nbsp;     * The reason for this is that the handoff might fail and can be aborted (using {@link #abortRelocationHandoff}), in which case
<i>123</i>&nbsp;     * it is important that the global checkpoint tracker does not miss any state updates that might happened during the handoff attempt.
<i>124</i>&nbsp;     * This means, however, that the global checkpoint can still advance after the primary relocation handoff has been initiated, but only
<i>125</i>&nbsp;     * because the master could have failed some of the in-sync shard copies and marked them as stale. That is ok though, as this
<i>126</i>&nbsp;     * information is conveyed through cluster state updates, and the new primary relocation target will also eventually learn about those.
<i>127</i>&nbsp;     */
<i>128</i>&nbsp;    boolean handoffInProgress;
<i>129</i>&nbsp;
<i>130</i>&nbsp;    /**
<i>131</i>&nbsp;     * Boolean flag that indicates whether a relocation handoff completed (see {@link #completeRelocationHandoff}).
<i>132</i>&nbsp;     */
<i>133</i>&nbsp;    volatile boolean relocated;
<i>134</i>&nbsp;
<i>135</i>&nbsp;    /**
<i>136</i>&nbsp;     * The global checkpoint tracker relies on the property that cluster state updates are applied in-order. After transferring a primary
<i>137</i>&nbsp;     * context from the primary relocation source to the target and initializing the target, it is possible for the target to apply a
<i>138</i>&nbsp;     * cluster state that is older than the one upon which the primary context was based. If we allowed this old cluster state
<i>139</i>&nbsp;     * to influence the list of in-sync shard copies here, this could possibly remove such an in-sync copy from the internal structures
<i>140</i>&nbsp;     * until the newer cluster state were to be applied, which would unsafely advance the global checkpoint. This field thus captures
<i>141</i>&nbsp;     * the version of the last applied cluster state to ensure in-order updates.
<i>142</i>&nbsp;     */
<i>143</i>&nbsp;    long appliedClusterStateVersion;
<i>144</i>&nbsp;
<i>145</i>&nbsp;    IndexShardRoutingTable routingTable;
<i>146</i>&nbsp;
<i>147</i>&nbsp;    /**
<i>148</i>&nbsp;     * Local checkpoint information for all shard copies that are tracked. Has an entry for all shard copies that are either initializing
<i>149</i>&nbsp;     * and / or in-sync, possibly also containing information about unassigned in-sync shard copies. The information that is tracked for
<i>150</i>&nbsp;     * each shard copy is explained in the docs for the {@link CheckpointState} class.
<i>151</i>&nbsp;     */
<i>152</i>&nbsp;    final Map&lt;String, CheckpointState&gt; checkpoints;
<i>153</i>&nbsp;
<i>154</i>&nbsp;    /**
<i>155</i>&nbsp;     * The current in-memory global checkpoint. In primary mode, this is a cached version of the checkpoint computed from the local
<i>156</i>&nbsp;     * checkpoints. In replica mode, this is the in-memory global checkpoint that&#39;s communicated by the primary.
<i>157</i>&nbsp;     */
<i>158</i>&nbsp;    volatile long globalCheckpoint;
<i>159</i>&nbsp;
<i>160</i>&nbsp;    /**
<i>161</i>&nbsp;     * A callback invoked when the in-memory global checkpoint is updated. For primary mode this occurs if the computed global checkpoint
<i>162</i>&nbsp;     * advances on the basis of state changes tracked here. For non-primary mode this occurs if the local knowledge of the global checkpoint
<i>163</i>&nbsp;     * advances due to an update from the primary.
<i>164</i>&nbsp;     */
<i>165</i>&nbsp;    private final LongConsumer onGlobalCheckpointUpdated;
<i>166</i>&nbsp;
<i>167</i>&nbsp;    /**
<i>168</i>&nbsp;     * A supplier of the current time. This supplier is used to add a timestamp to retention leases, and to determine retention lease
<i>169</i>&nbsp;     * expiration.
<i>170</i>&nbsp;     */
<i>171</i>&nbsp;    private final LongSupplier currentTimeMillisSupplier;
<i>172</i>&nbsp;
<i>173</i>&nbsp;    /**
<i>174</i>&nbsp;     * A callback when a new retention lease is created or an existing retention lease is removed. In practice, this callback invokes the
<i>175</i>&nbsp;     * retention lease sync action, to sync retention leases to replicas.
<i>176</i>&nbsp;     */
<i>177</i>&nbsp;    private final BiConsumer&lt;RetentionLeases, ActionListener&lt;ReplicationResponse&gt;&gt; onSyncRetentionLeases;
<i>178</i>&nbsp;
<i>179</i>&nbsp;    /**
<i>180</i>&nbsp;     * This set contains allocation IDs for which there is a thread actively waiting for the local checkpoint to advance to at least the
<i>181</i>&nbsp;     * current global checkpoint.
<i>182</i>&nbsp;     */
<i>183</i>&nbsp;    final Set&lt;String&gt; pendingInSync;
<i>184</i>&nbsp;
<i>185</i>&nbsp;    /**
<i>186</i>&nbsp;     * Cached value for the last replication group that was computed
<i>187</i>&nbsp;     */
<i>188</i>&nbsp;    volatile ReplicationGroup replicationGroup;
<i>189</i>&nbsp;
<i>190</i>&nbsp;    /**
<i>191</i>&nbsp;     * The current retention leases.
<i>192</i>&nbsp;     */
<b class="fc"><i>193</i>&nbsp;    private RetentionLeases retentionLeases = RetentionLeases.EMPTY;</b>
<i>194</i>&nbsp;
<i>195</i>&nbsp;    /**
<i>196</i>&nbsp;     * The primary term of the most-recently persisted retention leases. This is used to check if we need to persist the current retention
<i>197</i>&nbsp;     * leases.
<i>198</i>&nbsp;     */
<i>199</i>&nbsp;    private long persistedRetentionLeasesPrimaryTerm;
<i>200</i>&nbsp;
<i>201</i>&nbsp;    /**
<i>202</i>&nbsp;     * The version of the most-recently persisted retention leases. This is used to check if we need to persist the current retention
<i>203</i>&nbsp;     * leases.
<i>204</i>&nbsp;     */
<i>205</i>&nbsp;    private long persistedRetentionLeasesVersion;
<i>206</i>&nbsp;
<i>207</i>&nbsp;    /**
<i>208</i>&nbsp;     * Whether there should be a peer recovery retention lease (PRRL) for every tracked shard copy. Always true on indices created from
<i>209</i>&nbsp;     * {@link Version#V_7_4_0} onwards, because these versions create PRRLs properly. May be false on indices created in an earlier version
<i>210</i>&nbsp;     * if we recently did a rolling upgrade and {@link ReplicationTracker#createMissingPeerRecoveryRetentionLeases(ActionListener)} has not
<i>211</i>&nbsp;     * yet completed. Is only permitted to change from false to true; can be removed once support for pre-PRRL indices is no longer needed.
<i>212</i>&nbsp;     */
<i>213</i>&nbsp;    private boolean hasAllPeerRecoveryRetentionLeases;
<i>214</i>&nbsp;
<i>215</i>&nbsp;    /**
<i>216</i>&nbsp;     * Supplies information about the current safe commit which may be used to expire peer-recovery retention leases.
<i>217</i>&nbsp;     */
<i>218</i>&nbsp;    private final Supplier&lt;SafeCommitInfo&gt; safeCommitInfoSupplier;
<i>219</i>&nbsp;
<i>220</i>&nbsp;    /**
<i>221</i>&nbsp;     * Threshold for expiring peer-recovery retention leases and falling back to file-based recovery. See
<i>222</i>&nbsp;     * {@link IndexSettings#FILE_BASED_RECOVERY_THRESHOLD_SETTING}.
<i>223</i>&nbsp;     */
<i>224</i>&nbsp;    private final double fileBasedRecoveryThreshold;
<i>225</i>&nbsp;
<i>226</i>&nbsp;    /**
<i>227</i>&nbsp;     * Get all retention leases tracked on this shard.
<i>228</i>&nbsp;     *
<i>229</i>&nbsp;     * @return the retention leases
<i>230</i>&nbsp;     */
<i>231</i>&nbsp;    public RetentionLeases getRetentionLeases() {
<b class="nc"><i>232</i>&nbsp;        return getRetentionLeases(false).v2();</b>
<i>233</i>&nbsp;    }
<i>234</i>&nbsp;
<i>235</i>&nbsp;    /**
<i>236</i>&nbsp;     * If the expire leases parameter is false, gets all retention leases tracked on this shard and otherwise first calculates
<i>237</i>&nbsp;     * expiration of existing retention leases, and then gets all non-expired retention leases tracked on this shard. Note that only the
<i>238</i>&nbsp;     * primary shard calculates which leases are expired, and if any have expired, syncs the retention leases to any replicas. If the
<i>239</i>&nbsp;     * expire leases parameter is true, this replication tracker must be in primary mode.
<i>240</i>&nbsp;     *
<i>241</i>&nbsp;     * @return a tuple indicating whether or not any retention leases were expired, and the non-expired retention leases
<i>242</i>&nbsp;     */
<i>243</i>&nbsp;    public synchronized Tuple&lt;Boolean, RetentionLeases&gt; getRetentionLeases(final boolean expireLeases) {
<b class="fc"><i>244</i>&nbsp;        if (expireLeases == false) {</b>
<b class="fc"><i>245</i>&nbsp;            return Tuple.tuple(false, retentionLeases);</b>
<i>246</i>&nbsp;        }
<b class="nc"><i>247</i>&nbsp;        assert primaryMode;</b>
<i>248</i>&nbsp;        // the primary calculates the non-expired retention leases and syncs them to replicas
<b class="nc"><i>249</i>&nbsp;        final long currentTimeMillis = currentTimeMillisSupplier.getAsLong();</b>
<b class="nc"><i>250</i>&nbsp;        final long retentionLeaseMillis = indexSettings.getRetentionLeaseMillis();</b>
<b class="nc"><i>251</i>&nbsp;        final Set&lt;String&gt; leaseIdsForCurrentPeers</b>
<b class="nc"><i>252</i>&nbsp;            = routingTable.assignedShards().stream().map(ReplicationTracker::getPeerRecoveryRetentionLeaseId).collect(Collectors.toSet());</b>
<b class="nc"><i>253</i>&nbsp;        final boolean allShardsStarted = routingTable.allShardsStarted();</b>
<b class="nc"><i>254</i>&nbsp;        final long minimumReasonableRetainedSeqNo = allShardsStarted ? 0L : getMinimumReasonableRetainedSeqNo();</b>
<b class="nc"><i>255</i>&nbsp;        final Map&lt;Boolean, List&lt;RetentionLease&gt;&gt; partitionByExpiration = retentionLeases</b>
<b class="nc"><i>256</i>&nbsp;                .leases()</b>
<b class="nc"><i>257</i>&nbsp;                .stream()</b>
<b class="nc"><i>258</i>&nbsp;                .collect(Collectors.groupingBy(lease -&gt; {</b>
<b class="nc"><i>259</i>&nbsp;                    if (lease.source().equals(PEER_RECOVERY_RETENTION_LEASE_SOURCE)) {</b>
<b class="nc"><i>260</i>&nbsp;                        if (leaseIdsForCurrentPeers.contains(lease.id())) {</b>
<b class="nc"><i>261</i>&nbsp;                            return false;</b>
<i>262</i>&nbsp;                        }
<b class="nc"><i>263</i>&nbsp;                        if (allShardsStarted) {</b>
<b class="nc"><i>264</i>&nbsp;                            logger.trace(&quot;expiring unused [{}]&quot;, lease);</b>
<b class="nc"><i>265</i>&nbsp;                            return true;</b>
<i>266</i>&nbsp;                        }
<b class="nc"><i>267</i>&nbsp;                        if (lease.retainingSequenceNumber() &lt; minimumReasonableRetainedSeqNo) {</b>
<b class="nc"><i>268</i>&nbsp;                            logger.trace(&quot;expiring unreasonable [{}] retaining history before [{}]&quot;, lease, minimumReasonableRetainedSeqNo);</b>
<b class="nc"><i>269</i>&nbsp;                            return true;</b>
<i>270</i>&nbsp;                        }
<i>271</i>&nbsp;                    }
<b class="nc"><i>272</i>&nbsp;                    return currentTimeMillis - lease.timestamp() &gt; retentionLeaseMillis;</b>
<i>273</i>&nbsp;                }));
<b class="nc"><i>274</i>&nbsp;        final Collection&lt;RetentionLease&gt; expiredLeases = partitionByExpiration.get(true);</b>
<b class="nc"><i>275</i>&nbsp;        if (expiredLeases == null) {</b>
<i>276</i>&nbsp;            // early out as no retention leases have expired
<b class="nc"><i>277</i>&nbsp;            logger.debug(&quot;no retention leases are expired from current retention leases [{}]&quot;, retentionLeases);</b>
<b class="nc"><i>278</i>&nbsp;            return Tuple.tuple(false, retentionLeases);</b>
<i>279</i>&nbsp;        }
<i>280</i>&nbsp;        final Collection&lt;RetentionLease&gt; nonExpiredLeases =
<b class="nc"><i>281</i>&nbsp;                partitionByExpiration.get(false) != null ? partitionByExpiration.get(false) : Collections.emptyList();</b>
<b class="nc"><i>282</i>&nbsp;        logger.debug(&quot;expiring retention leases [{}] from current retention leases [{}]&quot;, expiredLeases, retentionLeases);</b>
<b class="nc"><i>283</i>&nbsp;        retentionLeases = new RetentionLeases(operationPrimaryTerm, retentionLeases.version() + 1, nonExpiredLeases);</b>
<b class="nc"><i>284</i>&nbsp;        return Tuple.tuple(true, retentionLeases);</b>
<i>285</i>&nbsp;    }
<i>286</i>&nbsp;
<i>287</i>&nbsp;    private long getMinimumReasonableRetainedSeqNo() {
<b class="nc"><i>288</i>&nbsp;        final SafeCommitInfo safeCommitInfo = safeCommitInfoSupplier.get();</b>
<b class="nc"><i>289</i>&nbsp;        return safeCommitInfo.localCheckpoint + 1 - Math.round(Math.ceil(safeCommitInfo.docCount * fileBasedRecoveryThreshold));</b>
<i>290</i>&nbsp;        // NB safeCommitInfo.docCount is a very low-level count of the docs in the index, and in particular if this shard contains nested
<i>291</i>&nbsp;        // docs then safeCommitInfo.docCount counts every child doc separately from the parent doc. However every part of a nested document
<i>292</i>&nbsp;        // has the same seqno, so we may be overestimating the cost of a file-based recovery when compared to an ops-based recovery and
<i>293</i>&nbsp;        // therefore preferring ops-based recoveries inappropriately in this case. Correctly accounting for nested docs seems difficult to
<i>294</i>&nbsp;        // do cheaply, and the circumstances in which this matters should be relatively rare, so we use this naive calculation regardless.
<i>295</i>&nbsp;        // TODO improve this measure for when nested docs are in use
<i>296</i>&nbsp;    }
<i>297</i>&nbsp;
<i>298</i>&nbsp;    /**
<i>299</i>&nbsp;     * Adds a new retention lease.
<i>300</i>&nbsp;     *
<i>301</i>&nbsp;     * @param id                      the identifier of the retention lease
<i>302</i>&nbsp;     * @param retainingSequenceNumber the retaining sequence number
<i>303</i>&nbsp;     * @param source                  the source of the retention lease
<i>304</i>&nbsp;     * @param listener                the callback when the retention lease is successfully added and synced to replicas
<i>305</i>&nbsp;     * @return the new retention lease
<i>306</i>&nbsp;     * @throws RetentionLeaseAlreadyExistsException if the specified retention lease already exists
<i>307</i>&nbsp;     */
<i>308</i>&nbsp;    public RetentionLease addRetentionLease(
<i>309</i>&nbsp;            final String id,
<i>310</i>&nbsp;            final long retainingSequenceNumber,
<i>311</i>&nbsp;            final String source,
<i>312</i>&nbsp;            final ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>313</i>&nbsp;        Objects.requireNonNull(listener);</b>
<i>314</i>&nbsp;        final RetentionLease retentionLease;
<i>315</i>&nbsp;        final RetentionLeases currentRetentionLeases;
<b class="nc"><i>316</i>&nbsp;        synchronized (this) {</b>
<b class="nc"><i>317</i>&nbsp;            retentionLease = innerAddRetentionLease(id, retainingSequenceNumber, source);</b>
<b class="nc"><i>318</i>&nbsp;            currentRetentionLeases = retentionLeases;</b>
<b class="nc"><i>319</i>&nbsp;        }</b>
<b class="nc"><i>320</i>&nbsp;        onSyncRetentionLeases.accept(currentRetentionLeases, listener);</b>
<b class="nc"><i>321</i>&nbsp;        return retentionLease;</b>
<i>322</i>&nbsp;    }
<i>323</i>&nbsp;
<i>324</i>&nbsp;    /**
<i>325</i>&nbsp;     * Atomically clones an existing retention lease to a new ID.
<i>326</i>&nbsp;     *
<i>327</i>&nbsp;     * @param sourceLeaseId the identifier of the source retention lease
<i>328</i>&nbsp;     * @param targetLeaseId the identifier of the retention lease to create
<i>329</i>&nbsp;     * @param listener      the callback when the retention lease is successfully added and synced to replicas
<i>330</i>&nbsp;     * @return the new retention lease
<i>331</i>&nbsp;     * @throws RetentionLeaseNotFoundException      if the specified source retention lease does not exist
<i>332</i>&nbsp;     * @throws RetentionLeaseAlreadyExistsException if the specified target retention lease already exists
<i>333</i>&nbsp;     */
<i>334</i>&nbsp;    RetentionLease cloneRetentionLease(String sourceLeaseId, String targetLeaseId, ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>335</i>&nbsp;        Objects.requireNonNull(listener);</b>
<i>336</i>&nbsp;        final RetentionLease retentionLease;
<i>337</i>&nbsp;        final RetentionLeases currentRetentionLeases;
<b class="nc"><i>338</i>&nbsp;        synchronized (this) {</b>
<b class="nc"><i>339</i>&nbsp;            assert primaryMode;</b>
<b class="nc"><i>340</i>&nbsp;            if (getRetentionLeases().contains(sourceLeaseId) == false) {</b>
<b class="nc"><i>341</i>&nbsp;                throw new RetentionLeaseNotFoundException(sourceLeaseId);</b>
<i>342</i>&nbsp;            }
<b class="nc"><i>343</i>&nbsp;            final RetentionLease sourceLease = getRetentionLeases().get(sourceLeaseId);</b>
<b class="nc"><i>344</i>&nbsp;            retentionLease = innerAddRetentionLease(targetLeaseId, sourceLease.retainingSequenceNumber(), sourceLease.source());</b>
<b class="nc"><i>345</i>&nbsp;            currentRetentionLeases = retentionLeases;</b>
<b class="nc"><i>346</i>&nbsp;        }</b>
<i>347</i>&nbsp;
<i>348</i>&nbsp;        // Syncing here may not be strictly necessary, because this new lease isn&#39;t retaining any extra history that wasn&#39;t previously
<i>349</i>&nbsp;        // retained by the source lease; however we prefer to sync anyway since we expect to do so whenever creating a new lease.
<b class="nc"><i>350</i>&nbsp;        onSyncRetentionLeases.accept(currentRetentionLeases, listener);</b>
<b class="nc"><i>351</i>&nbsp;        return retentionLease;</b>
<i>352</i>&nbsp;    }
<i>353</i>&nbsp;
<i>354</i>&nbsp;    /**
<i>355</i>&nbsp;     * Adds a new retention lease, but does not synchronise it with the rest of the replication group.
<i>356</i>&nbsp;     *
<i>357</i>&nbsp;     * @param id                      the identifier of the retention lease
<i>358</i>&nbsp;     * @param retainingSequenceNumber the retaining sequence number
<i>359</i>&nbsp;     * @param source                  the source of the retention lease
<i>360</i>&nbsp;     * @return the new retention lease
<i>361</i>&nbsp;     * @throws RetentionLeaseAlreadyExistsException if the specified retention lease already exists
<i>362</i>&nbsp;     */
<i>363</i>&nbsp;    private RetentionLease innerAddRetentionLease(String id, long retainingSequenceNumber, String source) {
<b class="nc"><i>364</i>&nbsp;        assert Thread.holdsLock(this);</b>
<b class="nc"><i>365</i>&nbsp;        assert primaryMode : id + &quot;/&quot; + retainingSequenceNumber + &quot;/&quot; + source;</b>
<b class="nc"><i>366</i>&nbsp;        if (retentionLeases.contains(id)) {</b>
<b class="nc"><i>367</i>&nbsp;            throw new RetentionLeaseAlreadyExistsException(id);</b>
<i>368</i>&nbsp;        }
<b class="nc"><i>369</i>&nbsp;        final RetentionLease retentionLease</b>
<b class="nc"><i>370</i>&nbsp;            = new RetentionLease(id, retainingSequenceNumber, currentTimeMillisSupplier.getAsLong(), source);</b>
<b class="nc"><i>371</i>&nbsp;        logger.debug(&quot;adding new retention lease [{}] to current retention leases [{}]&quot;, retentionLease, retentionLeases);</b>
<b class="nc"><i>372</i>&nbsp;        retentionLeases = new RetentionLeases(</b>
<i>373</i>&nbsp;                operationPrimaryTerm,
<b class="nc"><i>374</i>&nbsp;                retentionLeases.version() + 1,</b>
<b class="nc"><i>375</i>&nbsp;                Stream.concat(retentionLeases.leases().stream(), Stream.of(retentionLease)).collect(Collectors.toList()));</b>
<b class="nc"><i>376</i>&nbsp;        return retentionLease;</b>
<i>377</i>&nbsp;    }
<i>378</i>&nbsp;
<i>379</i>&nbsp;    /**
<i>380</i>&nbsp;     * Renews an existing retention lease.
<i>381</i>&nbsp;     *
<i>382</i>&nbsp;     * @param id                      the identifier of the retention lease
<i>383</i>&nbsp;     * @param retainingSequenceNumber the retaining sequence number
<i>384</i>&nbsp;     * @param source                  the source of the retention lease
<i>385</i>&nbsp;     * @return the renewed retention lease
<i>386</i>&nbsp;     * @throws RetentionLeaseNotFoundException              if the specified retention lease does not exist
<i>387</i>&nbsp;     * @throws RetentionLeaseInvalidRetainingSeqNoException if the new retaining sequence number is lower than
<i>388</i>&nbsp;     *                                                      the retaining sequence number of the current retention lease.
<i>389</i>&nbsp;     */
<i>390</i>&nbsp;    public synchronized RetentionLease renewRetentionLease(final String id, final long retainingSequenceNumber, final String source) {
<b class="nc"><i>391</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>392</i>&nbsp;        final RetentionLease existingRetentionLease = retentionLeases.get(id);</b>
<b class="nc"><i>393</i>&nbsp;        if (existingRetentionLease == null) {</b>
<b class="nc"><i>394</i>&nbsp;            throw new RetentionLeaseNotFoundException(id);</b>
<i>395</i>&nbsp;        }
<b class="nc"><i>396</i>&nbsp;        if (retainingSequenceNumber &lt; existingRetentionLease.retainingSequenceNumber()) {</b>
<b class="nc"><i>397</i>&nbsp;            assert PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(source) == false :</b>
<i>398</i>&nbsp;                &quot;renewing peer recovery retention lease [&quot; + existingRetentionLease + &quot;]&quot; +
<i>399</i>&nbsp;                    &quot; with a lower retaining sequence number [&quot; + retainingSequenceNumber + &quot;]&quot;;
<b class="nc"><i>400</i>&nbsp;            throw new RetentionLeaseInvalidRetainingSeqNoException(id, source, retainingSequenceNumber, existingRetentionLease);</b>
<i>401</i>&nbsp;        }
<b class="nc"><i>402</i>&nbsp;        final RetentionLease retentionLease =</b>
<b class="nc"><i>403</i>&nbsp;            new RetentionLease(id, retainingSequenceNumber, currentTimeMillisSupplier.getAsLong(), source);</b>
<b class="nc"><i>404</i>&nbsp;        retentionLeases = new RetentionLeases(</b>
<i>405</i>&nbsp;                operationPrimaryTerm,
<b class="nc"><i>406</i>&nbsp;                retentionLeases.version() + 1,</b>
<b class="nc"><i>407</i>&nbsp;                Stream.concat(</b>
<b class="nc"><i>408</i>&nbsp;                        retentionLeases.leases().stream().filter(lease -&gt; lease.id().equals(id) == false),</b>
<b class="nc"><i>409</i>&nbsp;                        Stream.of(retentionLease))</b>
<b class="nc"><i>410</i>&nbsp;                        .collect(Collectors.toList()));</b>
<b class="nc"><i>411</i>&nbsp;        return retentionLease;</b>
<i>412</i>&nbsp;    }
<i>413</i>&nbsp;
<i>414</i>&nbsp;    /**
<i>415</i>&nbsp;     * Removes an existing retention lease.
<i>416</i>&nbsp;     *
<i>417</i>&nbsp;     * @param id       the identifier of the retention lease
<i>418</i>&nbsp;     * @param listener the callback when the retention lease is successfully removed and synced to replicas
<i>419</i>&nbsp;     */
<i>420</i>&nbsp;    public void removeRetentionLease(final String id, final ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>421</i>&nbsp;        Objects.requireNonNull(listener);</b>
<i>422</i>&nbsp;        final RetentionLeases currentRetentionLeases;
<b class="nc"><i>423</i>&nbsp;        synchronized (this) {</b>
<b class="nc"><i>424</i>&nbsp;            assert primaryMode;</b>
<b class="nc"><i>425</i>&nbsp;            if (retentionLeases.contains(id) == false) {</b>
<b class="nc"><i>426</i>&nbsp;                throw new RetentionLeaseNotFoundException(id);</b>
<i>427</i>&nbsp;            }
<b class="nc"><i>428</i>&nbsp;            logger.debug(&quot;removing retention lease [{}] from current retention leases [{}]&quot;, id, retentionLeases);</b>
<b class="nc"><i>429</i>&nbsp;            retentionLeases = new RetentionLeases(</b>
<i>430</i>&nbsp;                    operationPrimaryTerm,
<b class="nc"><i>431</i>&nbsp;                    retentionLeases.version() + 1,</b>
<b class="nc"><i>432</i>&nbsp;                    retentionLeases.leases().stream().filter(lease -&gt; lease.id().equals(id) == false).collect(Collectors.toList()));</b>
<b class="nc"><i>433</i>&nbsp;            currentRetentionLeases = retentionLeases;</b>
<b class="nc"><i>434</i>&nbsp;        }</b>
<b class="nc"><i>435</i>&nbsp;        onSyncRetentionLeases.accept(currentRetentionLeases, listener);</b>
<b class="nc"><i>436</i>&nbsp;    }</b>
<i>437</i>&nbsp;
<i>438</i>&nbsp;    /**
<i>439</i>&nbsp;     * Updates retention leases on a replica.
<i>440</i>&nbsp;     *
<i>441</i>&nbsp;     * @param retentionLeases the retention leases
<i>442</i>&nbsp;     */
<i>443</i>&nbsp;    public synchronized void updateRetentionLeasesOnReplica(final RetentionLeases retentionLeases) {
<b class="fc"><i>444</i>&nbsp;        assert primaryMode == false;</b>
<b class="fc"><i>445</i>&nbsp;        if (retentionLeases.supersedes(this.retentionLeases)) {</b>
<b class="nc"><i>446</i>&nbsp;            this.retentionLeases = retentionLeases;</b>
<i>447</i>&nbsp;        }
<b class="fc"><i>448</i>&nbsp;    }</b>
<i>449</i>&nbsp;
<i>450</i>&nbsp;    /**
<i>451</i>&nbsp;     * Loads the latest retention leases from their dedicated state file.
<i>452</i>&nbsp;     *
<i>453</i>&nbsp;     * @param path the path to the directory containing the state file
<i>454</i>&nbsp;     * @return the retention leases
<i>455</i>&nbsp;     * @throws IOException if an I/O exception occurs reading the retention leases
<i>456</i>&nbsp;     */
<i>457</i>&nbsp;    public RetentionLeases loadRetentionLeases(final Path path) throws IOException {
<i>458</i>&nbsp;        final RetentionLeases retentionLeases;
<b class="fc"><i>459</i>&nbsp;        synchronized (retentionLeasePersistenceLock) {</b>
<b class="fc"><i>460</i>&nbsp;            retentionLeases = RetentionLeases.FORMAT.loadLatestState(logger, NamedXContentRegistry.EMPTY, path);</b>
<b class="fc"><i>461</i>&nbsp;        }</b>
<i>462</i>&nbsp;
<i>463</i>&nbsp;        // TODO after backporting we expect this never to happen in 8.x, so adjust this to throw an exception instead.
<b class="fc"><i>464</i>&nbsp;        assert Version.CURRENT.major &lt;= 8 : &quot;throw an exception instead of returning EMPTY on null&quot;;</b>
<b class="fc"><i>465</i>&nbsp;        if (retentionLeases == null) {</b>
<b class="nc"><i>466</i>&nbsp;            return RetentionLeases.EMPTY;</b>
<i>467</i>&nbsp;        }
<b class="fc"><i>468</i>&nbsp;        return retentionLeases;</b>
<i>469</i>&nbsp;    }
<i>470</i>&nbsp;
<b class="fc"><i>471</i>&nbsp;    private final Object retentionLeasePersistenceLock = new Object();</b>
<i>472</i>&nbsp;
<i>473</i>&nbsp;    /**
<i>474</i>&nbsp;     * Persists the current retention leases to their dedicated state file. If this version of the retention leases are already persisted
<i>475</i>&nbsp;     * then persistence is skipped.
<i>476</i>&nbsp;     *
<i>477</i>&nbsp;     * @param path the path to the directory containing the state file
<i>478</i>&nbsp;     * @throws WriteStateException if an exception occurs writing the state file
<i>479</i>&nbsp;     */
<i>480</i>&nbsp;    public void persistRetentionLeases(final Path path) throws WriteStateException {
<b class="fc"><i>481</i>&nbsp;        synchronized (retentionLeasePersistenceLock) {</b>
<i>482</i>&nbsp;            final RetentionLeases currentRetentionLeases;
<b class="fc"><i>483</i>&nbsp;            synchronized (this) {</b>
<b class="fc"><i>484</i>&nbsp;                if (retentionLeases.supersedes(persistedRetentionLeasesPrimaryTerm, persistedRetentionLeasesVersion) == false) {</b>
<b class="nc"><i>485</i>&nbsp;                    logger.trace(&quot;skipping persisting retention leases [{}], already persisted&quot;, retentionLeases);</b>
<b class="nc"><i>486</i>&nbsp;                    return;</b>
<i>487</i>&nbsp;                }
<b class="fc"><i>488</i>&nbsp;                currentRetentionLeases = retentionLeases;</b>
<b class="fc"><i>489</i>&nbsp;            }</b>
<b class="fc"><i>490</i>&nbsp;            logger.trace(&quot;persisting retention leases [{}]&quot;, currentRetentionLeases);</b>
<b class="fc"><i>491</i>&nbsp;            RetentionLeases.FORMAT.writeAndCleanup(currentRetentionLeases, path);</b>
<b class="fc"><i>492</i>&nbsp;            persistedRetentionLeasesPrimaryTerm = currentRetentionLeases.primaryTerm();</b>
<b class="fc"><i>493</i>&nbsp;            persistedRetentionLeasesVersion = currentRetentionLeases.version();</b>
<b class="fc"><i>494</i>&nbsp;        }</b>
<b class="fc"><i>495</i>&nbsp;    }</b>
<i>496</i>&nbsp;
<i>497</i>&nbsp;    public boolean assertRetentionLeasesPersisted(final Path path) throws IOException {
<b class="nc"><i>498</i>&nbsp;        assert RetentionLeases.FORMAT.loadLatestState(logger, NamedXContentRegistry.EMPTY, path) != null;</b>
<b class="nc"><i>499</i>&nbsp;        return true;</b>
<i>500</i>&nbsp;    }
<i>501</i>&nbsp;
<i>502</i>&nbsp;
<i>503</i>&nbsp;    /**
<i>504</i>&nbsp;     * Retention leases for peer recovery have source {@link ReplicationTracker#PEER_RECOVERY_RETENTION_LEASE_SOURCE}, a lease ID
<i>505</i>&nbsp;     * containing the persistent node ID calculated by {@link ReplicationTracker#getPeerRecoveryRetentionLeaseId}, and retain operations
<i>506</i>&nbsp;     * with sequence numbers strictly greater than the given global checkpoint.
<i>507</i>&nbsp;     */
<i>508</i>&nbsp;    public RetentionLease addPeerRecoveryRetentionLease(String nodeId, long globalCheckpoint,
<i>509</i>&nbsp;                                                        ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>510</i>&nbsp;        return addRetentionLease(getPeerRecoveryRetentionLeaseId(nodeId), globalCheckpoint + 1,</b>
<i>511</i>&nbsp;            PEER_RECOVERY_RETENTION_LEASE_SOURCE, listener);
<i>512</i>&nbsp;    }
<i>513</i>&nbsp;
<i>514</i>&nbsp;    public RetentionLease cloneLocalPeerRecoveryRetentionLease(String nodeId, ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>515</i>&nbsp;        return cloneRetentionLease(</b>
<b class="nc"><i>516</i>&nbsp;            getPeerRecoveryRetentionLeaseId(routingTable.primaryShard()),</b>
<b class="nc"><i>517</i>&nbsp;            getPeerRecoveryRetentionLeaseId(nodeId), listener);</b>
<i>518</i>&nbsp;    }
<i>519</i>&nbsp;
<i>520</i>&nbsp;    public void removePeerRecoveryRetentionLease(String nodeId, ActionListener&lt;ReplicationResponse&gt; listener) {
<b class="nc"><i>521</i>&nbsp;        removeRetentionLease(getPeerRecoveryRetentionLeaseId(nodeId), listener);</b>
<b class="nc"><i>522</i>&nbsp;    }</b>
<i>523</i>&nbsp;
<i>524</i>&nbsp;    /**
<i>525</i>&nbsp;     * Source for peer recovery retention leases; see {@link ReplicationTracker#addPeerRecoveryRetentionLease}.
<i>526</i>&nbsp;     */
<i>527</i>&nbsp;    public static final String PEER_RECOVERY_RETENTION_LEASE_SOURCE = &quot;peer recovery&quot;;
<i>528</i>&nbsp;
<i>529</i>&nbsp;    /**
<i>530</i>&nbsp;     * Id for a peer recovery retention lease for the given node. See {@link ReplicationTracker#addPeerRecoveryRetentionLease}.
<i>531</i>&nbsp;     */
<i>532</i>&nbsp;    public static String getPeerRecoveryRetentionLeaseId(String nodeId) {
<b class="nc"><i>533</i>&nbsp;        return &quot;peer_recovery/&quot; + nodeId;</b>
<i>534</i>&nbsp;    }
<i>535</i>&nbsp;
<i>536</i>&nbsp;    /**
<i>537</i>&nbsp;     * Id for a peer recovery retention lease for the given {@link ShardRouting}.
<i>538</i>&nbsp;     * See {@link ReplicationTracker#addPeerRecoveryRetentionLease}.
<i>539</i>&nbsp;     */
<i>540</i>&nbsp;    public static String getPeerRecoveryRetentionLeaseId(ShardRouting shardRouting) {
<b class="nc"><i>541</i>&nbsp;        return getPeerRecoveryRetentionLeaseId(shardRouting.currentNodeId());</b>
<i>542</i>&nbsp;    }
<i>543</i>&nbsp;
<i>544</i>&nbsp;    /**
<i>545</i>&nbsp;     * Returns a list of peer recovery retention leases installed in this replication group
<i>546</i>&nbsp;     */
<i>547</i>&nbsp;    public List&lt;RetentionLease&gt; getPeerRecoveryRetentionLeases() {
<b class="nc"><i>548</i>&nbsp;        return getRetentionLeases().leases().stream()</b>
<b class="nc"><i>549</i>&nbsp;            .filter(lease -&gt; PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(lease.source()))</b>
<b class="nc"><i>550</i>&nbsp;            .collect(Collectors.toList());</b>
<i>551</i>&nbsp;    }
<i>552</i>&nbsp;
<i>553</i>&nbsp;    /**
<i>554</i>&nbsp;     * Advance the peer-recovery retention leases for all assigned shard copies to discard history below the corresponding global
<i>555</i>&nbsp;     * checkpoint, and renew any leases that are approaching expiry.
<i>556</i>&nbsp;     */
<i>557</i>&nbsp;    public synchronized void renewPeerRecoveryRetentionLeases() {
<b class="nc"><i>558</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>559</i>&nbsp;        assert invariant();</b>
<i>560</i>&nbsp;
<i>561</i>&nbsp;        /*
<i>562</i>&nbsp;         * Peer-recovery retention leases never expire while the associated shard is assigned, but we must still renew them occasionally in
<i>563</i>&nbsp;         * case the associated shard is temporarily unassigned. However we must not renew them too often, since each renewal must be
<i>564</i>&nbsp;         * persisted and the resulting IO can be expensive on nodes with large numbers of shards (see #42299). We choose to renew them after
<i>565</i>&nbsp;         * half the expiry time, so that by default the cluster has at least 6 hours to recover before these leases start to expire.
<i>566</i>&nbsp;         */
<b class="nc"><i>567</i>&nbsp;        final long renewalTimeMillis = currentTimeMillisSupplier.getAsLong() - indexSettings.getRetentionLeaseMillis() / 2;</b>
<i>568</i>&nbsp;
<i>569</i>&nbsp;        /*
<i>570</i>&nbsp;         * If any of the peer-recovery retention leases need renewal, it&#39;s a good opportunity to renew them all.
<i>571</i>&nbsp;         */
<b class="nc"><i>572</i>&nbsp;        final boolean renewalNeeded = StreamSupport.stream(routingTable.spliterator(), false).filter(ShardRouting::assignedToNode)</b>
<b class="nc"><i>573</i>&nbsp;            .anyMatch(shardRouting -&gt; {</b>
<b class="nc"><i>574</i>&nbsp;                final RetentionLease retentionLease = retentionLeases.get(getPeerRecoveryRetentionLeaseId(shardRouting));</b>
<b class="nc"><i>575</i>&nbsp;                if (retentionLease == null) {</b>
<i>576</i>&nbsp;                    /*
<i>577</i>&nbsp;                     * If this shard copy is tracked then we got here here via a rolling upgrade from an older version that doesn&#39;t
<i>578</i>&nbsp;                     * create peer recovery retention leases for every shard copy.
<i>579</i>&nbsp;                     */
<b class="nc"><i>580</i>&nbsp;                    assert checkpoints.get(shardRouting.allocationId().getId()).tracked == false</b>
<i>581</i>&nbsp;                        || hasAllPeerRecoveryRetentionLeases == false;
<b class="nc"><i>582</i>&nbsp;                    return false;</b>
<i>583</i>&nbsp;                }
<b class="nc"><i>584</i>&nbsp;                return retentionLease.timestamp() &lt;= renewalTimeMillis</b>
<b class="nc"><i>585</i>&nbsp;                    || retentionLease.retainingSequenceNumber() &lt;= checkpoints.get(shardRouting.allocationId().getId()).globalCheckpoint;</b>
<i>586</i>&nbsp;            });
<i>587</i>&nbsp;
<b class="nc"><i>588</i>&nbsp;        if (renewalNeeded) {</b>
<b class="nc"><i>589</i>&nbsp;            for (ShardRouting shardRouting : routingTable) {</b>
<b class="nc"><i>590</i>&nbsp;                if (shardRouting.assignedToNode()) {</b>
<b class="nc"><i>591</i>&nbsp;                    final RetentionLease retentionLease = retentionLeases.get(getPeerRecoveryRetentionLeaseId(shardRouting));</b>
<b class="nc"><i>592</i>&nbsp;                    if (retentionLease != null) {</b>
<b class="nc"><i>593</i>&nbsp;                        final CheckpointState checkpointState = checkpoints.get(shardRouting.allocationId().getId());</b>
<b class="nc"><i>594</i>&nbsp;                        final long newRetainedSequenceNumber = Math.max(0L, checkpointState.globalCheckpoint + 1L);</b>
<b class="nc"><i>595</i>&nbsp;                        if (retentionLease.retainingSequenceNumber() &lt;= newRetainedSequenceNumber) {</b>
<b class="nc"><i>596</i>&nbsp;                            renewRetentionLease(getPeerRecoveryRetentionLeaseId(shardRouting), newRetainedSequenceNumber,</b>
<i>597</i>&nbsp;                                PEER_RECOVERY_RETENTION_LEASE_SOURCE);
<i>598</i>&nbsp;                        } else {
<i>599</i>&nbsp;                            // the retention lease is tied to the node, not the shard copy, so it&#39;s possible a copy was removed and now
<i>600</i>&nbsp;                            // we are in the process of recovering it again, or maybe we were just promoted and have not yet received the
<i>601</i>&nbsp;                            // global checkpoints from our peers.
<b class="nc"><i>602</i>&nbsp;                            assert checkpointState.globalCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO :</b>
<i>603</i>&nbsp;                                &quot;cannot renew &quot; + retentionLease + &quot; according to &quot; + checkpointState + &quot; for &quot; + shardRouting;
<i>604</i>&nbsp;                        }
<i>605</i>&nbsp;                    }
<i>606</i>&nbsp;                }
<b class="nc"><i>607</i>&nbsp;            }</b>
<i>608</i>&nbsp;        }
<i>609</i>&nbsp;
<b class="nc"><i>610</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>611</i>&nbsp;    }</b>
<i>612</i>&nbsp;
<i>613</i>&nbsp;    public static class CheckpointState implements Writeable {
<i>614</i>&nbsp;
<i>615</i>&nbsp;        /**
<i>616</i>&nbsp;         * the last local checkpoint information that we have for this shard. All operations up to this point are properly fsynced to disk.
<i>617</i>&nbsp;         */
<i>618</i>&nbsp;        long localCheckpoint;
<i>619</i>&nbsp;
<i>620</i>&nbsp;        /**
<i>621</i>&nbsp;         * the last global checkpoint information that we have for this shard. This is the global checkpoint that&#39;s fsynced to disk on the
<i>622</i>&nbsp;         * respective shard, and all operations up to this point are properly fsynced to disk as well.
<i>623</i>&nbsp;         */
<i>624</i>&nbsp;        long globalCheckpoint;
<i>625</i>&nbsp;        /**
<i>626</i>&nbsp;         * whether this shard is treated as in-sync and thus contributes to the global checkpoint calculation
<i>627</i>&nbsp;         */
<i>628</i>&nbsp;        boolean inSync;
<i>629</i>&nbsp;
<i>630</i>&nbsp;        /**
<i>631</i>&nbsp;         * whether this shard is tracked in the replication group, i.e., should receive document updates from the primary.
<i>632</i>&nbsp;         */
<i>633</i>&nbsp;        boolean tracked;
<i>634</i>&nbsp;
<b class="fc"><i>635</i>&nbsp;        public CheckpointState(long localCheckpoint, long globalCheckpoint, boolean inSync, boolean tracked) {</b>
<b class="fc"><i>636</i>&nbsp;            this.localCheckpoint = localCheckpoint;</b>
<b class="fc"><i>637</i>&nbsp;            this.globalCheckpoint = globalCheckpoint;</b>
<b class="fc"><i>638</i>&nbsp;            this.inSync = inSync;</b>
<b class="fc"><i>639</i>&nbsp;            this.tracked = tracked;</b>
<b class="fc"><i>640</i>&nbsp;        }</b>
<i>641</i>&nbsp;
<b class="nc"><i>642</i>&nbsp;        public CheckpointState(StreamInput in) throws IOException {</b>
<b class="nc"><i>643</i>&nbsp;            this.localCheckpoint = in.readZLong();</b>
<b class="nc"><i>644</i>&nbsp;            this.globalCheckpoint = in.readZLong();</b>
<b class="nc"><i>645</i>&nbsp;            this.inSync = in.readBoolean();</b>
<b class="nc"><i>646</i>&nbsp;            if (in.getVersion().onOrAfter(Version.V_6_3_0)) {</b>
<b class="nc"><i>647</i>&nbsp;                this.tracked = in.readBoolean();</b>
<i>648</i>&nbsp;            } else {
<i>649</i>&nbsp;                // Every in-sync shard copy is also tracked (see invariant). This was the case even in earlier ES versions.
<i>650</i>&nbsp;                // Non in-sync shard copies might be tracked or not. As this information here is only serialized during relocation hand-off,
<i>651</i>&nbsp;                // after which replica recoveries cannot complete anymore (i.e. they cannot move from in-sync == false to in-sync == true),
<i>652</i>&nbsp;                // we can treat non in-sync replica shard copies as untracked. They will go through a fresh recovery against the new
<i>653</i>&nbsp;                // primary and will become tracked again under this primary before they are marked as in-sync.
<b class="nc"><i>654</i>&nbsp;                this.tracked = inSync;</b>
<i>655</i>&nbsp;            }
<b class="nc"><i>656</i>&nbsp;        }</b>
<i>657</i>&nbsp;
<i>658</i>&nbsp;        @Override
<i>659</i>&nbsp;        public void writeTo(StreamOutput out) throws IOException {
<b class="nc"><i>660</i>&nbsp;            out.writeZLong(localCheckpoint);</b>
<b class="nc"><i>661</i>&nbsp;            out.writeZLong(globalCheckpoint);</b>
<b class="nc"><i>662</i>&nbsp;            out.writeBoolean(inSync);</b>
<b class="nc"><i>663</i>&nbsp;            if (out.getVersion().onOrAfter(Version.V_6_3_0)) {</b>
<b class="nc"><i>664</i>&nbsp;                out.writeBoolean(tracked);</b>
<i>665</i>&nbsp;            }
<b class="nc"><i>666</i>&nbsp;        }</b>
<i>667</i>&nbsp;
<i>668</i>&nbsp;        /**
<i>669</i>&nbsp;         * Returns a full copy of this object
<i>670</i>&nbsp;         */
<i>671</i>&nbsp;        public CheckpointState copy() {
<b class="nc"><i>672</i>&nbsp;            return new CheckpointState(localCheckpoint, globalCheckpoint, inSync, tracked);</b>
<i>673</i>&nbsp;        }
<i>674</i>&nbsp;
<i>675</i>&nbsp;        public long getLocalCheckpoint() {
<b class="fc"><i>676</i>&nbsp;            return localCheckpoint;</b>
<i>677</i>&nbsp;        }
<i>678</i>&nbsp;
<i>679</i>&nbsp;        public long getGlobalCheckpoint() {
<b class="nc"><i>680</i>&nbsp;            return globalCheckpoint;</b>
<i>681</i>&nbsp;        }
<i>682</i>&nbsp;
<i>683</i>&nbsp;        @Override
<i>684</i>&nbsp;        public String toString() {
<b class="nc"><i>685</i>&nbsp;            return &quot;LocalCheckpointState{&quot; +</b>
<i>686</i>&nbsp;                &quot;localCheckpoint=&quot; + localCheckpoint +
<i>687</i>&nbsp;                &quot;, globalCheckpoint=&quot; + globalCheckpoint +
<i>688</i>&nbsp;                &quot;, inSync=&quot; + inSync +
<i>689</i>&nbsp;                &quot;, tracked=&quot; + tracked +
<i>690</i>&nbsp;                &#39;}&#39;;
<i>691</i>&nbsp;        }
<i>692</i>&nbsp;
<i>693</i>&nbsp;        @Override
<i>694</i>&nbsp;        public boolean equals(Object o) {
<b class="nc"><i>695</i>&nbsp;            if (this == o) return true;</b>
<b class="nc"><i>696</i>&nbsp;            if (o == null || getClass() != o.getClass()) return false;</b>
<i>697</i>&nbsp;
<b class="nc"><i>698</i>&nbsp;            CheckpointState that = (CheckpointState) o;</b>
<i>699</i>&nbsp;
<b class="nc"><i>700</i>&nbsp;            if (localCheckpoint != that.localCheckpoint) return false;</b>
<b class="nc"><i>701</i>&nbsp;            if (globalCheckpoint != that.globalCheckpoint) return false;</b>
<b class="nc"><i>702</i>&nbsp;            if (inSync != that.inSync) return false;</b>
<b class="nc"><i>703</i>&nbsp;            return tracked == that.tracked;</b>
<i>704</i>&nbsp;        }
<i>705</i>&nbsp;
<i>706</i>&nbsp;        @Override
<i>707</i>&nbsp;        public int hashCode() {
<b class="nc"><i>708</i>&nbsp;            int result = Long.hashCode(localCheckpoint);</b>
<b class="nc"><i>709</i>&nbsp;            result = 31 * result + Long.hashCode(globalCheckpoint);</b>
<b class="nc"><i>710</i>&nbsp;            result = 31 * result + Boolean.hashCode(inSync);</b>
<b class="nc"><i>711</i>&nbsp;            result = 31 * result + Boolean.hashCode(tracked);</b>
<b class="nc"><i>712</i>&nbsp;            return result;</b>
<i>713</i>&nbsp;        }
<i>714</i>&nbsp;    }
<i>715</i>&nbsp;
<i>716</i>&nbsp;    /**
<i>717</i>&nbsp;     * Get the local knowledge of the persisted global checkpoints for all in-sync allocation IDs.
<i>718</i>&nbsp;     *
<i>719</i>&nbsp;     * @return a map from allocation ID to the local knowledge of the persisted global checkpoint for that allocation ID
<i>720</i>&nbsp;     */
<i>721</i>&nbsp;    public synchronized ObjectLongMap&lt;String&gt; getInSyncGlobalCheckpoints() {
<b class="nc"><i>722</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>723</i>&nbsp;        assert handoffInProgress == false;</b>
<b class="nc"><i>724</i>&nbsp;        final ObjectLongMap&lt;String&gt; globalCheckpoints = new ObjectLongHashMap&lt;&gt;(checkpoints.size()); // upper bound on the size</b>
<b class="nc"><i>725</i>&nbsp;        checkpoints</b>
<b class="nc"><i>726</i>&nbsp;                .entrySet()</b>
<b class="nc"><i>727</i>&nbsp;                .stream()</b>
<b class="nc"><i>728</i>&nbsp;                .filter(e -&gt; e.getValue().inSync)</b>
<b class="nc"><i>729</i>&nbsp;                .forEach(e -&gt; globalCheckpoints.put(e.getKey(), e.getValue().globalCheckpoint));</b>
<b class="nc"><i>730</i>&nbsp;        return globalCheckpoints;</b>
<i>731</i>&nbsp;    }
<i>732</i>&nbsp;
<i>733</i>&nbsp;    /**
<i>734</i>&nbsp;     * Returns whether the replication tracker is in primary mode, i.e., whether the current shard is acting as primary from the point of
<i>735</i>&nbsp;     * view of replication.
<i>736</i>&nbsp;     */
<i>737</i>&nbsp;    public boolean isPrimaryMode() {
<b class="fc"><i>738</i>&nbsp;        return primaryMode;</b>
<i>739</i>&nbsp;    }
<i>740</i>&nbsp;
<i>741</i>&nbsp;    /**
<i>742</i>&nbsp;     * Returns the current operation primary term.
<i>743</i>&nbsp;     *
<i>744</i>&nbsp;     * @return the primary term
<i>745</i>&nbsp;     */
<i>746</i>&nbsp;    public long getOperationPrimaryTerm() {
<b class="fc"><i>747</i>&nbsp;        return operationPrimaryTerm;</b>
<i>748</i>&nbsp;    }
<i>749</i>&nbsp;
<i>750</i>&nbsp;    /**
<i>751</i>&nbsp;     * Sets the current operation primary term. This method should be invoked only when no other operations are possible on the shard. That
<i>752</i>&nbsp;     * is, either from the constructor of {@link IndexShard} or while holding all permits on the {@link IndexShard} instance.
<i>753</i>&nbsp;     *
<i>754</i>&nbsp;     * @param operationPrimaryTerm the new operation primary term
<i>755</i>&nbsp;     */
<i>756</i>&nbsp;    public void setOperationPrimaryTerm(final long operationPrimaryTerm) {
<b class="nc"><i>757</i>&nbsp;        this.operationPrimaryTerm = operationPrimaryTerm;</b>
<b class="nc"><i>758</i>&nbsp;    }</b>
<i>759</i>&nbsp;
<i>760</i>&nbsp;    /**
<i>761</i>&nbsp;     * Returns whether the replication tracker has relocated away to another shard copy.
<i>762</i>&nbsp;     */
<i>763</i>&nbsp;    public boolean isRelocated() {
<b class="nc"><i>764</i>&nbsp;        return relocated;</b>
<i>765</i>&nbsp;    }
<i>766</i>&nbsp;
<i>767</i>&nbsp;    /**
<i>768</i>&nbsp;     * Class invariant that should hold before and after every invocation of public methods on this class. As Java lacks implication
<i>769</i>&nbsp;     * as a logical operator, many of the invariants are written under the form (!A || B), they should be read as (A implies B) however.
<i>770</i>&nbsp;     */
<i>771</i>&nbsp;    private boolean invariant() {
<i>772</i>&nbsp;        // local checkpoints only set during primary mode
<b class="fc"><i>773</i>&nbsp;        assert primaryMode || checkpoints.values().stream().allMatch(lcps -&gt; lcps.localCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO);</b>
<i>774</i>&nbsp;
<i>775</i>&nbsp;        // global checkpoints only set during primary mode
<b class="fc"><i>776</i>&nbsp;        assert primaryMode || checkpoints.values().stream().allMatch(cps -&gt; cps.globalCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO);</b>
<i>777</i>&nbsp;
<i>778</i>&nbsp;        // relocation handoff can only occur in primary mode
<b class="fc"><i>779</i>&nbsp;        assert !handoffInProgress || primaryMode;</b>
<i>780</i>&nbsp;
<i>781</i>&nbsp;        // a relocated copy is not in primary mode
<b class="fc"><i>782</i>&nbsp;        assert !relocated || !primaryMode;</b>
<i>783</i>&nbsp;
<i>784</i>&nbsp;        // the current shard is marked as in-sync when the global checkpoint tracker operates in primary mode
<b class="fc"><i>785</i>&nbsp;        assert !primaryMode || checkpoints.get(shardAllocationId).inSync;</b>
<i>786</i>&nbsp;
<i>787</i>&nbsp;        // the routing table and replication group is set when the global checkpoint tracker operates in primary mode
<b class="fc"><i>788</i>&nbsp;        assert !primaryMode || (routingTable != null &amp;&amp; replicationGroup != null) :</b>
<i>789</i>&nbsp;            &quot;primary mode but routing table is &quot; + routingTable + &quot; and replication group is &quot; + replicationGroup;
<i>790</i>&nbsp;
<i>791</i>&nbsp;        // when in primary mode, the current allocation ID is the allocation ID of the primary or the relocation allocation ID
<b class="fc"><i>792</i>&nbsp;        assert !primaryMode</b>
<b class="fc"><i>793</i>&nbsp;                || (routingTable.primaryShard().allocationId().getId().equals(shardAllocationId)</b>
<b class="nc"><i>794</i>&nbsp;                || routingTable.primaryShard().allocationId().getRelocationId().equals(shardAllocationId));</b>
<i>795</i>&nbsp;
<i>796</i>&nbsp;        // during relocation handoff there are no entries blocking global checkpoint advancement
<b class="fc"><i>797</i>&nbsp;        assert !handoffInProgress || pendingInSync.isEmpty() :</b>
<i>798</i>&nbsp;            &quot;entries blocking global checkpoint advancement during relocation handoff: &quot; + pendingInSync;
<i>799</i>&nbsp;
<i>800</i>&nbsp;        // entries blocking global checkpoint advancement can only exist in primary mode and when not having a relocation handoff
<b class="fc"><i>801</i>&nbsp;        assert pendingInSync.isEmpty() || (primaryMode &amp;&amp; !handoffInProgress);</b>
<i>802</i>&nbsp;
<i>803</i>&nbsp;        // the computed global checkpoint is always up-to-date
<b class="fc"><i>804</i>&nbsp;        assert !primaryMode</b>
<b class="fc"><i>805</i>&nbsp;                || globalCheckpoint == computeGlobalCheckpoint(pendingInSync, checkpoints.values(), globalCheckpoint)</b>
<i>806</i>&nbsp;                : &quot;global checkpoint is not up-to-date, expected: &quot; +
<b class="nc"><i>807</i>&nbsp;                computeGlobalCheckpoint(pendingInSync, checkpoints.values(), globalCheckpoint) + &quot; but was: &quot; + globalCheckpoint;</b>
<i>808</i>&nbsp;
<i>809</i>&nbsp;        // when in primary mode, the global checkpoint is at most the minimum local checkpoint on all in-sync shard copies
<b class="fc"><i>810</i>&nbsp;        assert !primaryMode</b>
<b class="fc"><i>811</i>&nbsp;                || globalCheckpoint &lt;= inSyncCheckpointStates(checkpoints, CheckpointState::getLocalCheckpoint, LongStream::min)</b>
<i>812</i>&nbsp;                : &quot;global checkpoint [&quot; + globalCheckpoint + &quot;] &quot;
<i>813</i>&nbsp;                + &quot;for primary mode allocation ID [&quot; + shardAllocationId + &quot;] &quot;
<i>814</i>&nbsp;                + &quot;more than in-sync local checkpoints [&quot; + checkpoints + &quot;]&quot;;
<i>815</i>&nbsp;
<i>816</i>&nbsp;        // we have a routing table iff we have a replication group
<b class="fc"><i>817</i>&nbsp;        assert (routingTable == null) == (replicationGroup == null) :</b>
<i>818</i>&nbsp;            &quot;routing table is &quot; + routingTable + &quot; but replication group is &quot; + replicationGroup;
<i>819</i>&nbsp;
<b class="fc"><i>820</i>&nbsp;        assert replicationGroup == null || replicationGroup.equals(calculateReplicationGroup()) :</b>
<b class="nc"><i>821</i>&nbsp;            &quot;cached replication group out of sync: expected: &quot; + calculateReplicationGroup() + &quot; but was: &quot; + replicationGroup;</b>
<i>822</i>&nbsp;
<i>823</i>&nbsp;        // all assigned shards from the routing table are tracked
<b class="fc"><i>824</i>&nbsp;        assert routingTable == null || checkpoints.keySet().containsAll(routingTable.getAllAllocationIds()) :</b>
<i>825</i>&nbsp;            &quot;local checkpoints &quot; + checkpoints + &quot; not in-sync with routing table &quot; + routingTable;
<i>826</i>&nbsp;
<b class="fc"><i>827</i>&nbsp;        for (Map.Entry&lt;String, CheckpointState&gt; entry : checkpoints.entrySet()) {</b>
<i>828</i>&nbsp;            // blocking global checkpoint advancement only happens for shards that are not in-sync
<b class="fc"><i>829</i>&nbsp;            assert !pendingInSync.contains(entry.getKey()) || !entry.getValue().inSync :</b>
<b class="nc"><i>830</i>&nbsp;                &quot;shard copy &quot; + entry.getKey() + &quot; blocks global checkpoint advancement but is in-sync&quot;;</b>
<i>831</i>&nbsp;            // in-sync shard copies are tracked
<b class="fc"><i>832</i>&nbsp;            assert !entry.getValue().inSync || entry.getValue().tracked :</b>
<b class="nc"><i>833</i>&nbsp;                &quot;shard copy &quot; + entry.getKey() + &quot; is in-sync but not tracked&quot;;</b>
<b class="fc"><i>834</i>&nbsp;        }</b>
<i>835</i>&nbsp;
<i>836</i>&nbsp;        // all pending in sync shards are tracked
<b class="fc"><i>837</i>&nbsp;        for (String aId : pendingInSync) {</b>
<b class="nc"><i>838</i>&nbsp;            assert checkpoints.get(aId) != null : &quot;aId [&quot; + aId + &quot;] is pending in sync but isn&#39;t tracked&quot;;</b>
<b class="nc"><i>839</i>&nbsp;        }</b>
<i>840</i>&nbsp;
<b class="fc"><i>841</i>&nbsp;        if (primaryMode</b>
<b class="fc"><i>842</i>&nbsp;            &amp;&amp; indexSettings.isSoftDeleteEnabled()</b>
<b class="nc"><i>843</i>&nbsp;            &amp;&amp; indexSettings.getIndexMetaData().getState() == IndexMetaData.State.OPEN</b>
<i>844</i>&nbsp;            &amp;&amp; hasAllPeerRecoveryRetentionLeases) {
<i>845</i>&nbsp;            // all tracked shard copies have a corresponding peer-recovery retention lease
<b class="nc"><i>846</i>&nbsp;            for (final ShardRouting shardRouting : routingTable.assignedShards()) {</b>
<b class="nc"><i>847</i>&nbsp;                if (checkpoints.get(shardRouting.allocationId().getId()).tracked) {</b>
<b class="nc"><i>848</i>&nbsp;                    assert retentionLeases.contains(getPeerRecoveryRetentionLeaseId(shardRouting))</b>
<i>849</i>&nbsp;                        : &quot;no retention lease for tracked shard [&quot; + shardRouting + &quot;] in &quot; + retentionLeases;
<b class="nc"><i>850</i>&nbsp;                    assert PEER_RECOVERY_RETENTION_LEASE_SOURCE.equals(</b>
<b class="nc"><i>851</i>&nbsp;                        retentionLeases.get(getPeerRecoveryRetentionLeaseId(shardRouting)).source())</b>
<b class="nc"><i>852</i>&nbsp;                        : &quot;incorrect source [&quot; + retentionLeases.get(getPeerRecoveryRetentionLeaseId(shardRouting)).source()</b>
<i>853</i>&nbsp;                        + &quot;] for [&quot; + shardRouting + &quot;] in &quot; + retentionLeases;
<i>854</i>&nbsp;                }
<b class="nc"><i>855</i>&nbsp;            }</b>
<i>856</i>&nbsp;        }
<i>857</i>&nbsp;
<b class="fc"><i>858</i>&nbsp;        return true;</b>
<i>859</i>&nbsp;    }
<i>860</i>&nbsp;
<i>861</i>&nbsp;    private static long inSyncCheckpointStates(
<i>862</i>&nbsp;            final Map&lt;String, CheckpointState&gt; checkpoints,
<i>863</i>&nbsp;            ToLongFunction&lt;CheckpointState&gt; function,
<i>864</i>&nbsp;            Function&lt;LongStream, OptionalLong&gt; reducer) {
<b class="fc"><i>865</i>&nbsp;        final OptionalLong value =</b>
<b class="fc"><i>866</i>&nbsp;                reducer.apply(</b>
<i>867</i>&nbsp;                        checkpoints
<b class="fc"><i>868</i>&nbsp;                                .values()</b>
<b class="fc"><i>869</i>&nbsp;                                .stream()</b>
<b class="fc"><i>870</i>&nbsp;                                .filter(cps -&gt; cps.inSync)</b>
<b class="fc"><i>871</i>&nbsp;                                .mapToLong(function)</b>
<b class="fc"><i>872</i>&nbsp;                                .filter(v -&gt; v != SequenceNumbers.UNASSIGNED_SEQ_NO));</b>
<b class="fc"><i>873</i>&nbsp;        return value.isPresent() ? value.getAsLong() : SequenceNumbers.UNASSIGNED_SEQ_NO;</b>
<i>874</i>&nbsp;    }
<i>875</i>&nbsp;
<i>876</i>&nbsp;    /**
<i>877</i>&nbsp;     * Initialize the global checkpoint service. The specified global checkpoint should be set to the last known global checkpoint, or
<i>878</i>&nbsp;     * {@link SequenceNumbers#UNASSIGNED_SEQ_NO}.
<i>879</i>&nbsp;     *
<i>880</i>&nbsp;     * @param shardId               the shard ID
<i>881</i>&nbsp;     * @param allocationId          the allocation ID
<i>882</i>&nbsp;     * @param indexSettings         the index settings
<i>883</i>&nbsp;     * @param operationPrimaryTerm  the current primary term
<i>884</i>&nbsp;     * @param globalCheckpoint      the last known global checkpoint for this shard, or {@link SequenceNumbers#UNASSIGNED_SEQ_NO}
<i>885</i>&nbsp;     * @param onSyncRetentionLeases a callback when a new retention lease is created or an existing retention lease expires
<i>886</i>&nbsp;     */
<i>887</i>&nbsp;    public ReplicationTracker(
<i>888</i>&nbsp;            final ShardId shardId,
<i>889</i>&nbsp;            final String allocationId,
<i>890</i>&nbsp;            final IndexSettings indexSettings,
<i>891</i>&nbsp;            final long operationPrimaryTerm,
<i>892</i>&nbsp;            final long globalCheckpoint,
<i>893</i>&nbsp;            final LongConsumer onGlobalCheckpointUpdated,
<i>894</i>&nbsp;            final LongSupplier currentTimeMillisSupplier,
<i>895</i>&nbsp;            final BiConsumer&lt;RetentionLeases, ActionListener&lt;ReplicationResponse&gt;&gt; onSyncRetentionLeases,
<i>896</i>&nbsp;            final Supplier&lt;SafeCommitInfo&gt; safeCommitInfoSupplier) {
<b class="fc"><i>897</i>&nbsp;        super(shardId, indexSettings);</b>
<b class="fc"><i>898</i>&nbsp;        assert globalCheckpoint &gt;= SequenceNumbers.UNASSIGNED_SEQ_NO : &quot;illegal initial global checkpoint: &quot; + globalCheckpoint;</b>
<b class="fc"><i>899</i>&nbsp;        this.shardAllocationId = allocationId;</b>
<b class="fc"><i>900</i>&nbsp;        this.primaryMode = false;</b>
<b class="fc"><i>901</i>&nbsp;        this.operationPrimaryTerm = operationPrimaryTerm;</b>
<b class="fc"><i>902</i>&nbsp;        this.handoffInProgress = false;</b>
<b class="fc"><i>903</i>&nbsp;        this.appliedClusterStateVersion = -1L;</b>
<b class="fc"><i>904</i>&nbsp;        this.globalCheckpoint = globalCheckpoint;</b>
<b class="fc"><i>905</i>&nbsp;        this.checkpoints = new HashMap&lt;&gt;(1 + indexSettings.getNumberOfReplicas());</b>
<b class="fc"><i>906</i>&nbsp;        this.onGlobalCheckpointUpdated = Objects.requireNonNull(onGlobalCheckpointUpdated);</b>
<b class="fc"><i>907</i>&nbsp;        this.currentTimeMillisSupplier = Objects.requireNonNull(currentTimeMillisSupplier);</b>
<b class="fc"><i>908</i>&nbsp;        this.onSyncRetentionLeases = Objects.requireNonNull(onSyncRetentionLeases);</b>
<b class="fc"><i>909</i>&nbsp;        this.pendingInSync = new HashSet&lt;&gt;();</b>
<b class="fc"><i>910</i>&nbsp;        this.routingTable = null;</b>
<b class="fc"><i>911</i>&nbsp;        this.replicationGroup = null;</b>
<b class="fc"><i>912</i>&nbsp;        this.hasAllPeerRecoveryRetentionLeases = indexSettings.isSoftDeleteEnabled()</b>
<b class="nc"><i>913</i>&nbsp;            &amp;&amp; indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_4_0)</b>
<b class="nc"><i>914</i>&nbsp;            &amp;&amp; indexSettings.getIndexMetaData().getState() == IndexMetaData.State.OPEN;</b>
<b class="fc"><i>915</i>&nbsp;        this.fileBasedRecoveryThreshold = IndexSettings.FILE_BASED_RECOVERY_THRESHOLD_SETTING.get(indexSettings.getSettings());</b>
<b class="fc"><i>916</i>&nbsp;        this.safeCommitInfoSupplier = safeCommitInfoSupplier;</b>
<b class="fc"><i>917</i>&nbsp;        assert Version.V_EMPTY.equals(indexSettings.getIndexVersionCreated()) == false;</b>
<b class="fc"><i>918</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>919</i>&nbsp;    }</b>
<i>920</i>&nbsp;
<i>921</i>&nbsp;    /**
<i>922</i>&nbsp;     * Returns the current replication group for the shard.
<i>923</i>&nbsp;     *
<i>924</i>&nbsp;     * @return the replication group
<i>925</i>&nbsp;     */
<i>926</i>&nbsp;    public ReplicationGroup getReplicationGroup() {
<b class="nc"><i>927</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>928</i>&nbsp;        return replicationGroup;</b>
<i>929</i>&nbsp;    }
<i>930</i>&nbsp;
<i>931</i>&nbsp;    private ReplicationGroup calculateReplicationGroup() {
<b class="fc"><i>932</i>&nbsp;        return new ReplicationGroup(routingTable,</b>
<b class="fc"><i>933</i>&nbsp;            checkpoints.entrySet().stream().filter(e -&gt; e.getValue().inSync).map(Map.Entry::getKey).collect(Collectors.toSet()),</b>
<b class="fc"><i>934</i>&nbsp;            checkpoints.entrySet().stream().filter(e -&gt; e.getValue().tracked).map(Map.Entry::getKey).collect(Collectors.toSet()));</b>
<i>935</i>&nbsp;    }
<i>936</i>&nbsp;
<i>937</i>&nbsp;    /**
<i>938</i>&nbsp;     * Returns the in-memory global checkpoint for the shard.
<i>939</i>&nbsp;     *
<i>940</i>&nbsp;     * @return the global checkpoint
<i>941</i>&nbsp;     */
<i>942</i>&nbsp;    public long getGlobalCheckpoint() {
<b class="fc"><i>943</i>&nbsp;        return globalCheckpoint;</b>
<i>944</i>&nbsp;    }
<i>945</i>&nbsp;
<i>946</i>&nbsp;    @Override
<i>947</i>&nbsp;    public long getAsLong() {
<b class="fc"><i>948</i>&nbsp;        return globalCheckpoint;</b>
<i>949</i>&nbsp;    }
<i>950</i>&nbsp;
<i>951</i>&nbsp;    /**
<i>952</i>&nbsp;     * Updates the global checkpoint on a replica shard after it has been updated by the primary.
<i>953</i>&nbsp;     *
<i>954</i>&nbsp;     * @param newGlobalCheckpoint the new global checkpoint
<i>955</i>&nbsp;     * @param reason              the reason the global checkpoint was updated
<i>956</i>&nbsp;     */
<i>957</i>&nbsp;    public synchronized void updateGlobalCheckpointOnReplica(final long newGlobalCheckpoint, final String reason) {
<b class="fc"><i>958</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>959</i>&nbsp;        assert primaryMode == false;</b>
<i>960</i>&nbsp;        /*
<i>961</i>&nbsp;         * The global checkpoint here is a local knowledge which is updated under the mandate of the primary. It can happen that the primary
<i>962</i>&nbsp;         * information is lagging compared to a replica (e.g., if a replica is promoted to primary but has stale info relative to other
<i>963</i>&nbsp;         * replica shards). In these cases, the local knowledge of the global checkpoint could be higher than the sync from the lagging
<i>964</i>&nbsp;         * primary.
<i>965</i>&nbsp;         */
<b class="fc"><i>966</i>&nbsp;        final long previousGlobalCheckpoint = globalCheckpoint;</b>
<b class="fc"><i>967</i>&nbsp;        if (newGlobalCheckpoint &gt; previousGlobalCheckpoint) {</b>
<b class="fc"><i>968</i>&nbsp;            globalCheckpoint = newGlobalCheckpoint;</b>
<b class="fc"><i>969</i>&nbsp;            logger.trace(&quot;updated global checkpoint from [{}] to [{}] due to [{}]&quot;, previousGlobalCheckpoint, globalCheckpoint, reason);</b>
<b class="fc"><i>970</i>&nbsp;            onGlobalCheckpointUpdated.accept(globalCheckpoint);</b>
<i>971</i>&nbsp;        }
<b class="fc"><i>972</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>973</i>&nbsp;    }</b>
<i>974</i>&nbsp;
<i>975</i>&nbsp;    /**
<i>976</i>&nbsp;     * Update the local knowledge of the persisted global checkpoint for the specified allocation ID.
<i>977</i>&nbsp;     *
<i>978</i>&nbsp;     * @param allocationId     the allocation ID to update the global checkpoint for
<i>979</i>&nbsp;     * @param globalCheckpoint the global checkpoint
<i>980</i>&nbsp;     */
<i>981</i>&nbsp;    public synchronized void updateGlobalCheckpointForShard(final String allocationId, final long globalCheckpoint) {
<b class="nc"><i>982</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>983</i>&nbsp;        assert handoffInProgress == false;</b>
<b class="nc"><i>984</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>985</i>&nbsp;        final CheckpointState cps = checkpoints.get(allocationId);</b>
<b class="nc"><i>986</i>&nbsp;        assert !this.shardAllocationId.equals(allocationId) || cps != null;</b>
<b class="nc"><i>987</i>&nbsp;        if (cps != null &amp;&amp; globalCheckpoint &gt; cps.globalCheckpoint) {</b>
<b class="nc"><i>988</i>&nbsp;            final long previousGlobalCheckpoint = cps.globalCheckpoint;</b>
<b class="nc"><i>989</i>&nbsp;            cps.globalCheckpoint = globalCheckpoint;</b>
<b class="nc"><i>990</i>&nbsp;            logger.trace(&quot;updated local knowledge for [{}] on the primary of the global checkpoint from [{}] to [{}]&quot;,</b>
<b class="nc"><i>991</i>&nbsp;                allocationId, previousGlobalCheckpoint, globalCheckpoint);</b>
<i>992</i>&nbsp;        }
<b class="nc"><i>993</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>994</i>&nbsp;    }</b>
<i>995</i>&nbsp;
<i>996</i>&nbsp;    /**
<i>997</i>&nbsp;     * Initializes the global checkpoint tracker in primary mode (see {@link #primaryMode}. Called on primary activation or promotion.
<i>998</i>&nbsp;     */
<i>999</i>&nbsp;    public synchronized void activatePrimaryMode(final long localCheckpoint) {
<b class="fc"><i>1000</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>1001</i>&nbsp;        assert primaryMode == false;</b>
<b class="fc"><i>1002</i>&nbsp;        assert checkpoints.get(shardAllocationId) != null &amp;&amp; checkpoints.get(shardAllocationId).inSync &amp;&amp;</b>
<b class="fc"><i>1003</i>&nbsp;            checkpoints.get(shardAllocationId).localCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO :</b>
<i>1004</i>&nbsp;            &quot;expected &quot; + shardAllocationId + &quot; to have initialized entry in &quot; + checkpoints + &quot; when activating primary&quot;;
<b class="fc"><i>1005</i>&nbsp;        assert localCheckpoint &gt;= SequenceNumbers.NO_OPS_PERFORMED;</b>
<b class="fc"><i>1006</i>&nbsp;        primaryMode = true;</b>
<b class="fc"><i>1007</i>&nbsp;        updateLocalCheckpoint(shardAllocationId, checkpoints.get(shardAllocationId), localCheckpoint);</b>
<b class="fc"><i>1008</i>&nbsp;        updateGlobalCheckpointOnPrimary();</b>
<i>1009</i>&nbsp;
<b class="fc"><i>1010</i>&nbsp;        if (indexSettings.isSoftDeleteEnabled()) {</b>
<b class="nc"><i>1011</i>&nbsp;            addPeerRecoveryRetentionLeaseForSolePrimary();</b>
<i>1012</i>&nbsp;        }
<i>1013</i>&nbsp;
<b class="fc"><i>1014</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>1015</i>&nbsp;    }</b>
<i>1016</i>&nbsp;
<i>1017</i>&nbsp;    /**
<i>1018</i>&nbsp;     * Creates a peer recovery retention lease for this shard, if one does not already exist and this shard is the sole shard copy in the
<i>1019</i>&nbsp;     * replication group. If one does not already exist and yet there are other shard copies in this group then we must have just done
<i>1020</i>&nbsp;     * a rolling upgrade from a version before {@link Version#V_7_4_0}, in which case the missing leases should be created asynchronously
<i>1021</i>&nbsp;     * by the caller using {@link ReplicationTracker#createMissingPeerRecoveryRetentionLeases(ActionListener)}.
<i>1022</i>&nbsp;     */
<i>1023</i>&nbsp;    private void addPeerRecoveryRetentionLeaseForSolePrimary() {
<b class="nc"><i>1024</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1025</i>&nbsp;        assert Thread.holdsLock(this);</b>
<i>1026</i>&nbsp;
<b class="nc"><i>1027</i>&nbsp;        if (indexSettings().getIndexMetaData().getState() == IndexMetaData.State.OPEN) {</b>
<b class="nc"><i>1028</i>&nbsp;            final ShardRouting primaryShard = routingTable.primaryShard();</b>
<b class="nc"><i>1029</i>&nbsp;            final String leaseId = getPeerRecoveryRetentionLeaseId(primaryShard);</b>
<b class="nc"><i>1030</i>&nbsp;            if (retentionLeases.get(leaseId) == null) {</b>
<b class="nc"><i>1031</i>&nbsp;                if (replicationGroup.getReplicationTargets().equals(Collections.singletonList(primaryShard))) {</b>
<b class="nc"><i>1032</i>&nbsp;                    assert primaryShard.allocationId().getId().equals(shardAllocationId)</b>
<b class="nc"><i>1033</i>&nbsp;                        : routingTable.assignedShards() + &quot; vs &quot; + shardAllocationId;</b>
<i>1034</i>&nbsp;                    // Safe to call innerAddRetentionLease() without a subsequent sync since there are no other members of this replication
<i>1035</i>&nbsp;                    // group.
<b class="nc"><i>1036</i>&nbsp;                    logger.trace(&quot;addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [{}]&quot;, leaseId);</b>
<b class="nc"><i>1037</i>&nbsp;                    innerAddRetentionLease(leaseId, Math.max(0L, checkpoints.get(shardAllocationId).globalCheckpoint + 1),</b>
<i>1038</i>&nbsp;                        PEER_RECOVERY_RETENTION_LEASE_SOURCE);
<b class="nc"><i>1039</i>&nbsp;                    hasAllPeerRecoveryRetentionLeases = true;</b>
<i>1040</i>&nbsp;                } else {
<i>1041</i>&nbsp;                    /*
<i>1042</i>&nbsp;                     * We got here here via a rolling upgrade from an older version that doesn&#39;t create peer recovery retention
<i>1043</i>&nbsp;                     * leases for every shard copy, but in this case we do not expect any leases to exist.
<i>1044</i>&nbsp;                     */
<b class="nc"><i>1045</i>&nbsp;                    assert hasAllPeerRecoveryRetentionLeases == false : routingTable + &quot; vs &quot; + retentionLeases;</b>
<b class="nc"><i>1046</i>&nbsp;                    logger.debug(&quot;{} becoming primary of {} with missing lease: {}&quot;, primaryShard, routingTable, retentionLeases);</b>
<i>1047</i>&nbsp;                }
<b class="nc"><i>1048</i>&nbsp;            } else if (hasAllPeerRecoveryRetentionLeases == false &amp;&amp; routingTable.assignedShards().stream().allMatch(shardRouting -&gt;</b>
<b class="nc"><i>1049</i>&nbsp;                retentionLeases.contains(getPeerRecoveryRetentionLeaseId(shardRouting))</b>
<b class="nc"><i>1050</i>&nbsp;                    || checkpoints.get(shardRouting.allocationId().getId()).tracked == false)) {</b>
<i>1051</i>&nbsp;                // Although this index is old enough not to have all the expected peer recovery retention leases, in fact it does, so we
<i>1052</i>&nbsp;                // don&#39;t need to do any more work.
<b class="nc"><i>1053</i>&nbsp;                hasAllPeerRecoveryRetentionLeases = true;</b>
<i>1054</i>&nbsp;            }
<i>1055</i>&nbsp;        }
<b class="nc"><i>1056</i>&nbsp;    }</b>
<i>1057</i>&nbsp;
<i>1058</i>&nbsp;    /**
<i>1059</i>&nbsp;     * Notifies the tracker of the current allocation IDs in the cluster state.
<i>1060</i>&nbsp;     * @param applyingClusterStateVersion the cluster state version being applied when updating the allocation IDs from the master
<i>1061</i>&nbsp;     * @param inSyncAllocationIds         the allocation IDs of the currently in-sync shard copies
<i>1062</i>&nbsp;     * @param routingTable                the shard routing table
<i>1063</i>&nbsp;     */
<i>1064</i>&nbsp;    public synchronized void updateFromMaster(final long applyingClusterStateVersion, final Set&lt;String&gt; inSyncAllocationIds,
<i>1065</i>&nbsp;                                              final IndexShardRoutingTable routingTable) {
<b class="fc"><i>1066</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>1067</i>&nbsp;        if (applyingClusterStateVersion &gt; appliedClusterStateVersion) {</b>
<i>1068</i>&nbsp;            // check that the master does not fabricate new in-sync entries out of thin air once we are in primary mode
<b class="fc"><i>1069</i>&nbsp;            assert !primaryMode || inSyncAllocationIds.stream().allMatch(</b>
<b class="nc"><i>1070</i>&nbsp;                inSyncId -&gt; checkpoints.containsKey(inSyncId) &amp;&amp; checkpoints.get(inSyncId).inSync) :</b>
<i>1071</i>&nbsp;                &quot;update from master in primary mode contains in-sync ids &quot; + inSyncAllocationIds +
<i>1072</i>&nbsp;                    &quot; that have no matching entries in &quot; + checkpoints;
<i>1073</i>&nbsp;            // remove entries which don&#39;t exist on master
<b class="fc"><i>1074</i>&nbsp;            Set&lt;String&gt; initializingAllocationIds = routingTable.getAllInitializingShards().stream()</b>
<b class="fc"><i>1075</i>&nbsp;                .map(ShardRouting::allocationId).map(AllocationId::getId).collect(Collectors.toSet());</b>
<b class="fc"><i>1076</i>&nbsp;            boolean removedEntries = checkpoints.keySet().removeIf(</b>
<b class="nc"><i>1077</i>&nbsp;                aid -&gt; !inSyncAllocationIds.contains(aid) &amp;&amp; !initializingAllocationIds.contains(aid));</b>
<i>1078</i>&nbsp;
<b class="fc"><i>1079</i>&nbsp;            if (primaryMode) {</b>
<i>1080</i>&nbsp;                // add new initializingIds that are missing locally. These are fresh shard copies - and not in-sync
<b class="nc"><i>1081</i>&nbsp;                for (String initializingId : initializingAllocationIds) {</b>
<b class="nc"><i>1082</i>&nbsp;                    if (checkpoints.containsKey(initializingId) == false) {</b>
<b class="nc"><i>1083</i>&nbsp;                        final boolean inSync = inSyncAllocationIds.contains(initializingId);</b>
<b class="nc"><i>1084</i>&nbsp;                        assert inSync == false : &quot;update from master in primary mode has &quot; + initializingId +</b>
<i>1085</i>&nbsp;                            &quot; as in-sync but it does not exist locally&quot;;
<b class="nc"><i>1086</i>&nbsp;                        final long localCheckpoint = SequenceNumbers.UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1087</i>&nbsp;                        final long globalCheckpoint = localCheckpoint;</b>
<b class="nc"><i>1088</i>&nbsp;                        checkpoints.put(initializingId, new CheckpointState(localCheckpoint, globalCheckpoint, inSync, inSync));</b>
<i>1089</i>&nbsp;                    }
<b class="nc"><i>1090</i>&nbsp;                }</b>
<b class="nc"><i>1091</i>&nbsp;                if (removedEntries) {</b>
<b class="nc"><i>1092</i>&nbsp;                    pendingInSync.removeIf(aId -&gt; checkpoints.containsKey(aId) == false);</b>
<i>1093</i>&nbsp;                }
<i>1094</i>&nbsp;            } else {
<b class="fc"><i>1095</i>&nbsp;                for (String initializingId : initializingAllocationIds) {</b>
<b class="nc"><i>1096</i>&nbsp;                    final long localCheckpoint = SequenceNumbers.UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1097</i>&nbsp;                    final long globalCheckpoint = localCheckpoint;</b>
<b class="nc"><i>1098</i>&nbsp;                    checkpoints.put(initializingId, new CheckpointState(localCheckpoint, globalCheckpoint, false, false));</b>
<b class="nc"><i>1099</i>&nbsp;                }</b>
<b class="fc"><i>1100</i>&nbsp;                for (String inSyncId : inSyncAllocationIds) {</b>
<b class="fc"><i>1101</i>&nbsp;                    final long localCheckpoint = SequenceNumbers.UNASSIGNED_SEQ_NO;</b>
<b class="fc"><i>1102</i>&nbsp;                    final long globalCheckpoint = localCheckpoint;</b>
<b class="fc"><i>1103</i>&nbsp;                    checkpoints.put(inSyncId, new CheckpointState(localCheckpoint, globalCheckpoint, true, true));</b>
<b class="fc"><i>1104</i>&nbsp;                }</b>
<i>1105</i>&nbsp;            }
<b class="fc"><i>1106</i>&nbsp;            appliedClusterStateVersion = applyingClusterStateVersion;</b>
<b class="fc"><i>1107</i>&nbsp;            this.routingTable = routingTable;</b>
<b class="fc"><i>1108</i>&nbsp;            replicationGroup = calculateReplicationGroup();</b>
<b class="fc"><i>1109</i>&nbsp;            if (primaryMode &amp;&amp; removedEntries) {</b>
<b class="nc"><i>1110</i>&nbsp;                updateGlobalCheckpointOnPrimary();</b>
<i>1111</i>&nbsp;                // notify any waiter for local checkpoint advancement to recheck that their shard is still being tracked.
<b class="nc"><i>1112</i>&nbsp;                notifyAllWaiters();</b>
<i>1113</i>&nbsp;            }
<i>1114</i>&nbsp;        }
<b class="fc"><i>1115</i>&nbsp;        assert invariant();</b>
<b class="fc"><i>1116</i>&nbsp;    }</b>
<i>1117</i>&nbsp;
<i>1118</i>&nbsp;    /**
<i>1119</i>&nbsp;     * Called when the recovery process for a shard has opened the engine on the target shard. Ensures that the right data structures
<i>1120</i>&nbsp;     * have been set up locally to track local checkpoint information for the shard and that the shard is added to the replication group.
<i>1121</i>&nbsp;     *
<i>1122</i>&nbsp;     * @param allocationId  the allocation ID of the shard for which recovery was initiated
<i>1123</i>&nbsp;     */
<i>1124</i>&nbsp;    public synchronized void initiateTracking(final String allocationId) {
<b class="nc"><i>1125</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1126</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1127</i>&nbsp;        assert handoffInProgress == false;</b>
<b class="nc"><i>1128</i>&nbsp;        CheckpointState cps = checkpoints.get(allocationId);</b>
<b class="nc"><i>1129</i>&nbsp;        if (cps == null) {</b>
<i>1130</i>&nbsp;            // can happen if replica was removed from cluster but recovery process is unaware of it yet
<b class="nc"><i>1131</i>&nbsp;            throw new IllegalStateException(&quot;no local checkpoint tracking information available&quot;);</b>
<i>1132</i>&nbsp;        }
<b class="nc"><i>1133</i>&nbsp;        cps.tracked = true;</b>
<b class="nc"><i>1134</i>&nbsp;        replicationGroup = calculateReplicationGroup();</b>
<b class="nc"><i>1135</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1136</i>&nbsp;    }</b>
<i>1137</i>&nbsp;
<i>1138</i>&nbsp;    /**
<i>1139</i>&nbsp;     * Marks the shard with the provided allocation ID as in-sync with the primary shard. This method will block until the local checkpoint
<i>1140</i>&nbsp;     * on the specified shard advances above the current global checkpoint.
<i>1141</i>&nbsp;     *
<i>1142</i>&nbsp;     * @param allocationId    the allocation ID of the shard to mark as in-sync
<i>1143</i>&nbsp;     * @param localCheckpoint the current local checkpoint on the shard
<i>1144</i>&nbsp;     */
<i>1145</i>&nbsp;    public synchronized void markAllocationIdAsInSync(final String allocationId, final long localCheckpoint) throws InterruptedException {
<b class="nc"><i>1146</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1147</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1148</i>&nbsp;        assert handoffInProgress == false;</b>
<b class="nc"><i>1149</i>&nbsp;        CheckpointState cps = checkpoints.get(allocationId);</b>
<b class="nc"><i>1150</i>&nbsp;        if (cps == null) {</b>
<i>1151</i>&nbsp;            // can happen if replica was removed from cluster but recovery process is unaware of it yet
<b class="nc"><i>1152</i>&nbsp;            throw new IllegalStateException(&quot;no local checkpoint tracking information available for &quot; + allocationId);</b>
<i>1153</i>&nbsp;        }
<b class="nc"><i>1154</i>&nbsp;        assert localCheckpoint &gt;= SequenceNumbers.NO_OPS_PERFORMED :</b>
<i>1155</i>&nbsp;            &quot;expected known local checkpoint for &quot; + allocationId + &quot; but was &quot; + localCheckpoint;
<b class="nc"><i>1156</i>&nbsp;        assert pendingInSync.contains(allocationId) == false : &quot;shard copy &quot; + allocationId + &quot; is already marked as pending in-sync&quot;;</b>
<b class="nc"><i>1157</i>&nbsp;        assert cps.tracked : &quot;shard copy &quot; + allocationId + &quot; cannot be marked as in-sync as it&#39;s not tracked&quot;;</b>
<b class="nc"><i>1158</i>&nbsp;        updateLocalCheckpoint(allocationId, cps, localCheckpoint);</b>
<i>1159</i>&nbsp;        // if it was already in-sync (because of a previously failed recovery attempt), global checkpoint must have been
<i>1160</i>&nbsp;        // stuck from advancing
<b class="nc"><i>1161</i>&nbsp;        assert !cps.inSync || (cps.localCheckpoint &gt;= getGlobalCheckpoint()) :</b>
<i>1162</i>&nbsp;            &quot;shard copy &quot; + allocationId + &quot; that&#39;s already in-sync should have a local checkpoint &quot; + cps.localCheckpoint +
<b class="nc"><i>1163</i>&nbsp;                &quot; that&#39;s above the global checkpoint &quot; + getGlobalCheckpoint();</b>
<b class="nc"><i>1164</i>&nbsp;        if (cps.localCheckpoint &lt; getGlobalCheckpoint()) {</b>
<b class="nc"><i>1165</i>&nbsp;            pendingInSync.add(allocationId);</b>
<i>1166</i>&nbsp;            try {
<i>1167</i>&nbsp;                while (true) {
<b class="nc"><i>1168</i>&nbsp;                    if (pendingInSync.contains(allocationId)) {</b>
<b class="nc"><i>1169</i>&nbsp;                        waitForLocalCheckpointToAdvance();</b>
<i>1170</i>&nbsp;                    } else {
<i>1171</i>&nbsp;                        break;
<i>1172</i>&nbsp;                    }
<i>1173</i>&nbsp;                }
<i>1174</i>&nbsp;            } finally {
<b class="nc"><i>1175</i>&nbsp;                pendingInSync.remove(allocationId);</b>
<b class="nc"><i>1176</i>&nbsp;            }</b>
<i>1177</i>&nbsp;        } else {
<b class="nc"><i>1178</i>&nbsp;            cps.inSync = true;</b>
<b class="nc"><i>1179</i>&nbsp;            replicationGroup = calculateReplicationGroup();</b>
<b class="nc"><i>1180</i>&nbsp;            logger.trace(&quot;marked [{}] as in-sync&quot;, allocationId);</b>
<b class="nc"><i>1181</i>&nbsp;            updateGlobalCheckpointOnPrimary();</b>
<i>1182</i>&nbsp;        }
<i>1183</i>&nbsp;
<b class="nc"><i>1184</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1185</i>&nbsp;    }</b>
<i>1186</i>&nbsp;
<i>1187</i>&nbsp;    private boolean updateLocalCheckpoint(String allocationId, CheckpointState cps, long localCheckpoint) {
<i>1188</i>&nbsp;        // a local checkpoint for a shard copy should be a valid sequence number
<b class="fc"><i>1189</i>&nbsp;        assert localCheckpoint &gt;= SequenceNumbers.NO_OPS_PERFORMED :</b>
<i>1190</i>&nbsp;            &quot;invalid local checkpoint [&quot; + localCheckpoint + &quot;] for shard copy [&quot; + allocationId + &quot;]&quot;;
<b class="fc"><i>1191</i>&nbsp;        if (localCheckpoint &gt; cps.localCheckpoint) {</b>
<b class="fc"><i>1192</i>&nbsp;            logger.trace(&quot;updated local checkpoint of [{}] from [{}] to [{}]&quot;, allocationId, cps.localCheckpoint, localCheckpoint);</b>
<b class="fc"><i>1193</i>&nbsp;            cps.localCheckpoint = localCheckpoint;</b>
<b class="fc"><i>1194</i>&nbsp;            return true;</b>
<i>1195</i>&nbsp;        } else {
<b class="nc"><i>1196</i>&nbsp;            logger.trace(&quot;skipped updating local checkpoint of [{}] from [{}] to [{}], current checkpoint is higher&quot;, allocationId,</b>
<b class="nc"><i>1197</i>&nbsp;                cps.localCheckpoint, localCheckpoint);</b>
<b class="nc"><i>1198</i>&nbsp;            return false;</b>
<i>1199</i>&nbsp;        }
<i>1200</i>&nbsp;    }
<i>1201</i>&nbsp;
<i>1202</i>&nbsp;    /**
<i>1203</i>&nbsp;     * Notifies the service to update the local checkpoint for the shard with the provided allocation ID. If the checkpoint is lower than
<i>1204</i>&nbsp;     * the currently known one, this is a no-op. If the allocation ID is not tracked, it is ignored.
<i>1205</i>&nbsp;     *
<i>1206</i>&nbsp;     * @param allocationId    the allocation ID of the shard to update the local checkpoint for
<i>1207</i>&nbsp;     * @param localCheckpoint the local checkpoint for the shard
<i>1208</i>&nbsp;     */
<i>1209</i>&nbsp;    public synchronized void updateLocalCheckpoint(final String allocationId, final long localCheckpoint) {
<b class="nc"><i>1210</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1211</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1212</i>&nbsp;        assert handoffInProgress == false;</b>
<b class="nc"><i>1213</i>&nbsp;        CheckpointState cps = checkpoints.get(allocationId);</b>
<b class="nc"><i>1214</i>&nbsp;        if (cps == null) {</b>
<i>1215</i>&nbsp;            // can happen if replica was removed from cluster but replication process is unaware of it yet
<b class="nc"><i>1216</i>&nbsp;            return;</b>
<i>1217</i>&nbsp;        }
<b class="nc"><i>1218</i>&nbsp;        boolean increasedLocalCheckpoint = updateLocalCheckpoint(allocationId, cps, localCheckpoint);</b>
<b class="nc"><i>1219</i>&nbsp;        boolean pending = pendingInSync.contains(allocationId);</b>
<b class="nc"><i>1220</i>&nbsp;        if (pending &amp;&amp; cps.localCheckpoint &gt;= getGlobalCheckpoint()) {</b>
<b class="nc"><i>1221</i>&nbsp;            pendingInSync.remove(allocationId);</b>
<b class="nc"><i>1222</i>&nbsp;            pending = false;</b>
<b class="nc"><i>1223</i>&nbsp;            cps.inSync = true;</b>
<b class="nc"><i>1224</i>&nbsp;            replicationGroup = calculateReplicationGroup();</b>
<b class="nc"><i>1225</i>&nbsp;            logger.trace(&quot;marked [{}] as in-sync&quot;, allocationId);</b>
<b class="nc"><i>1226</i>&nbsp;            notifyAllWaiters();</b>
<i>1227</i>&nbsp;        }
<b class="nc"><i>1228</i>&nbsp;        if (increasedLocalCheckpoint &amp;&amp; pending == false) {</b>
<b class="nc"><i>1229</i>&nbsp;            updateGlobalCheckpointOnPrimary();</b>
<i>1230</i>&nbsp;        }
<b class="nc"><i>1231</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1232</i>&nbsp;    }</b>
<i>1233</i>&nbsp;
<i>1234</i>&nbsp;    /**
<i>1235</i>&nbsp;     * Computes the global checkpoint based on the given local checkpoints. In case where there are entries preventing the
<i>1236</i>&nbsp;     * computation to happen (for example due to blocking), it returns the fallback value.
<i>1237</i>&nbsp;     */
<i>1238</i>&nbsp;    private static long computeGlobalCheckpoint(final Set&lt;String&gt; pendingInSync, final Collection&lt;CheckpointState&gt; localCheckpoints,
<i>1239</i>&nbsp;                                                final long fallback) {
<b class="fc"><i>1240</i>&nbsp;        long minLocalCheckpoint = Long.MAX_VALUE;</b>
<b class="fc"><i>1241</i>&nbsp;        if (pendingInSync.isEmpty() == false) {</b>
<b class="nc"><i>1242</i>&nbsp;            return fallback;</b>
<i>1243</i>&nbsp;        }
<b class="fc"><i>1244</i>&nbsp;        for (final CheckpointState cps : localCheckpoints) {</b>
<b class="fc"><i>1245</i>&nbsp;            if (cps.inSync) {</b>
<b class="fc"><i>1246</i>&nbsp;                if (cps.localCheckpoint == SequenceNumbers.UNASSIGNED_SEQ_NO) {</b>
<i>1247</i>&nbsp;                    // unassigned in-sync replica
<b class="nc"><i>1248</i>&nbsp;                    return fallback;</b>
<i>1249</i>&nbsp;                } else {
<b class="fc"><i>1250</i>&nbsp;                    minLocalCheckpoint = Math.min(cps.localCheckpoint, minLocalCheckpoint);</b>
<i>1251</i>&nbsp;                }
<i>1252</i>&nbsp;            }
<b class="fc"><i>1253</i>&nbsp;        }</b>
<b class="fc"><i>1254</i>&nbsp;        assert minLocalCheckpoint != Long.MAX_VALUE;</b>
<b class="fc"><i>1255</i>&nbsp;        return minLocalCheckpoint;</b>
<i>1256</i>&nbsp;    }
<i>1257</i>&nbsp;
<i>1258</i>&nbsp;    /**
<i>1259</i>&nbsp;     * Scans through the currently known local checkpoint and updates the global checkpoint accordingly.
<i>1260</i>&nbsp;     */
<i>1261</i>&nbsp;    private synchronized void updateGlobalCheckpointOnPrimary() {
<b class="fc"><i>1262</i>&nbsp;        assert primaryMode;</b>
<b class="fc"><i>1263</i>&nbsp;        final long computedGlobalCheckpoint = computeGlobalCheckpoint(pendingInSync, checkpoints.values(), getGlobalCheckpoint());</b>
<b class="fc"><i>1264</i>&nbsp;        assert computedGlobalCheckpoint &gt;= globalCheckpoint : &quot;new global checkpoint [&quot; + computedGlobalCheckpoint +</b>
<i>1265</i>&nbsp;            &quot;] is lower than previous one [&quot; + globalCheckpoint + &quot;]&quot;;
<b class="fc"><i>1266</i>&nbsp;        if (globalCheckpoint != computedGlobalCheckpoint) {</b>
<b class="nc"><i>1267</i>&nbsp;            globalCheckpoint = computedGlobalCheckpoint;</b>
<b class="nc"><i>1268</i>&nbsp;            logger.trace(&quot;updated global checkpoint to [{}]&quot;, computedGlobalCheckpoint);</b>
<b class="nc"><i>1269</i>&nbsp;            onGlobalCheckpointUpdated.accept(computedGlobalCheckpoint);</b>
<i>1270</i>&nbsp;        }
<b class="fc"><i>1271</i>&nbsp;    }</b>
<i>1272</i>&nbsp;
<i>1273</i>&nbsp;    /**
<i>1274</i>&nbsp;     * Initiates a relocation handoff and returns the corresponding primary context.
<i>1275</i>&nbsp;     */
<i>1276</i>&nbsp;    public synchronized PrimaryContext startRelocationHandoff(String targetAllocationId) {
<b class="nc"><i>1277</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1278</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1279</i>&nbsp;        assert handoffInProgress == false;</b>
<b class="nc"><i>1280</i>&nbsp;        assert pendingInSync.isEmpty() : &quot;relocation handoff started while there are still shard copies pending in-sync: &quot; + pendingInSync;</b>
<b class="nc"><i>1281</i>&nbsp;        if (checkpoints.containsKey(targetAllocationId) == false) {</b>
<i>1282</i>&nbsp;            // can happen if the relocation target was removed from cluster but the recovery process isn&#39;t aware of that.
<b class="nc"><i>1283</i>&nbsp;            throw new IllegalStateException(&quot;relocation target [&quot; + targetAllocationId + &quot;] is no longer part of the replication group&quot;);</b>
<i>1284</i>&nbsp;        }
<b class="nc"><i>1285</i>&nbsp;        handoffInProgress = true;</b>
<i>1286</i>&nbsp;        // copy clusterStateVersion and checkpoints and return
<i>1287</i>&nbsp;        // all the entries from checkpoints that are inSync: the reason we don&#39;t need to care about initializing non-insync entries
<i>1288</i>&nbsp;        // is that they will have to undergo a recovery attempt on the relocation target, and will hence be supplied by the cluster state
<i>1289</i>&nbsp;        // update on the relocation target once relocation completes). We could alternatively also copy the map as-is (its safe), and it
<i>1290</i>&nbsp;        // would be cleaned up on the target by cluster state updates.
<b class="nc"><i>1291</i>&nbsp;        Map&lt;String, CheckpointState&gt; localCheckpointsCopy = new HashMap&lt;&gt;();</b>
<b class="nc"><i>1292</i>&nbsp;        for (Map.Entry&lt;String, CheckpointState&gt; entry : checkpoints.entrySet()) {</b>
<b class="nc"><i>1293</i>&nbsp;            localCheckpointsCopy.put(entry.getKey(), entry.getValue().copy());</b>
<b class="nc"><i>1294</i>&nbsp;        }</b>
<b class="nc"><i>1295</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1296</i>&nbsp;        return new PrimaryContext(appliedClusterStateVersion, localCheckpointsCopy, routingTable);</b>
<i>1297</i>&nbsp;    }
<i>1298</i>&nbsp;
<i>1299</i>&nbsp;    /**
<i>1300</i>&nbsp;     * Fails a relocation handoff attempt.
<i>1301</i>&nbsp;     */
<i>1302</i>&nbsp;    public synchronized void abortRelocationHandoff() {
<b class="nc"><i>1303</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1304</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1305</i>&nbsp;        assert handoffInProgress;</b>
<b class="nc"><i>1306</i>&nbsp;        handoffInProgress = false;</b>
<b class="nc"><i>1307</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1308</i>&nbsp;    }</b>
<i>1309</i>&nbsp;
<i>1310</i>&nbsp;    /**
<i>1311</i>&nbsp;     * Marks a relocation handoff attempt as successful. Moves the tracker into replica mode.
<i>1312</i>&nbsp;     */
<i>1313</i>&nbsp;    public synchronized void completeRelocationHandoff() {
<b class="nc"><i>1314</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1315</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1316</i>&nbsp;        assert handoffInProgress;</b>
<b class="nc"><i>1317</i>&nbsp;        assert relocated == false;</b>
<b class="nc"><i>1318</i>&nbsp;        primaryMode = false;</b>
<b class="nc"><i>1319</i>&nbsp;        handoffInProgress = false;</b>
<b class="nc"><i>1320</i>&nbsp;        relocated = true;</b>
<i>1321</i>&nbsp;        // forget all checkpoint information
<b class="nc"><i>1322</i>&nbsp;        checkpoints.forEach((key, cps) -&gt; {</b>
<b class="nc"><i>1323</i>&nbsp;            cps.localCheckpoint = SequenceNumbers.UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1324</i>&nbsp;            cps.globalCheckpoint = SequenceNumbers.UNASSIGNED_SEQ_NO;</b>
<b class="nc"><i>1325</i>&nbsp;        });</b>
<b class="nc"><i>1326</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1327</i>&nbsp;    }</b>
<i>1328</i>&nbsp;
<i>1329</i>&nbsp;    /**
<i>1330</i>&nbsp;     * Activates the global checkpoint tracker in primary mode (see {@link #primaryMode}. Called on primary relocation target during
<i>1331</i>&nbsp;     * primary relocation handoff.
<i>1332</i>&nbsp;     *
<i>1333</i>&nbsp;     * @param primaryContext the primary context used to initialize the state
<i>1334</i>&nbsp;     */
<i>1335</i>&nbsp;    public synchronized void activateWithPrimaryContext(PrimaryContext primaryContext) {
<b class="nc"><i>1336</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1337</i>&nbsp;        assert primaryMode == false;</b>
<b class="nc"><i>1338</i>&nbsp;        if (primaryContext.checkpoints.containsKey(shardAllocationId) == false) {</b>
<i>1339</i>&nbsp;            // can happen if the old primary was on an old version
<b class="nc"><i>1340</i>&nbsp;            assert indexSettings.getIndexVersionCreated().before(Version.V_7_3_0);</b>
<b class="nc"><i>1341</i>&nbsp;            throw new IllegalStateException(&quot;primary context [&quot; + primaryContext + &quot;] does not contain &quot; + shardAllocationId);</b>
<i>1342</i>&nbsp;        }
<b class="nc"><i>1343</i>&nbsp;        final Runnable runAfter = getMasterUpdateOperationFromCurrentState();</b>
<b class="nc"><i>1344</i>&nbsp;        primaryMode = true;</b>
<i>1345</i>&nbsp;        // capture current state to possibly replay missed cluster state update
<b class="nc"><i>1346</i>&nbsp;        appliedClusterStateVersion = primaryContext.clusterStateVersion();</b>
<b class="nc"><i>1347</i>&nbsp;        checkpoints.clear();</b>
<b class="nc"><i>1348</i>&nbsp;        for (Map.Entry&lt;String, CheckpointState&gt; entry : primaryContext.checkpoints.entrySet()) {</b>
<b class="nc"><i>1349</i>&nbsp;            checkpoints.put(entry.getKey(), entry.getValue().copy());</b>
<b class="nc"><i>1350</i>&nbsp;        }</b>
<b class="nc"><i>1351</i>&nbsp;        routingTable = primaryContext.getRoutingTable();</b>
<b class="nc"><i>1352</i>&nbsp;        replicationGroup = calculateReplicationGroup();</b>
<b class="nc"><i>1353</i>&nbsp;        updateGlobalCheckpointOnPrimary();</b>
<i>1354</i>&nbsp;        // reapply missed cluster state update
<i>1355</i>&nbsp;        // note that if there was no cluster state update between start of the engine of this shard and the call to
<i>1356</i>&nbsp;        // initializeWithPrimaryContext, we might still have missed a cluster state update. This is best effort.
<b class="nc"><i>1357</i>&nbsp;        runAfter.run();</b>
<i>1358</i>&nbsp;
<b class="nc"><i>1359</i>&nbsp;        if (indexSettings.isSoftDeleteEnabled()) {</b>
<b class="nc"><i>1360</i>&nbsp;            addPeerRecoveryRetentionLeaseForSolePrimary();</b>
<i>1361</i>&nbsp;        }
<i>1362</i>&nbsp;
<b class="nc"><i>1363</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1364</i>&nbsp;    }</b>
<i>1365</i>&nbsp;
<i>1366</i>&nbsp;    private synchronized void setHasAllPeerRecoveryRetentionLeases() {
<b class="nc"><i>1367</i>&nbsp;        hasAllPeerRecoveryRetentionLeases = true;</b>
<b class="nc"><i>1368</i>&nbsp;        assert invariant();</b>
<b class="nc"><i>1369</i>&nbsp;    }</b>
<i>1370</i>&nbsp;
<i>1371</i>&nbsp;    public synchronized boolean hasAllPeerRecoveryRetentionLeases() {
<b class="fc"><i>1372</i>&nbsp;        return hasAllPeerRecoveryRetentionLeases;</b>
<i>1373</i>&nbsp;    }
<i>1374</i>&nbsp;
<i>1375</i>&nbsp;    /**
<i>1376</i>&nbsp;     * Create any required peer-recovery retention leases that do not currently exist because we just did a rolling upgrade from a version
<i>1377</i>&nbsp;     * prior to {@link Version#V_7_4_0} that does not create peer-recovery retention leases.
<i>1378</i>&nbsp;     */
<i>1379</i>&nbsp;    public synchronized void createMissingPeerRecoveryRetentionLeases(ActionListener&lt;Void&gt; listener) {
<b class="fc"><i>1380</i>&nbsp;        if (indexSettings().isSoftDeleteEnabled()</b>
<b class="nc"><i>1381</i>&nbsp;            &amp;&amp; indexSettings().getIndexMetaData().getState() == IndexMetaData.State.OPEN</b>
<i>1382</i>&nbsp;            &amp;&amp; hasAllPeerRecoveryRetentionLeases == false) {
<i>1383</i>&nbsp;
<b class="nc"><i>1384</i>&nbsp;            final List&lt;ShardRouting&gt; shardRoutings = routingTable.assignedShards();</b>
<b class="nc"><i>1385</i>&nbsp;            final GroupedActionListener&lt;ReplicationResponse&gt; groupedActionListener = new GroupedActionListener&lt;&gt;(ActionListener.wrap(vs -&gt; {</b>
<b class="nc"><i>1386</i>&nbsp;                setHasAllPeerRecoveryRetentionLeases();</b>
<b class="nc"><i>1387</i>&nbsp;                listener.onResponse(null);</b>
<b class="nc"><i>1388</i>&nbsp;            }, listener::onFailure), shardRoutings.size());</b>
<b class="nc"><i>1389</i>&nbsp;            for (ShardRouting shardRouting : shardRoutings) {</b>
<b class="nc"><i>1390</i>&nbsp;                if (retentionLeases.contains(getPeerRecoveryRetentionLeaseId(shardRouting))) {</b>
<b class="nc"><i>1391</i>&nbsp;                    groupedActionListener.onResponse(null);</b>
<i>1392</i>&nbsp;                } else {
<b class="nc"><i>1393</i>&nbsp;                    final CheckpointState checkpointState = checkpoints.get(shardRouting.allocationId().getId());</b>
<b class="nc"><i>1394</i>&nbsp;                    if (checkpointState.tracked == false) {</b>
<b class="nc"><i>1395</i>&nbsp;                        groupedActionListener.onResponse(null);</b>
<i>1396</i>&nbsp;                    } else {
<b class="nc"><i>1397</i>&nbsp;                        logger.trace(&quot;createMissingPeerRecoveryRetentionLeases: adding missing lease for {}&quot;, shardRouting);</b>
<i>1398</i>&nbsp;                        try {
<b class="nc"><i>1399</i>&nbsp;                            addPeerRecoveryRetentionLease(shardRouting.currentNodeId(),</b>
<b class="nc"><i>1400</i>&nbsp;                                Math.max(SequenceNumbers.NO_OPS_PERFORMED, checkpointState.globalCheckpoint), groupedActionListener);</b>
<b class="nc"><i>1401</i>&nbsp;                        } catch (Exception e) {</b>
<b class="nc"><i>1402</i>&nbsp;                            groupedActionListener.onFailure(e);</b>
<b class="nc"><i>1403</i>&nbsp;                        }</b>
<i>1404</i>&nbsp;                    }
<i>1405</i>&nbsp;                }
<b class="nc"><i>1406</i>&nbsp;            }</b>
<b class="nc"><i>1407</i>&nbsp;        } else {</b>
<b class="fc"><i>1408</i>&nbsp;            logger.trace(&quot;createMissingPeerRecoveryRetentionLeases: nothing to do&quot;);</b>
<b class="fc"><i>1409</i>&nbsp;            listener.onResponse(null);</b>
<i>1410</i>&nbsp;        }
<b class="fc"><i>1411</i>&nbsp;    }</b>
<i>1412</i>&nbsp;
<i>1413</i>&nbsp;    private Runnable getMasterUpdateOperationFromCurrentState() {
<b class="nc"><i>1414</i>&nbsp;        assert primaryMode == false;</b>
<b class="nc"><i>1415</i>&nbsp;        final long lastAppliedClusterStateVersion = appliedClusterStateVersion;</b>
<b class="nc"><i>1416</i>&nbsp;        final Set&lt;String&gt; inSyncAllocationIds = new HashSet&lt;&gt;();</b>
<b class="nc"><i>1417</i>&nbsp;        checkpoints.entrySet().forEach(entry -&gt; {</b>
<b class="nc"><i>1418</i>&nbsp;            if (entry.getValue().inSync) {</b>
<b class="nc"><i>1419</i>&nbsp;                inSyncAllocationIds.add(entry.getKey());</b>
<i>1420</i>&nbsp;            }
<b class="nc"><i>1421</i>&nbsp;        });</b>
<b class="nc"><i>1422</i>&nbsp;        final IndexShardRoutingTable lastAppliedRoutingTable = routingTable;</b>
<b class="nc"><i>1423</i>&nbsp;        return () -&gt; updateFromMaster(lastAppliedClusterStateVersion, inSyncAllocationIds, lastAppliedRoutingTable);</b>
<i>1424</i>&nbsp;    }
<i>1425</i>&nbsp;
<i>1426</i>&nbsp;    /**
<i>1427</i>&nbsp;     * Whether the are shards blocking global checkpoint advancement.
<i>1428</i>&nbsp;     */
<i>1429</i>&nbsp;    public synchronized boolean pendingInSync() {
<b class="nc"><i>1430</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1431</i>&nbsp;        return pendingInSync.isEmpty() == false;</b>
<i>1432</i>&nbsp;    }
<i>1433</i>&nbsp;
<i>1434</i>&nbsp;    /**
<i>1435</i>&nbsp;     * Returns the local checkpoint information tracked for a specific shard. Used by tests.
<i>1436</i>&nbsp;     */
<i>1437</i>&nbsp;    public synchronized CheckpointState getTrackedLocalCheckpointForShard(String allocationId) {
<b class="nc"><i>1438</i>&nbsp;        assert primaryMode;</b>
<b class="nc"><i>1439</i>&nbsp;        return checkpoints.get(allocationId);</b>
<i>1440</i>&nbsp;    }
<i>1441</i>&nbsp;
<i>1442</i>&nbsp;    /**
<i>1443</i>&nbsp;     * Notify all threads waiting on the monitor on this tracker. These threads should be waiting for the local checkpoint on a specific
<i>1444</i>&nbsp;     * allocation ID to catch up to the global checkpoint.
<i>1445</i>&nbsp;     */
<i>1446</i>&nbsp;    @SuppressForbidden(reason = &quot;Object#notifyAll waiters for local checkpoint advancement&quot;)
<i>1447</i>&nbsp;    private synchronized void notifyAllWaiters() {
<b class="nc"><i>1448</i>&nbsp;        this.notifyAll();</b>
<b class="nc"><i>1449</i>&nbsp;    }</b>
<i>1450</i>&nbsp;
<i>1451</i>&nbsp;    /**
<i>1452</i>&nbsp;     * Wait for the local checkpoint to advance to the global checkpoint.
<i>1453</i>&nbsp;     *
<i>1454</i>&nbsp;     * @throws InterruptedException if this thread was interrupted before of during waiting
<i>1455</i>&nbsp;     */
<i>1456</i>&nbsp;    @SuppressForbidden(reason = &quot;Object#wait for local checkpoint advancement&quot;)
<i>1457</i>&nbsp;    private synchronized void waitForLocalCheckpointToAdvance() throws InterruptedException {
<b class="nc"><i>1458</i>&nbsp;        this.wait();</b>
<b class="nc"><i>1459</i>&nbsp;    }</b>
<i>1460</i>&nbsp;
<i>1461</i>&nbsp;    /**
<i>1462</i>&nbsp;     * Represents the sequence number component of the primary context. This is the knowledge on the primary of the in-sync and initializing
<i>1463</i>&nbsp;     * shards and their local checkpoints.
<i>1464</i>&nbsp;     */
<i>1465</i>&nbsp;    public static class PrimaryContext implements Writeable {
<i>1466</i>&nbsp;
<i>1467</i>&nbsp;        private final long clusterStateVersion;
<i>1468</i>&nbsp;        private final Map&lt;String, CheckpointState&gt; checkpoints;
<i>1469</i>&nbsp;        private final IndexShardRoutingTable routingTable;
<i>1470</i>&nbsp;
<i>1471</i>&nbsp;        public PrimaryContext(long clusterStateVersion, Map&lt;String, CheckpointState&gt; checkpoints,
<i>1472</i>&nbsp;                              IndexShardRoutingTable routingTable) {
<i>1473</i>&nbsp;            this.clusterStateVersion = clusterStateVersion;
<i>1474</i>&nbsp;            this.checkpoints = checkpoints;
<i>1475</i>&nbsp;            this.routingTable = routingTable;
<i>1476</i>&nbsp;        }
<i>1477</i>&nbsp;
<i>1478</i>&nbsp;        public PrimaryContext(StreamInput in) throws IOException {
<i>1479</i>&nbsp;            clusterStateVersion = in.readVLong();
<i>1480</i>&nbsp;            checkpoints = in.readMap(StreamInput::readString, CheckpointState::new);
<i>1481</i>&nbsp;            routingTable = IndexShardRoutingTable.Builder.readFrom(in);
<i>1482</i>&nbsp;        }
<i>1483</i>&nbsp;
<i>1484</i>&nbsp;        public long clusterStateVersion() {
<i>1485</i>&nbsp;            return clusterStateVersion;
<i>1486</i>&nbsp;        }
<i>1487</i>&nbsp;
<i>1488</i>&nbsp;        public Map&lt;String, CheckpointState&gt; getCheckpointStates() {
<i>1489</i>&nbsp;            return checkpoints;
<i>1490</i>&nbsp;        }
<i>1491</i>&nbsp;
<i>1492</i>&nbsp;        public IndexShardRoutingTable getRoutingTable() {
<i>1493</i>&nbsp;            return routingTable;
<i>1494</i>&nbsp;        }
<i>1495</i>&nbsp;
<i>1496</i>&nbsp;        @Override
<i>1497</i>&nbsp;        public void writeTo(StreamOutput out) throws IOException {
<i>1498</i>&nbsp;            out.writeVLong(clusterStateVersion);
<i>1499</i>&nbsp;            out.writeMap(checkpoints, (streamOutput, s) -&gt; out.writeString(s), (streamOutput, cps) -&gt; cps.writeTo(out));
<i>1500</i>&nbsp;            IndexShardRoutingTable.Builder.writeTo(routingTable, out);
<i>1501</i>&nbsp;        }
<i>1502</i>&nbsp;
<i>1503</i>&nbsp;        @Override
<i>1504</i>&nbsp;        public String toString() {
<i>1505</i>&nbsp;            return &quot;PrimaryContext{&quot; +
<i>1506</i>&nbsp;                    &quot;clusterStateVersion=&quot; + clusterStateVersion +
<i>1507</i>&nbsp;                    &quot;, checkpoints=&quot; + checkpoints +
<i>1508</i>&nbsp;                    &quot;, routingTable=&quot; + routingTable +
<i>1509</i>&nbsp;                    &#39;}&#39;;
<i>1510</i>&nbsp;        }
<i>1511</i>&nbsp;
<i>1512</i>&nbsp;        @Override
<i>1513</i>&nbsp;        public boolean equals(Object o) {
<i>1514</i>&nbsp;            if (this == o) return true;
<i>1515</i>&nbsp;            if (o == null || getClass() != o.getClass()) return false;
<i>1516</i>&nbsp;
<i>1517</i>&nbsp;            PrimaryContext that = (PrimaryContext) o;
<i>1518</i>&nbsp;
<i>1519</i>&nbsp;            if (clusterStateVersion != that.clusterStateVersion) return false;
<i>1520</i>&nbsp;            if (routingTable.equals(that.routingTable)) return false;
<i>1521</i>&nbsp;            return routingTable.equals(that.routingTable);
<i>1522</i>&nbsp;        }
<i>1523</i>&nbsp;
<i>1524</i>&nbsp;        @Override
<i>1525</i>&nbsp;        public int hashCode() {
<i>1526</i>&nbsp;            int result = Long.hashCode(clusterStateVersion);
<i>1527</i>&nbsp;            result = 31 * result + checkpoints.hashCode();
<i>1528</i>&nbsp;            result = 31 * result + routingTable.hashCode();
<i>1529</i>&nbsp;            return result;
<i>1530</i>&nbsp;        }
<i>1531</i>&nbsp;    }
<i>1532</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-02-09 18:45</div>
</div>
</body>
</html>
